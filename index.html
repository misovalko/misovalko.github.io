<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<!-- saved from url=(0056)http://researchers.lille.inria.fr/~valko/hp/research.php -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		<meta name="author" content="valko">
		<meta name="keywords" content="Michal, Valko, Michal Valko, CS, Pitt, homepage, fmph, fmfi, uk, alejova, oktava, lisboa">
		<meta name="description" content="Michal Valko&#39;s homepage.">
		
		<title>Michal Valko  - Research</title>
 		<link rel="shortcut icon" href="http://researchers.lille.inria.fr/~valko/hp/images/micon6.jpg"> 	
		<link rel="stylesheet" href="./Michal Valko - Research_files/luky.css" title="base" type="text/css">
		<link href="./Michal Valko - Research_files/css" rel="stylesheet" type="text/css">
				<script type="text/javascript" async="" src="./Michal Valko - Research_files/ga.js"></script><script type="text/javascript" src="./Michal Valko - Research_files/dojo.js"></script>
		<script type="text/javascript">	
			dojo.require("dojo.lfx.*");	
			function wipeOut(elId) {dojo.lfx.wipeOut(elId, 300).play();}
			function wipeIn(elId) {dojo.lfx.wipeIn(elId, 300).play();}
			function wipeToggle(elId){if (document.getElementById(elId).style.display=="none") wipeIn(elId); else wipeOut(elId);}	
			dojo.require("dojo.widget.TabContainer");
			dojo.require("dojo.widget.ContentPane");
		</script><style type="text/css">.dojoLayoutContainer{ position: relative; display: block; }
body .dojoAlignTop, body .dojoAlignBottom, body .dojoAlignLeft, body .dojoAlignRight { position: absolute; overflow: hidden; }
body .dojoAlignClient { position: absolute }
.dojoAlignClient { overflow: auto; }
</style>
		<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-306495-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

	</head>
	<body>
	<div id="supertoplt"><div id="supertoprt"><div id="supertop"></div></div></div>
	<div id="lt"><div id="rt">
	<div id="top"><span class="nadpis">Michal Valko : Research</span></div>
	  <div id="menu">
	    <div class="menulink">
				    <a href="http://researchers.lille.inria.fr/~valko/hp/index.php">Intro</a>
				    <a href="http://researchers.lille.inria.fr/~valko/hp/research.php">Publications</a>
				    <a href="http://researchers.lille.inria.fr/~valko/hp/project.php">Projects</a>
					<a href="http://researchers.lille.inria.fr/~valko/hp/press.php">Press</a>
					<a href="http://researchers.lille.inria.fr/~valko/hp/talks.php">Talks</a>
				    <a href="http://researchers.lille.inria.fr/~valko/hp/service.php">Service</a>
				    <a href="http://researchers.lille.inria.fr/~valko/hp/study.php">Experience</a>
				    <a href="http://researchers.lille.inria.fr/~valko/hp/mva-ml-graphs.php">Teaching (MVA)</a>				    
<!--				    				    <a href="ta2061-0007.php">Teaching</a>-->
<!--				    <a href="project-pexeso">Matching</a>                -->
<!--                                    <a      href="../gallery2/main.php?g2_itemId=1455">Vallery</a> -->
<!--				    <a href="glee.php">Music</a>  -->
<!--				    <a href="lisboa.php">Lisboa</a> -->
<!--				    <a href="photo">Photos</a> -->
<!--				    <a href="links.php">Links</a> -->
<!--					<a href="misc.php">Misc.</a> -->
					
			  	    </div> 
			<br>
			<span class="male">michal.valko#inria.fr</span>
		<div id="menuicons">
<!--
			<a href="http://www.nedstatbasic.net/stats?ACneZAiW8vuD3iacaP9T1angcH5Q" ><img src="http://m1.nedstatbasic.net/n?id=ACneZAiW8vuD3iacaP9T1angcH5Q"  width="0" height="0" title="nedstat" alt="counter1" /></a>   
                        <a href="http://counters.dataintech.com/"><img src="http://counters.dataintech.com/counter.php?id=1946&amp;login=misovalko" alt="" width="0" height="0" /></a> 
-->		
	    </div>
		<div class="centered">
		<a href="http://researchers.lille.inria.fr/~valko/hp/images/gr20.jpg"><img src="./Michal Valko - Research_files/mvgr20.jpg" alt="mv"></a>
		<br><br>
		<a href="https://deepmind.com/"><img src="./Michal Valko - Research_files/DM_RGB_Lockup_Blue.png" alt="DeepMind" height="35"></a><br><br>	
		<a href="https://sequel.lille.inria.fr/"><img src="./Michal Valko - Research_files/sequel.jpg" alt="SequeL" height="25"></a><br><br>
		<a href="http://www.inria.fr/centre/lille"><img src="./Michal Valko - Research_files/INRIA-CORPO-CMJN.jpg" alt="inria" height="40"></a><br><br><br>
		<a href="https://team.inria.fr/sequel/team-members/"><img src="./Michal Valko - Research_files/vstudents" width="65" alt="students"></a>
<!--		<span class="note"><a href="http://kms.sk/~gallery/main.php?g2_view=rss.SimpleRender&amp;g2_itemId=1455"><img src="images/rss-big.png" alt="rss for gallery" /></a> <br />
<a href="http://spreadsheets.google.com/ccc?key=pjN4Ej7sIAYlEWvtPWE-uWg"><img src="images/fish.png" alt="fish"/></a></span>  -->
		</div>

	  </div> 
	  <div id="content"> 

My 
<a href="http://scholar.google.com/citations?user=jrazNCQAAAAJ&amp;sortby=pubdate">Google Scholar profile</a>,
<a href="https://deepmind.com/research?filters=%7B%22authors%22:%5B%225783124260945920%22%5D%7D">DeepMind profile</a>,
<a href="https://arxiv.org/search/?query=Valko%2C+Michal&amp;searchtype=author&amp;abstracts=show&amp;order=-announced_date_first&amp;size=100">ArXiv profile</a>,
and 
<a href="https://hal.inria.fr/search/index/?qa[auth_t][]=Michal+Valko&amp;sort=producedDateY_i+desc">HAL profile</a>.



<!-- 
http://haltools.inria.fr/Public/afficheRequetePubli.php?auteur_exp=Michal,%20Valko&CB_auteur=oui&CB_titre=oui&CB_article=oui&langue=Anglais&tri_exp=annee_publi&tri_exp2=typdoc&tri_exp3=date_publi&ordre_aff=TA&Fen=Aff&css=../css/styles_publicationsHAL.css
-->


<!--<h2>Selected Publications</h2> -->
<!-- <ul id="starred-publications-list">
<? //require("selected_publications.php") ?>
</ul> -->
<!--<h2>Other Publications</h2> -->
<!-- <ul id="publications-list"> -->
<h2>preprints</h2>
<ul class="publications-list">

<li>Zhaohan Daniel Guo, Mohammad Gheshlaghi Azar, Alaa Saade, Shantanu Thakoor, Bilal Piot, Bernardo Avila Pires, <strong>Michal Valko</strong>, Thomas Mesnard, Tor Lattimore, Rémi Munos:
  <aa href="serve.php?what=publications/guo2021geometric"><em>
Geometric entropic exploration,</em></aa>
  <a href="https://arxiv.org/abs/2101.02055">arXiv preprint</a>
</li>	

<li>Xavier Fontaine, Pierre Perrault, <strong>Michal Valko</strong>, Vianney Perchet:
  <aa href="serve.php?what=publications/fontaine2021online"><em>
Online A-optimal design and active linear regression</em></aa>, 
 <a href="https://arxiv.org/abs/1906.08509">arXiv preprint</a>
</li>


<li>Pierre Perrault, Jennifer Healey, Zheng Wen, Michal Valko <strong>Michal Valko</strong>:
  <aa href="serve.php?what=publications/perrault2021on"><em>
On the approximation relationship between optimizing ratio of submodular (RS) and difference of submodular (DS) functions,</em></aa>
  <a href="https://arxiv.org/abs/2101.01631">arXiv preprint</a>
</li>	


	
<li>Pierre Ménard, Omar Darwiche Domingues, Emilie Kaufmann, Anders Jonsson, Edouard Leurent, <strong>Michal Valko</strong>:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/menard2020fast"><em>
Fast active learning for pure exploration in reinforcement learning,</em></a>
  <a href="http://arxiv.org/abs/2007.13442">arXiv preprint,</a>
<a href="http://researchers.lille.inria.fr/~valko/hp/publications/menard2020fast.bib">bibtex</a><a onclick="wipeToggle(&#39;menard2020fast_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="menard2020fast_abstract" style="display: none"> <p><em>  Abstract:</em>Realistic environments often provide agents with very limited feedback. When the environment is initially unknown, the feedback, in the beginning, can be completely absent, and the agents may first choose to devote all their effort on exploring efficiently. The exploration remains a challenge while it has been addressed with many hand-tuned heuristics with different levels of generality on one side, and a few theoretically backed exploration strategies on the other. Many of them are incarnated by intrinsic motivation and in particular explorations bonuses. A common rule of thumb for exploration bonuses is to use 1/n‾√ bonus that is added to the empirical estimates of the reward, where n is a number of times this particular state (or a state-action pair) was visited. We show that, surprisingly, for a pure-exploration objective of reward-free exploration, bonuses that scale with 1/n bring faster learning rates, improving the known upper bounds with respect to the dependence on the horizon H. Furthermore, we show that with an improved analysis of the stopping time, we can improve by a factor H the sample complexity in the best-policy identification setting, which is another pure-exploration objective, where the environment provides rewards but the agent is not penalized for its behavior during the exploration phase.</p></div></li>	

<li>Jean Tarbouriech, Matteo Pirotta, <strong>Michal Valko</strong>, Alessandro Lazaric:
  <aa href="serve.php?what=publications/tarbouriech2020provably"><em>
A provably efficient sample collection strategy for reinforcement learning</em></aa> 
  <a href="http://arxiv.org/abs/2007.06437">arXiv preprint,</a>
<a href="http://researchers.lille.inria.fr/~valko/hp/publications/tarbouriech2020provably.bib">bibtex</a><a onclick="wipeToggle(&#39;tarbouriech2020provably_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="tarbouriech2020provably_abstract" style="display: none"> <p><em>  Abstract:</em>A common assumption in reinforcement learning (RL) is to have access to a generative model (i.e., a simulator of the environment), which allows to generate samples from any desired state-action pair. Nonetheless, in many settings a generative model may not be available and an adaptive exploration strategy is needed to efficiently collect samples from an unknown environment by direct interaction. In this paper, we study the scenario where an algorithm based on the generative model assumption defines the (possibly time-varying) amount of samples b(s,a) required at each state-action pair (s,a) and an exploration strategy has to learn how to generate b(s,a) samples as fast as possible. Building on recent results for regret minimization in the stochastic shortest path (SSP) setting (Cohen et al., 2020; Tarbouriech et al., 2020), we derive an algorithm that requires O(BD+D3/2S2A) time steps to collect the B=∑s,ab(s,a) desired samples, in any unknown and communicating MDP with S states, A actions and diameter D. Leveraging the generality of our strategy, we readily apply it to a variety of existing settings (e.g., model estimation, pure exploration in MDPs) for which we obtain improved sample-complexity guarantees, and to a set of new problems such as best-state identification and sparse reward discovery.</p></div></li>


<li>Jean Tarbouriech, Matteo Pirotta, <strong>Michal Valko</strong>, Alessandro Lazaric:
  <aa href="serve.php?what=publications/tarbouriech2020reward-free"><em>
Reward-free Exploration beyond finite-horizon</em></aa>, in 
<a href="https://wensun.github.io/rl_theory_workshop_2020_ICML.github.io/">Theoretical Foundations of RL Workshop @ ICML 2020</a>
 (<span class="conference-shortcut">ICML 2020 - RL Theory</span>)  
 	<a href="https://youtu.be/rDLaWSNAnqs">video</a> 
</li>


 

 <li>Omar Darwiche Domingues, Pierre Ménard, Matteo Pirotta,  Emilie Kaufmann, <strong>Michal Valko</strong>:
   <aa href="serve.php?what=publications/domingues2020regret"><em>
 Regret bounds for kernel-based reinforcement learning</em></aa>,  
  <a href="https://arxiv.org/abs/2004.05599">arXiv preprint</a>
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/domingues2020regret.bib">bibtex</a><a onclick="wipeToggle(&#39;domingues2020regret_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="domingues2020regret_abstract" style="display: none"> <p><em>  Abstract:</em>We consider the exploration-exploitation dilemma in finite-horizon reinforcement learning problems whose state-action space is endowed with a metric. We introduce Kernel-UCBVI, a model-based optimistic algorithm that leverages the smoothness of the MDP and a non-parametric kernel estimator of the rewards and transitions to efficiently balance exploration and exploitation. Unlike existing approaches with regret guarantees, it does not use any kind of partitioning of the state-action space. For problems with K episodes and horizon H, we provide a regret bound of O H 3 K max(1 2 , 2d 2d+1) , where d is the covering dimension of the joint state-action space. We empirically validate Kernel-UCBVI on discrete and continuous MDPs.</p></div> </li>



 
 


</ul>

<h2>2021</h2>
<ul class="publications-list">
	
	<li>Karl Tuyls, Shayegan Omidshafiei, Paul Muller, Zhe Wang, Jerome Connor, Daniel Hennes, Ian Graham, William Spearman, Tim Waskett, Dafydd Steele, Pauline Luc, Adria Recasens, Alexandre Galashov, Gregory Thornton, Romuald Elie, Pablo Sprechmann, Pol Moreno, Kris Cao, Marta Garnelo, Praneet Dutta, <strong>Michal Valko</strong>, Nicolas Heess, Alex Bridgland, Julien Perolat, Bart De Vylder, Ali Eslami, Mark Rowland, Andrew Jaegle, Remi Munos, Trevor Back, Razia Ahamed, Simon Bouton, Nathalie Beauguerlange, Jackson Broshear, Thore Graepel, Demis Hassabis:
	  <aa href="serve.php?what=publications/tuyls2021game"><em>
	Game plan: What AI can do for football, and what football can do for AI,</em></aa>
	accepted with minor revisions to 
		 <a href="https://www.jair.org/">Journal of Artificial Intelligence Research</a>
			  (<span class="conference-shortcut">JAIR 2021</span>)  
	  <a href="https://arxiv.org/abs/2011.09192">arXiv preprint</a>
		</li>	
	
	
	
	<li>Omar Darwiche Domingues, Pierre Ménard, Matteo Pirotta,  Emilie Kaufmann, <strong>Michal Valko</strong>:
	  <aa href="serve.php?what=publications/domingues2020kernel-based"><em>
	A kernel-based approach to non-stationary reinforcement learning in metric spaces</em></aa>, in 
	in <a href="http://www.aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
	 (<span class="conference-shortcut">AISTATS 2021</span>) and
	 (<span class="conference-shortcut-more">ICML 2020 - RL Theory</span>) 	 [<span style="color: #CC3333">oral - 6% acceptance rate</span>]
	 <a href="https://arxiv.org/abs/2007.05078">arXiv preprint</a>  
	 <a href="https://youtu.be/jJBpyPbyjQA">video</a> 
	 	
	
	</li><li>Omar Darwiche Domingues, Pierre Ménard,  Emilie Kaufmann, <strong>Michal Valko</strong>:
	  <aa href="serve.php?what=publications/domingues2020episodic"><em>
	Episodic reinforcement learning in finite MDPs: Minimax lower bounds revisited</em></aa>,
	 in  <a href="http://algorithmiclearningtheory.org/alt2021/">Algorithmic Learning Theory</a> 
	(<span class="conference-shortcut">ALT 2021</span>)
	  <a href="https://arxiv.org/abs/2010.03531">arXiv preprint</a>
	<a href="http://researchers.lille.inria.fr/~valko/hp/publications/domingues2020episodic.bib">bibtex</a><a onclick="wipeToggle(&#39;domingues2020episodic_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="domingues2020episodic_abstract" style="display: none"> <p><em>  Abstract:</em>In this paper, we propose new problem-independent lower bounds on the sample complexity and regret in episodic MDPs, with a particular focus on the non-stationary case in which the transition kernel is allowed to change in each stage of the episode. Our main contribution is a novel lower bound of Omega((H3SA/ϵ2)log(1/$\delta$)) on the sample complexity of an ($\epsilon$,$\delta$)-PAC algorithm for best policy identification in a non-stationary MDP. This lower bound relies on a construction of "hard MDPs" which is different from the ones previously used in the literature. Using this same class of MDPs, we also provide a rigorous proof of the Omega(sqrtH3SAT) regret bound for non-stationary MDPs. Finally, we discuss connections to PAC-MDP lower bounds.</p></div>	</li>
	
	
	<li>Jean Tarbouriech, Matteo Pirotta, <strong>Michal Valko</strong>, Alessandro Lazaric:
	  <aa href="serve.php?what=publications/tarbouriech2021sample"><em>
	Sample complexity bounds for stochastic shortest path with a generative model</em></aa>,
	 in  <a href="http://algorithmiclearningtheory.org/alt2021/">Algorithmic Learning Theory</a> 
	(<span class="conference-shortcut">ALT 2021</span>)   
	<!--? //php read_bib("tarbouriech2021sample");?-->
	</li>
	
    <li>Emilie Kaufmann, Pierre Ménard, Omar Darwiche Domingues, Anders Jonsson, Edouard Leurent, <strong>Michal Valko</strong>:
      <aa href="serve.php?what=publications/kaufmann2020adaptive"><em>
    Adaptive reward-free exploration</em></aa>, in 
      <a href="http://arxiv.org/abs/2006.06294">arXiv preprint</a>,
      <a href="https://youtu.be/BeuLl5_cTu0">video</a> 	  
	  in  <a href="http://algorithmiclearningtheory.org/alt2021/">Algorithmic Learning Theory</a>  
	   (<span class="conference-shortcut">ALT 2021</span>) and    (<span class="conference-shortcut">ICML 2020 - RL Theory</span>) 
	  
    <a href="http://researchers.lille.inria.fr/~valko/hp/publications/kaufmann2020adaptive.bib">bibtex</a><a onclick="wipeToggle(&#39;kaufmann2020adaptive_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="kaufmann2020adaptive_abstract" style="display: none"> <p><em>  Abstract:</em>Reward-free exploration is a reinforcement learning setting recently studied by Jin et al., who address it by running several algorithms with regret guarantees in parallel. In our work, we instead propose a more adaptive approach for reward-free exploration which directly reduces upper bounds on the maximum MDP estimation error. We show that, interestingly, our reward-free UCRL algorithm can be seen as a variant of an algorithm of Fiechter from 1994, originally proposed for a different objective that we call best-policy identification. We prove that RF-UCRL needs O((SAH4/$\epsilon$2)ln(1/$\delta$)) episodes to output, with probability 1−$\delta$, an $\epsilon$-approximation of the optimal policy for any reward function. We empirically compare it to oracle strategies using a generative model.</p></div>    </li>	
	

    <li>Guillaume Gautier, Rémi Bardenet, <strong>Michal Valko</strong>:
      <a href="https://rdcu.be/cdtIo"><em>
    Fast sampling from β-ensembles</em></a>,
	 <a href="https://www.springer.com/journal/11222">Statistics and Computing</a>  
	 (<span class="conference-shortcut">Statistics and Computing 2021</span>) 
   <a href="https://arxiv.org/abs/2003.02344">arXiv preprint</a>,
   <a href="http://researchers.lille.inria.fr/~valko/hp/publications/gautier2021fast.bib">bibtex</a> </li>

</ul>
<h2>2020</h2>
<ul class="publications-list">

<!-- <h2>preprints</h2>
<ul class="publications-list"> -->


<li>Jean-Bastien Grill, Florian Strub, Florent Altché, Corentin Tallec, Pierre H. Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Daniel Guo, Mohammad Gheshlaghi Azar, Bilal Piot, Koray Kavukcuoglu, Rémi Munos, <strong>Michal Valko</strong>:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/grill2020bootstrap"><em>
Bootstrap Your Own Latent: A new approach to self-supervised learning</em></a>,
in <a href="http://nips.cc/Conferences/2020/">Neural Information Processing Systems</a> 
   (<span class="conference-shortcut">NeurIPS 2020</span>)  <span style="color: #CC3333">oral - 1% acceptance rate</span>]
   
<ul>	   
<li> <a href="http://arxiv.org/abs/2006.07733">arXiv preprint</a> 
   <a href="http://researchers.lille.inria.fr/~valko/hp/publications/grill2020bootstrap.bib">bibtex</a><a onclick="wipeToggle(&#39;grill2020bootstrap_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="grill2020bootstrap_abstract" style="display: none"> <p><em>  Abstract:</em>We introduce Bootstrap Your Own Latent (BYOL), a new approach to self-supervised image representation learning. BYOL relies on two neural networks, referred to as online and target networks, that interact and learn from each other. From an augmented view of an image, we train the online network to predict the target network representation of the same image under a different augmented view. At the same time, we update the target network with a slow-moving average of the online network. While state-of-the art methods intrinsically rely on negative pairs, BYOL achieves a new state of the art without them. BYOL reaches 74.3 per cent top-1 classification accuracy on ImageNet using the standard linear evaluation protocol with a ResNet-50 architecture and 79.6 per cent; with a larger ResNet. We show that BYOL performs on par or better than the current state of the art on both transfer and semi-supervised benchmarks.</p></div> </li>
<li><a href="https://twitter.com/DeepMind/status/1272810643222126594">our twitter announcement</a>
and <a href="https://github.com/deepmind/deepmind-research/tree/master/byol">our code</a> </li>
<li> <a href="https://youtu.be/YPfUiOMYOEE">youtube video by Yannic</a>, <a href="https://towardsdatascience.com/easy-self-supervised-learning-with-byol-53b8ad8185d">unoffical blog 1</a> and <a href="https://medium.com/swlh/neural-networks-intuitions-10-byol-paper-explanation-f8b1d6e83b1c">unoffical blog 2</a> 

</li> 
</ul>

</li><li>Pierre H. Richemond, Jean-Bastien Grill, Florent Altché, Corentin Tallec, Florian Strub, Andrew Brock, Samuel Smith, Soham De, Razvan Pascanu, Bilal Piot, <strong>Michal Valko</strong>:
  <aa href="serve.php?what=publications/richemond2020byol"><em>
BYOL works even without batch statistics</em></aa>,
in <a href="https://sslneuips20.github.io/">NeurIPS 2020 Workshop: Self-Supervised Learning - Theory and Practice</a> 
  <a href="https://arxiv.org/abs/2010.10241">arXiv preprint</a> 
  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/richemond2020byol.bib">bibtex</a><a onclick="wipeToggle(&#39;richemond2020byol_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="richemond2020byol_abstract" style="display: none"> <p><em>  Abstract:</em>Bootstrap Your Own Latent (BYOL) is a self-supervised learning approach for image representation. From an augmented view of an image, BYOL trains an online network to predict a target network representation of a different augmented view of the same image. Unlike contrastive methods, BYOL does not explicitly use a repulsion term built from negative pairs in its training objective. Yet, it avoids collapse to a trivial, constant representation. Thus, it has recently been hypothesized that batch normalization (BN) is critical to prevent collapse in BYOL. Indeed, BN flows gradients across batch elements, and could leak information about negative views in the batch, which could act as an implicit negative (contrastive) term. However, we experimentally show that replacing BN with a batch-independent normalization scheme (namely, a combination of group normalization and weight standardization) achieves performance comparable to vanilla BYOL ({\$</p></div></li>	


<li>Jean Tarbouriech, Matteo Pirotta, <strong>Michal Valko</strong>, Alessandro Lazaric:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/tarbouriech2020improved"><em>
Improved sample complexity for incremental autonomous exploration in MDPs</em></a>, 
in <a href="http://nips.cc/Conferences/2020/">Neural Information Processing Systems</a> 
   (<span class="conference-shortcut">NeurIPS 2020</span>)   <span style="color: #CC3333">oral - 1% acceptance rate</span>]
     <a href="https://arxiv.org/abs/2012.14755">arXiv preprint</a> 
<a href="http://researchers.lille.inria.fr/~valko/hp/publications/tarbouriech2020improved.bib">bibtex</a><a onclick="wipeToggle(&#39;tarbouriech2020improved_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="tarbouriech2020improved_abstract" style="display: none"> <p><em>  Abstract:</em>We investigate the exploration of an unknown environment when no reward function is provided. Building on the incremental exploration setting introduced by Lim and Auer [1], we define the objective of learning the set of ϵ-optimal goal-conditioned policies attaining all states that are incrementally reachable within L steps (in expectation) from a reference state s0. In this paper, we introduce a novel model-based approach that interleaves discovering new states from s0 and improving the accuracy of a model estimate that is used to compute goal-conditioned policies to reach newly discovered states. The resulting algorithm, DisCo, achieves a sample complexity scaling as Õ (L5SL+ϵ$\Gamma$L+ϵAϵ−2), where A is the number of actions, SL+ϵ is the number of states that are incrementally reachable from s0 in L+ϵ steps, and $\Gamma$L+ϵ is the branching factor of the dynamics over such states. This improves over the algorithm proposed in [1] in both ϵ and L at the cost of an extra $\Gamma$L+ϵ factor, which is small in most environments of interest. Furthermore, DisCo is the first algorithm that can return an ϵ/cmin-optimal policy for any cost-sensitive shortest-path problem defined on the L-reachable states with minimum cost cmin. Finally, we report preliminary empirical results confirming our theoretical findings.</p></div></li>

<li>Daniele Calandriello*, Michał Dereziński*, <strong>Michal Valko</strong>:
  <aa href="serve.php?what=publications/calandriello2020sampling.pdf"><em>
Sampling from a k-DPP without looking at all items</em></aa>,
in <a href="http://nips.cc/Conferences/2020/">Neural Information Processing Systems</a>  
   (<span class="conference-shortcut">NeurIPS 2020</span>)  <span style="color: #CC3333">spotlight - 3% acceptance rate</span>] 
    <a href="http://arxiv.org/abs/2006.16947">arXiv preprint</a>
 <!--   <a href="serve.php?what=publications/calandriello2020sampling.talk.pdf">talk</a> -->
 <!-- <a href="serve.php?what=publications/derezinski2019exact.poster.pdf">poster</a> -->
    <!--  <a href="publications/calandriello2020sampling.bib">bibtex</a> -->
</li>

<li>Pierre Perrault, Etienne Boursier, Vianney Perchet, <strong>Michal Valko</strong>:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/perrault2020statistical"><em>
Statistical efficiency of Thompson sampling for combinatorial semi-bandits</em></a>, 
in <a href="http://nips.cc/Conferences/2020/">Neural Information Processing Systems</a>  
   (<span class="conference-shortcut">NeurIPS 2020</span>)  
 <a href="http://arxiv.org/abs/2006.06613">arXiv preprint</a>
<a href="http://researchers.lille.inria.fr/~valko/hp/publications/perrault2020statistical.bib">bibtex</a><a onclick="wipeToggle(&#39;perrault2020statistical_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="perrault2020statistical_abstract" style="display: none"> <p><em>  Abstract:</em>We investigate stochastic combinatorial multi-armed bandit with semi-bandit feedback (CMAB). In CMAB, the question of the existence of an efficient policy with an optimal asymptotic regret (up to a factor poly-logarithmic with the action size) is still open for many families of distributions, including mutually independent outcomes, and more generally the multivariate sub-Gaussian family. We propose to answer the above question for these two families by analyzing variants of the Combinatorial Thompson Sampling policy (CTS). For mutually independent outcomes in [0,1] , we propose a tight analysis of CTS using Beta priors. We then look at the more general setting of multivariate sub-Gaussian outcomes and propose a tight analysis of CTS using Gaussian priors. This last result gives us an alternative to the Efficient Sampling for Combinatorial Bandit policy (ESCB), which, although optimal, is not computationally efficient.</p></div></li>	



	
<li>Anders Jonsson, Emilie Kaufmann, Pierre Ménard, Omar Darwiche Domingues, Edouard Leurent, <strong>Michal Valko</strong>:
  <aa href="serve.php?what=publications/jonsson2020planning"><em>
Planning in Markov decision processes with gap-dependent sample complexity</em></aa>,  
in <a href="http://nips.cc/Conferences/2020/">Neural Information Processing Systems</a>  
   (<span class="conference-shortcut">NeurIPS 2020</span>) 
 <a href="https://arxiv.org/abs/2006.05879">arXiv preprint</a>
<a href="http://researchers.lille.inria.fr/~valko/hp/publications/jonsson2020planning.bib">bibtex</a><a onclick="wipeToggle(&#39;jonsson2020planning_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="jonsson2020planning_abstract" style="display: none"> <p><em>  Abstract:</em>We propose MDP-GapE, a new trajectory-based Monte-Carlo Tree Search algorithm for planning in a Markov Decision Process in which transitions have a finite support. We prove an upper bound on the number of calls to the generative models needed for MDP-GapE to identify a near-optimal action with high probability. This problem-dependent sample complexity result is expressed in terms of the sub-optimality gaps of the state-action pairs that are visited during exploration. Our experiments reveal that MDP-GapE is also effective in practice, in contrast with other algorithms with sample complexity guarantees in the fixed-confidence setting, that are mostly theoretical.</p></div></li>	
	


<li>
Jean-Bastien Grill, Florent Altché, Yunhao Tang, Thomas Hubert, <strong>Michal Valko</strong>, Ioannis Antonoglou, Rémi Munos:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/grill2020monte-carlo.pdf"><em>
Monte-Carlo tree search as regularized policy optimization</em></a>,  
  in <a href="https://icml.cc/Conferences/2020">International Conference on Machine Learning</a> (<span class="conference-shortcut">ICML 2020</span>)
     <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/grill2020monte-carlo.talk.pdf">talk</a>
	 <a href="https://arxiv.org/abs/2007.12509">arXiv preprint</a> 
	  <a href="https://icml.cc/virtual/2020/poster/6380">video</a> 
	   <a href="http://researchers.lille.inria.fr/~valko/hp/publications/grill2020monte-carlo.bib">bibtex</a><a onclick="wipeToggle(&#39;grill2020monte-carlo_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="grill2020monte-carlo_abstract" style="display: none"> <p><em>  Abstract:</em>The combination of Monte-Carlo tree search (MCTS) with deep reinforcement learning has led to groundbreaking results in artificial intelligence. However, AlphaZero, the current state-of-the-art MCTS algorithm still relies on handcrafted heuristics that are only partially understood. In this paper, we show that AlphaZero's search heuristic, along with other common ones, can be interpreted as an approximation to the solution of a specific regularized policy optimization problem. With this insight, we propose a variant of AlphaZero which uses the exact solution to this policy optimization problem, and show experimentally that it reliably outperforms the original algorithm in multiple domains.</p></div></li>

<li>Yunhao Tang, <strong>Michal Valko</strong>, Rémi Munos:
  <aa href="serve.php?what=publications/tang2020taylor.pdf"><em>
Taylor expansion policy optimization</em></aa>,  
  in <a href="https://icml.cc/Conferences/2020">International Conference on Machine Learning</a> (<span class="conference-shortcut">ICML 2020</span>)
  and (<span class="conference-shortcut-more">MS RL Day 2021</span>)
  <a href="https://arxiv.org/abs/2003.06259">arXiv preprint</a>
      <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/tang2020taylor.talk.pdf">talk</a> 
	    <!-- <a href="publications/tang2020taylor.bib">bibtex</a><a onclick="wipeToggle('tang2020taylor_abstract')"> abstract <img src="images/text.gif" alt="abstract" /></a><div id="tang2020taylor_abstract" style="display: none"> <p><em>  Abstract:</em>In this work, we investigate the application of Taylor expansions in reinforcement learning. In particular, we propose Taylor expansion policy optimization , a policy optimization formalism that generalizes prior work (e.g., TRPO) as a first-order special case. We also show that Taylor expansions intimately relate to off-policy evaluation. Finally, we show that this new formulation entails modifications which improve the performance of several state-of-the-art distributed algorithms.</p></div>-->
</li>


<li>Rémy Degenne, Pierre Ménard, Xuedong Shang, <strong>Michal Valko</strong>:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/degenne2020gamification.pdf"><em>
Gamification of pure exploration for linear bandits</em></a>,  
  in <a href="https://icml.cc/Conferences/2020">International Conference on Machine Learning</a> (<span class="conference-shortcut">ICML 2020</span>)
    <a href="https://arxiv.org/abs/2007.00953">arXiv preprint</a>
       <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publicationations/degenne2020gamification.talk.pdf">talk</a> 
	     <a href="http://researchers.lille.inria.fr/~valko/hp/publications/degenne2020gamification.bib">bibtex</a> 
</li>
 

<li>Pierre Perrault, Zheng Wen, Jennifer Healey, <strong>Michal Valko</strong>:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/perrault2020budgeted.pdf"><em>
Budgeted online influence maximization</em></a>,  
  in <a href="https://icml.cc/Conferences/2020">International Conference on Machine Learning</a> (<span class="conference-shortcut">ICML 2020</span>)
    <a href="https://icml.cc/virtual/2020/poster/6378">video</a> 
  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/perrault2020budgeted.bib">bibtex</a><a onclick="wipeToggle(&#39;perrault2020budgeted_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="perrault2020budgeted_abstract" style="display: none"> <p><em>  Abstract:</em>We introduce a new budgeted framework for online influence maximization, considering the total cost of an advertising campaign instead of the common cardinality constraint on a chosen influencer set. Our approach models better the real-world setting where the cost of influencers varies and advertizers want to find the best value for their overall social advertising budget. We propose an algorithm assuming an independent cascade diffusion model and edge-level semi-bandit feedback, and provide both theoretical and experimental results. Our analysis is also valid for the cardinality-constraint setting and improves the state of the art regret bound in this case.</p></div></li>

<li>Jean Tarbouriech, Evrard Garcelon, <strong>Michal Valko</strong>, Matteo Pirotta, Alessandro Lazaric:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/tarbouriech2020no-regret.pdf"><em>
No-regret exploration in goal-oriented reinforcement learning</em></a>, 
  in <a href="https://icml.cc/Conferences/2020">International Conference on Machine Learning</a> (<span class="conference-shortcut">ICML 2020</span>) 
  <a href="https://arxiv.org/abs/1912.03517">arXiv preprint</a>
    <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/tarbouriech2020no-regret.talk.pdf">talk</a> 
  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/tarbouriech2020no-regret.bib">bibtex</a><a onclick="wipeToggle(&#39;tarbouriech2020no-regret_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="tarbouriech2020no-regret_abstract" style="display: none"> <p><em>  Abstract:</em>Many popular reinforcement learning problems (e.g., navigation in a maze, some Atari games, mountain car) are instances of the episodic setting under its stochastic shortest path (SSP) formulation, where an agent has to achieve a goal state while minimizing the cumulative cost. Despite the popularity of this setting, the exploration-exploitation dilemma has been sparsely studied in general SSP problems, with most of the theoretical literature focusing on different problems (i.e., fixed-horizon and infinite-horizon) or making the restrictive loop-free SSP assumption (i.e., no state can be visited twice during an episode). In this paper, we study the general SSP problem with no assumption on its dynamics (some policies may actually never reach the goal). We introduce UC-SSP, the first no-regret algorithm in this setting, and prove a regret bound scaling as O(DSsqrt(ADK)) after K episodes for any unknown SSP with S states, A actions, positive costs and SSP-diameter D, defined as the smallest expected hitting time from any starting state to the goal. We achieve this result by crafting a novel stopping rule, such that UC-SSP may interrupt the current policy if it is taking too long to achieve the goal and switch to alternative policies that are designed to rapidly terminate the episode.</p></div></li>

   <li>Aadirupa Saha, Pierre Gaillard, <strong>Michal Valko</strong>:
     <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/saha2020improved.pdf"><em>
   Improved sleeping bandits with stochastic action sets and adversarial rewards</em></a>,
     in <a href="https://icml.cc/Conferences/2020">International Conference on Machine Learning</a> (<span class="conference-shortcut">ICML 2020</span>)
  <a href="https://arxiv.org/abs/2004.06248">arXiv preprint</a>
      <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/saha2020improved.talk.pdf">talk</a> 
  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/saha2020improved.bib">bibtex</a><a onclick="wipeToggle(&#39;saha2020improved_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="saha2020improved_abstract" style="display: none"> <p><em>  Abstract:</em>In this paper, we consider the problem of sleeping bandits with stochastic action sets and adversarial rewards. In this setting, in contrast to most work in bandits, the actions may not be available at all times. For instance, some products might be out of stock in item recommendation. The best existing efficient (i.e., polynomial-time) algorithms for this problem only guarantee a O(T**2/3) upper-bound on the regret. Yet, inefficient algorithms based on EXP4 can achieve O(sqrt(T)). In this paper, we provide a new computationally efficient algorithm inspired by EXP3 satisfying a regret of order O(sqrt(T)) when the availabilities of each action i in A are independent. We then study the most general version of the problem where at each round available sets are generated from some unknown arbitrary distribution (i.e., without the independence assumption) and propose an efficient algorithm with O(sqrt(2**KT)) regret guarantee. Our theoretical results are corroborated with experimental evaluations.</p></div></li>


<li>Anne Manegueu, Claire Vernade, Alexandra Carpentier, <strong>Michal Valko</strong>:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/manegueu2020stochastic.pdf"><em>
Stochastic bandits with arm-dependent delays</em></a>,  
  in <a href="https://icml.cc/Conferences/2020">International Conference on Machine Learning</a> (<span class="conference-shortcut">ICML 2020</span>) and
  (<span class="conference-shortcut-more">GPSD 2020</span>) and 
   (<span class="conference-shortcut-more">WiML 2019</span>)
     <a href="https://arxiv.org/abs/2006.10459">arXiv preprint</a>
  	<a href="https://icml.cc/virtual/2020/poster/6140">video</a>	 	 
   <a href="http://researchers.lille.inria.fr/~valko/hp/publications/manegueu2020stochastic.bib">bibtex</a><a onclick="wipeToggle(&#39;manegueu2020stochastic_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="manegueu2020stochastic_abstract" style="display: none"> <p><em>  Abstract:</em>Significant work has been recently dedicated to the stochastic delayed bandit setting because of its relevance in applications. The applicability of existing algorithms is however restricted by the fact that strong assumptions are often made on the delay distributions, such as full observability, restrictive shape constraints, or uniformity over arms. In this work, we weaken them significantly and only assume that there is a bound on the tail of the delay. In particular, we cover the important case where the delay distributions vary across arms, and the case where the delays are heavy-tailed. Addressing these difficulties, we propose a simple but efficient UCB-based algorithm called the PATIENTBANDITS. We provide both problem-dependent and problem-independent bounds on the regret as well as performance lower bounds.</p></div>

 </li><li>Daniele Calandriello, Luigi Carratino, Alessandro Lazaric, <strong>Michal Valko</strong>, Lorenzo Rosasco:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2020near-linear.pdf"><em>
Near-linear time Gaussian process optimization with adaptive batching and resparsification</em></a>, 
   in <a href="https://icml.cc/Conferences/2020">International Conference on Machine Learning</a> (<span class="conference-shortcut">ICML 2020</span>) and
   (<span class="conference-shortcut-more">OPT 2019</span>)
    <a href="https://arxiv.org/abs/2002.09954">arXiv preprint</a>
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2020near-linear.talk.pdf">talk</a>
 <!--  <a href="serve.php?what=publications/calandriello2020near-linear.poster.pdf">poster</a> -->
    <a href="http://researchers.lille.inria.fr/~valko/hp/publications/calandriello2020near-linear.bib">bibtex</a><a onclick="wipeToggle(&#39;calandriello2020near-linear_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="calandriello2020near-linear_abstract" style="display: none"> <p><em>  Abstract:</em>Gaussian processes (GP) are one of the most successful frameworks to model uncertainty. However , GP optimization (e.g., GP-UCB) suffers from major scalability issues. Experimental time grows linearly with the number of evaluations, unless candidates are selected in batches (e.g., using GP-BUCB) and evaluated in parallel. Furthermore , computational cost is often prohibitive since algorithms such as GP-BUCB require a time at least quadratic in the number of dimensions and iterations to select each batch. In this paper, we introduce BBKB (Batch Budgeted Kernel Bandits), the first no-regret GP optimization algorithm that provably runs in near-linear time and selects candidates in batches. This is obtained with a new guarantee for the tracking of the posterior variances that allows BBKB to choose increasingly larger batches, improving over GP-BUCB. Moreover , we show that the same bound can be used to adaptively delay costly updates to the sparse GP approximation used by BBKB, achieving a near-constant per-step amortized cost. These findings are then confirmed in several experiments, where BBKB is much faster than state-of-the-art methods.</p></div></li>



<li>Pierre Perrault, Vianney Perchet, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/perrault2020covariance-adapting.pdf">
<em>
Covariance-adapting algorithm for semi-bandits with application to sparse rewards</em></a>,
  in <a href="http://www.learningtheory.org/colt2020/"> Conference on Learning Theory</a>
   (<span class="conference-shortcut">COLT 2020</span>),
   	<a href="https://www.colt2020.org/virtual/papers/paper_251.html">video</a>
<!--
  <a href="serve.php?what=publications/perrault2020covariance-adapting.talk.pdf">talk</a>
	
  <a href="serve.php?what=publications/perrault2020covariance-adapting.poster.pdf">poster</a>
 -->
	 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/perrault2020covariance-adapting.bib">bibtex</a><a onclick="wipeToggle(&#39;perrault2020covariance-adapting_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="perrault2020covariance-adapting_abstract" style="display: none"> <p><em>  Abstract:</em>We investigate stochastic combinatorial semi-bandits, where the entire joint distribution of rewards impacts the complexity of the problem instance (unlike in the standard bandits). Typical distributions considered depend on specific parameter values, whose prior knowledge is required in theory but quite difficult to estimate in practice; an example is the commonly assumed sub-Gaussian family. We alleviate this issue by instead considering a new general family of sub-exponential distributions, which contains bounded and Gaussian ones. We prove a new lower bound on the expected regret on this family, that is parameterized by the unknown covariance matrix of rewards, a tighter quantity than the sub-Gaussian matrix. We then construct an algorithm that uses covariance estimates, and provide a tight asymptotic analysis of the regret. Finally, we apply and extend our results to the family of sparse rewards, which has applications in many recommender systems.</p></div></li>






<li>Xuedong Shang, Rianne de Heide,  Emilie Kaufmann, Pierre Ménard, <strong>Michal Valko</strong>:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/shang2020fixed-confidence.pdf"><em>
Fixed-confidence guarantees for Bayesian best-arm identification</em></a>,  
in <a href="http://www.aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2020</span>)
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/shang2020fixed-confidence.talk.pdf">talk</a>

 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/shang2020fixed-confidence.bib">bibtex</a><a onclick="wipeToggle(&#39;shang2020fixed-confidence_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="shang2020fixed-confidence_abstract" style="display: none"> <p><em>  Abstract:</em>We investigate and provide new insights on the sampling rule called Top-Two Thompson Sampling (TTTS). In particular, we justify its use for fixed-confidence best-arm identification. We further propose a variant of TTTS called Top-Two Transportation Cost (T3C), which disposes of the computational burden of TTTS. As our main contribution, we provide the first sample complexity analysis of TTTS and T3C when coupled with a very natural Bayesian stopping rule, for bandits with Gaussian rewards, solving one of the open questions raised by Russo (2016). We also provide new posterior convergence results for TTTS under two models that are commonly used in practice: bandits with Gaussian and Bernoulli rewards and conjugate priors.</p></div> 
 <!--
   <a href="serve.php?what=publications/shang2019simple.talk.pdf">talk</a> 
   <a href="serve.php?what=publications/shang2020fixed-confidence.poster.pdf">poster</a>  
     <a href="serve.php?what=publications/shang2020fixed-confidence.code.zip">code</a>
   --> 
   <a href="https://arxiv.org/abs/1910.10945">arXiv preprint</a>
</li>

<li>Côme Fiegel, Victor Gabillon, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/fiegel2020adaptive.pdf">
<em>
Adaptive multi-fidelity optimization with fast learning rates</em></a>
in <a href="http://www.aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2020</span>)
     <a href="http://researchers.lille.inria.fr/~valko/hp/publications/fiegel2020adaptive.bib">bibtex</a><a onclick="wipeToggle(&#39;fiegel2020adaptive_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="fiegel2020adaptive_abstract" style="display: none"> <p><em>  Abstract:</em>In multi-fidelity optimization, biased approximations of varying costs of the target function are available. This paper studies the problem of optimizing a locally smooth function with a limited budget, where the learner has to make a tradeoff between the cost and the bias of these approximations. We first prove lower bounds for the simple regret under different assumptions on the fidelities, based on a cost-to-bias function. We then present the Kometo algorithm which achieves, with additional logarithmic factors, the same rates without any knowledge of the function smoothness and fidelity assumptions, and improves previously proven guarantees. We finally empirically show that our algorithm outperforms previous multi-fidelity optimization methods without the knowledge of problem-dependent parameters.</p></div>     <!--
 <a href="https://slideslive.com/38917632/online-learning-2">video</a>
  <a href="serve.php?what=publications/bartlett2019scale-free.talk.pdf">talk</a>
  <a href="serve.php?what=publications/bartlett2019scale-free.poster.pdf">poster</a> 
</li>
 --> 

 </li><li>Victor Gabillon, Rasul Tutunov, <strong>Michal Valko</strong>, Haitham Bou Ammar:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/gabillon2020derivative-free.pdf">
<em>
Derivative-free &amp; order-robust optimisation</em></a>
in <a href="http://www.aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2020</span>)
     <a href="http://researchers.lille.inria.fr/~valko/hp/publications/gabillon2020derivative-free.bib">bibtex</a><a onclick="wipeToggle(&#39;gabillon2020derivative-free_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="gabillon2020derivative-free_abstract" style="display: none"> <p><em>  Abstract:</em>In this paper, we formalise order-robust optimisation as an instance of online learning minimising simple regret, and propose Vroom, a zero'th order optimisation algorithm capable of achieving vanishing regret in non-stationary environments, while recovering favorable rates under stochastic reward-generating processes. Our results are the first to target simple regret definitions in adversarial scenarios unveiling a challenge that has been rarely considered in prior work.</p></div>     <!--
 <a href="https://slideslive.com/38917632/online-learning-2">video</a>  --> 
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/gabillon2020derivative-free.talk.pdf">talk</a> 
    <!-- <a href="serve.php?what=publications/gabillon2020derivative-free".poster.pdf">poster</a> 
</li>
 --> 

</li><li> Julien Seznec, Pierre Ménard, Alessandro Lazaric, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/seznec2020single.pdf"><em>A single algorithm for both restless and rested rotting bandits</em></a>, 
 in <a href="http://www.aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2020</span>)
  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/seznec2020single.bib">bibtex</a><a onclick="wipeToggle(&#39;seznec2020single_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="seznec2020single_abstract" style="display: none"> <p><em>  Abstract:</em>In many application domains (e.g., recommender systems, intelligent tutoring systems), the rewards associated to the available actions tend to decrease over time. This decay is either caused by the actions executed in the past (e.g., a user may get bored when songs of the same genre are recommended over and over) or by an external factor (e.g., content becomes outdated). These two situations can be modeled as specific instances of the rested and restless bandit settings, where arms are rotting (i.e., their value decrease over time). These problems were thought to be significantly different, since Levine et al. (2017) showed that state-of-the-art algorithms for restless bandit perform poorly in the rested rotting setting. In this paper, we introduce a novel algorithm, Rotting Adaptive Window UCB (RAW-UCB), that achieves near-optimal regret in both rotting rested and restless bandit, without any prior knowledge of the setting (rested or restless) and the type of non-stationarity (e.g., piece-wise constant, bounded variation). This is in striking contrast with previous negative results showing that no algorithm can achieve similar results as soon as rewards are allowed to increase. We confirm our theoretical findings on a number of synthetic and dataset-based experiments.</p></div>  
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/seznec2020single.talk.pdf">talk</a> 
   <!--   <a href="serve.php?what=publications/seznec2020single.poster.pdf">poster</a>
   [<span style="color: #CC3333">full oral presentation</span> - 2.5% acceptance rate]
 -->
</li>





<li>Tomáš Kocák, Rémi Munos, Branislav Kveton, Shipra Agrawal, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kocak2020spectral.pdf">
<em>Spectral Bandits</em></a>, 
<a href="http://www.jmlr.org/"> Journal of Machine Learning Research</a>
 (<span class="conference-shortcut">JMLR 2020</span>) 
  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/kocak2020spectral.bib">bibtex</a><a onclick="wipeToggle(&#39;kocak2020spectral_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="kocak2020spectral_abstract" style="display: none"> <p><em>  Abstract:</em>Smooth functions on graphs have wide applications in manifold and semi-supervised learning. In this work, we study a bandit problem where the payoffs of arms are smooth on a graph. This framework is suitable for solving online learning problems that involve graphs, such as content-based recommendation. In this problem, each item we can recommend is a node of an undirected graph and its expected rating is similar to the one of its neighbors. The goal is to recommend items that have high expected ratings. We aim for the algorithms where the cumulative regret with respect to the optimal policy would not scale poorly with the number of nodes. In particular, we introduce the notion of an effective dimension, which is small in real-world graphs, and propose three algorithms for solving our problem that scale linearly and sublinearly in this dimension. Our experiments on content recommendation problem show that a good estimator of user preferences for thousands of items can be learned from just tens of node evaluations.</p></div> 
</li>

<li>Branislav Kveton, Zheng Wen, Azin Ashkan, <strong>Michal Valko</strong>:
 <aa href="serve.php?what=publications/kveton2016learning.pdf"><em>Learning to Act Greedily: Polymatroid Semi-Bandits</em></aa>, 
accepted for publication to <a href="http://www.jmlr.org/">Journal of Machine Learning Research</a>
 (<span class="conference-shortcut">JMLR 2020</span>)    
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/kveton2016learning.bib">bibtex</a><a onclick="wipeToggle(&#39;kveton2016learning_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="kveton2016learning_abstract" style="display: none"> <p><em>  Abstract:</em>Many important optimization problems, such as the minimum spanning tree and minimum-cost flow, can be solved optimally by a greedy method. In this work, we study a learning variant of these problems, where the model of the problem is unknown and has to be learned by interacting repeatedly with the environment in the bandit setting. We formalize our learning problem quite generally, as learning how to maximize an unknown modular function on a known polymatroid. We propose a computationally efficient algorithm for solving our problem and bound its expected cumulative regret. Our gap-dependent upper bound is tight up to a constant and our gap-free upper bound is tight up to polylogarithmic factors. Finally, we evaluate our method on three problems and demonstrate that it is practical.</p></div> 
 <a href="http://arxiv.org/abs/1405.7752">arXiv preprint</a>
  <!-- <a href="serve.php?what=publications/kveton2016learning.talk.pdf">talk</a> -->
  <!-- <a href="serve.php?what=publications/kveton2016learning.poster.pdf">poster</a> -->
</li>

</ul>

<h2>2019</h2>
<ul class="publications-list">

 

<li>Jean-Bastien Grill*, Omar Darwiche Domingues*, Pierre Ménard,  Rémi Munos, <strong>Michal Valko</strong>:
 <aa href="serve.php?what=publications/grill2019planning.pdf"><em>Planning in entropy-regularized Markov decision processes and games</em>, 
in <a href="http://nips.cc/Conferences/2019/">Neural Information Processing Systems</a> 
   (<span class="conference-shortcut">NeurIPS 2019</span>)
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/grill2019planning.bib">bibtex</a> 
  <!--
   <a href="serve.php?what=publications/grill2016blazing.talk.pdf">talk</a> 
       
  <a href="serve.php?what=publications/grill2018optimistic.poster.pdf">poster</a> -->
</aa></li>

<li>Mark Rowland, Shayegan Omidshafiei, Karl Tuyls, Julien Pérolat,  <strong>Michal Valko</strong>, Georgios Piliouras, Rémi Munos:
 <aa href="serve.php?what=publications/grill2019planning.pdf"><em>Multiagent evaluation under incomplete information</em>, 
in <a href="http://nips.cc/Conferences/2019/">Neural Information Processing Systems</a> 
   (<span class="conference-shortcut">NeurIPS 2019</span>)
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/rowland2019multiagent.bib">bibtex</a> 
  <!--
   <a href="serve.php?what=publications/grill2016blazing.talk.pdf">talk</a> 
       
  <a href="serve.php?what=publications/grill2018optimistic.poster.pdf">poster</a> -->
</aa></li>



<li>Michał Dereziński*, Daniele Calandriello*, <strong>Michal Valko</strong>:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/derezinski2019exact.pdf"><em>
Exact sampling of determinantal point processes with sublinear time preprocessing</em></a>,
     in <a href="http://nips.cc/Conferences/2019/">Neural Information Processing Systems</a> 
   (<span class="conference-shortcut">NeurIPS 2019</span>)   and
   (<span class="conference-shortcut-more">ICML 2019 - NEGDEP</span>)
   <a href="http://researchers.lille.inria.fr/~valko/hp/publications/derezinski2019exact.bib">bibtex</a><a onclick="wipeToggle(&#39;derezinski2019exact_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="derezinski2019exact_abstract" style="display: none"> <p><em>  Abstract:</em>We study the complexity of sampling from a distribution over all index subsets of the set (1,...,n) with the probability of a subset S proportional to the determinant of the submatrix LS of some n x n p.s.d. matrix L, where LS corresponds to the entries of L indexed by S. Known as a determinantal point process, this distribution is used in machine learning to induce diversity in subset selection. In practice, we often wish to sample multiple subsets S with small expected size k = E[card(S)] that is much smaller then n from a very large matrix L, so it is important to minimize the preprocessing cost of the procedure (performed once) as well as the sampling cost (performed repeatedly). For this purpose, we propose a new algorithm which, given access to L, samples exactly from a determinantal point process while satisfying the following two properties: (1) its preprocessing cost is n x poly(k) (sublinear in the size of L) and (2) its sampling cost is poly(k) (independent of the size of L). Prior to our results, state-of-the-art exact samplers required O(n3) preprocessing time and sampling time linear in n or dependent on the spectral properties of L. We also give a reduction which allows using our algorithm for sampling from cardinality constrained determinantal point processes with n x poly(k) time preprocessing.</p></div> 
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/derezinski2019exact.talk.pdf">talk</a>
 <!-- <a href="serve.php?what=publications/derezinski2019exact.poster.pdf">poster</a> -->
<a href="https://slideslive.com/38917381/exact-sampling-of-determinantal-point-processes-with-sublinear-time-preprocessing">video</a>
</li>

   <li>Guillaume Gautier, Rémi Bardenet, <strong>Michal Valko</strong>:
     <aa href="serve.php?what=publications/gautier2019two.pdf"><em>
   On two ways to use determinantal point processes for Monte Carlo integration</em></aa>,
   in <a href="http://nips.cc/Conferences/2019/">Neural Information Processing Systems</a> 
   (<span class="conference-shortcut">NeurIPS 2019</span>)   and
   (<span class="conference-shortcut-more">ICML 2019 - NEGDEP</span>)  
    <a href="http://researchers.lille.inria.fr/~valko/hp/publications/gautier2019two.bib">bibtex</a>  
 <a href="https://slideslive.com/38917386/on-two-ways-to-use-determinantal-point-processes-for-monte-carlo-integration">video</a>
</li>






<li>Daniele Calandriello, Luigi Carratino, Alessandro Lazaric, <strong>Michal Valko</strong>, Lorenzo Rosasco:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2019gaussian.pdf"><em>
Gaussian process optimization with adaptive sketching: Scalable and no regret</em></a>, in
  <a href="http://www.learningtheory.org/colt2019/"> Conference on Learning Theory</a>
   (<span class="conference-shortcut">COLT 2019</span>) and (<span class="conference-shortcut-more">ICML 2019 - NEGDEP</span>)
   and (<span class="conference-shortcut-more">SWSL 2019</span>)
   <a href="http://researchers.lille.inria.fr/~valko/hp/publications/calandriello2019gaussian.bib">bibtex</a><a onclick="wipeToggle(&#39;calandriello2019gaussian_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="calandriello2019gaussian_abstract" style="display: none"> <p><em>  Abstract:</em>Gaussian processes (GP) are a popular Bayesian approach for the optimization of black-box functions. Despite their effectiveness in simple problems, GP-based algorithms hardly scale to complex high-dimensional functions, as their per-iteration time and space cost is at least quadratic in the number of dimensions d and iterations t. Given a set of A alternative to choose from, the overall runtime O(t3A) quickly becomes prohibitive. In this paper, we introduce BKB (budgeted kernelized bandit), a novel approximate GP algorithm for optimization under bandit feedback that achieves near-optimal regret (and hence near-optimal convergence rate) with near-constant per-iteration complexity and no assumption on the input space or covariance of the GP. Combining a kernelized linear bandit algorithm (GP-UCB) with randomized matrix sketching technique (i.e., leverage score sampling), we prove that selecting inducing points based on their posterior variance gives an accurate low-rank approximation of the GP, preserving variance estimates and confidence intervals. As a consequence, BKB does not suffer from variance starvation, an important problem faced by many previous sparse GP approximations. Moreover, we show that our procedure selects at most Õ (deff) points, where deff is the effective dimension of the explored space, which is typically much smaller than both d and t. This greatly reduces the dimensionality of the problem, thus leading to a O(TAd2eff) runtime and O(Adeff) space complexity.</p></div> <a href="https://slideslive.com/38917391/gaussian-process-optimization-with-adaptive-sketching-scalable-and-no-regret">video</a>
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2019gaussian.talk.pdf">talk</a>
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2019gaussian.poster.pdf">poster</a> 
</li>



<li>Peter Bartlett, Victor Gabillon, Jennifer Healey, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/bartlett2019scale-free.pdf">
<em>
Scale-free adaptive planning for deterministic dynamics &amp; discounted rewards</em></a>
  in <a href="https://icml.cc/Conferences/2019">International Conference on Machine Learning</a> 
   (<span class="conference-shortcut">ICML 2019</span>)
     <a href="http://researchers.lille.inria.fr/~valko/hp/publications/bartlett2019scale-free.bib">bibtex</a><a onclick="wipeToggle(&#39;bartlett2019scale-free_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="bartlett2019scale-free_abstract" style="display: none"> <p><em>  Abstract:</em>We address the problem of planning in an environment with deterministic dynamics and stochastic discounted rewards under a limited numerical budget where the ranges of both rewards and noise are unknown. We introduce PlaTypOOS, an adaptive, robust, and efficient alternative to the OLOP (open-loop optimistic planning) algorithm. Whereas OLOP requires a priori knowledge of the ranges of both rewards and noise, PlaTypOOS dynamically adapts its behavior to both. This allows PlaTypOOS to be immune to two vulnerabilities of OLOP: failure when given underestimated ranges of noise and rewards and inefficiency when these are overestimated. PlaTypOOS additionally adapts to the global smoothness of the value function. PlaTypOOS acts in a provably more efficient manner vs. OLOP when OLOP is given an overestimated reward and show that in the case of no noise, PlaTypOOS learns exponentially faster.</p></div> <a href="https://slideslive.com/38917632/online-learning-2">video</a>
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/bartlett2019scale-free.talk.pdf">talk</a>
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/bartlett2019scale-free.poster.pdf">poster</a> 
</li>

<li>Pierre Perrault, Vianney Perchet, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/perrault2019exploiting.pdf">
<em>
Exploiting structure of uncertainty for efficient matroid semi-bandits</em></a>,
  in <a href="https://icml.cc/Conferences/2019">International Conference on Machine Learning</a> 
   (<span class="conference-shortcut">ICML 2019</span>)
    <a href="http://researchers.lille.inria.fr/~valko/hp/publications/perrault2019exploiting.bib">bibtex</a><a onclick="wipeToggle(&#39;perrault2019exploiting_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="perrault2019exploiting_abstract" style="display: none"> <p><em>  Abstract:</em>We improve the efficiency of algorithms for stochastic combinatorial semi-bandits. In most interesting problems, state-of-the-art algorithms take advantage of structural properties of rewards, such as independence. However, while being minimax optimal in terms of regret, these algorithms are intractable. In our paper, we first reduce their implementation to a specific submodular maximization. Then, in case of matroid constraints, we design adapted approximation routines, thereby providing the first efficient algorithms that exploit the reward structure. In particular, we improve the state-of-the-art efficient gap-free regret bound by a factor sqrt(k), where k is the maximum action size. Finally, we show how our improvement translates to more general budgeted combinatorial semi-bandits.</p></div> <a href="https://www.facebook.com/icml.imls/videos/444326646299556/">video</a>
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/perrault2019exploiting.talk.pdf">talk</a>
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/perrault2019exploiting.poster.pdf">poster</a>
 
</li>



<li>Xuedong Shang, Emilie Kaufmann, <strong>Michal Valko</strong>:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/shang2019simple.pdf"><em>
A simple dynamic bandit-based algorithm for hyper-parameter tuning</em></a>,  
in  <a href="https://sites.google.com/corp/view/automl2019icml/">  shop on Automated Machine Learning at International Conference on Machine Learning</a>  
 (<span class="conference-shortcut">ICML 2019 - AutoML</span>)

 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/shang2019simple.bib">bibtex</a><a onclick="wipeToggle(&#39;shang2019simple_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="shang2019simple_abstract" style="display: none"> <p><em>  Abstract:</em>Hyper-parameter tuning is a major part of modern machine learning systems. The tuning itself can be seen as a sequential resource allocation problem. As such, methods for multi-armed bandits have been already applied. In this paper, we view hyper-parameter optimization as an instance of best-arm identification in infinitely many-armed bandits. We propose D-TTTS, a new adaptive algorithm inspired by Thompson sampling, which dynamically balances between refining the estimate of the quality of hyper-parameter configurations previously explored and adding new hyper-parameter configurations to the pool of candidates. The algorithm is easy to implement and shows competitive performance compared to state-of-the-art algorithms for hyper-parameter tuning.</p></div> 
 <!--
   <a href="serve.php?what=publications/shang2019simple.talk.pdf">talk</a> --> 
   <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/shang2019simple.poster.pdf">poster</a>  
	   <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/shang2019simple.code.zip">code</a>
	 
</li>

  <li>Guillaume Gautier, Rémi Bardenet, <strong>Michal Valko</strong>:
     <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/gautier2019dppy.pdf"><em>
   DPPy: Sampling determinantal point processes with Python</em></a>,
   <a href="http://www.jmlr.org/">Journal of Machine Learning Research</a>
 (<span class="conference-shortcut">JMLR 2019</span>)      
    <a href="https://arxiv.org/abs/1809.07258">arXiv preprint</a>
	   <a href="http://researchers.lille.inria.fr/~valko/hp/publications/gautier2019dppy.bib">bibtex</a><a onclick="wipeToggle(&#39;gautier2019dppy_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="gautier2019dppy_abstract" style="display: none"> <p><em>  Abstract:</em>Determinantal point processes (DPPs) are specific probability distributions over clouds of points that are used as models and computational tools across physics, probability, statistics, and more recently machine learning. Sampling from DPPs is a challenge and therefore we present DPPy, a Python toolbox that gathers known exact and approximate sampling algorithms. The project is hosted on GitHub and equipped with an extensive documentation. This documentation takes the form of a short survey of DPPs and relates each mathematical property with DPPy objects.</p></div> 
   </li>



<li> Julien Seznec, Andrea Locatelli, Alexandra Carpentier, Alessandro Lazaric, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/seznec2019rotting.pdf"><em>Rotting bandits are not harder than stochastic ones</em></a>, 
 in <a href="http://www.aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2019</span>)
  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/seznec2019rotting.bib">bibtex</a><a onclick="wipeToggle(&#39;seznec2019rotting_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="seznec2019rotting_abstract" style="display: none"> <p><em>  Abstract:</em>In stochastic multi-armed bandits, the reward distribution of each arm is assumed to be stationary. This assumption is often violated in practice (e.g., in recommendation systems), where the reward of an arm may change whenever is selected, i.e., rested bandit setting. In this paper, we consider the non-parametric rotting bandit setting, where rewards can only decrease. We introduce the filtering on expanding window average (FEWA) algorithm that constructs moving averages of increasing windows to identify arms that are more likely to return high rewards when pulled once more. We prove that for an unknown horizon T, and without any knowledge on the decreasing behavior of the K arms, FEWA achieves problem-dependent regret bound of O(log(KT)), and a problem-independent one of O(sqrt(KT)). Our result substantially improves over the algorithm of Levine et al. (2017), which suffers regret ˜(K1/3T2/3). FEWA also matches known bounds for the stochastic bandit setting, thus showing that the rotting bandits are not harder. Finally, we report simulations confirming the theoretical improvements of FEWA.</p></div> 
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/seznec2019rotting.talk.pdf">talk</a> 
   <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/seznec2019rotting.poster.pdf">poster</a>
   [<span style="color: #CC3333">full oral presentation</span> - 2.5% acceptance rate]
</li>



<li>Andrea Locatelli, Alexandra Carpentier, <strong>Michal Valko</strong>:
 <aa href="serve.php?what=publications/locatelli2019active.pdf"><em>Active multiple matrix completion with adaptive confidence sets</em></aa>, 
 in <a href="http://www.aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
  (<span class="conference-shortcut">AISTATS 2019</span>)
  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/locatelli2019active.bib">bibtex</a><a onclick="wipeToggle(&#39;locatelli2019active_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="locatelli2019active_abstract" style="display: none"> <p><em>  Abstract:</em>In this work, we formulate a new multi-task active learning setting in which the learner's goal is to solve multiple matrix completion problems simultaneously. At each round, the learner can choose from which matrix it receives a sample from an entry drawn uniformly at random. Our main practical motivation is market segmentation, where the matrices represent different regions with different preferences of the customers. The challenge in this setting is that each of the matrices can be of a different size and also of a different rank which is unknown. We provide and analyze a new algorithm, MAlocate that is able to adapt to the unknown ranks of the different matrices. We then give a lower-bound showing that our strategy is minimax-optimal and demonstrate its performance with synthetic experiments.</p></div> 
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/locatelli2018active.talk.pdf">talk</a> 
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/locatelli2019active.poster.pdf">poster</a>
</li>

<li>Pierre Perrault, Vianney Perchet, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/perrault2019finding.pdf">
<em>
Finding the bandit in a graph: Sequential search-and-stop</em></a>, 
in <a href="http://www.aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2019</span>)
  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/perrault2019finding.bib">bibtex</a><a onclick="wipeToggle(&#39;perrault2019finding_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="perrault2019finding_abstract" style="display: none"> <p><em>  Abstract:</em>We consider the problem where an agent wants to find a hidden object that is randomly located in some vertex of a directed acyclic graph (DAG) according to a fixed but possibly unknown distribution. The agent can only examine vertices whose in-neighbors have already been examined. In scheduling theory, this problem is denoted by 1|prec|∑wjCj [Graham1979]. However, in this paper we address a learning setting where we allow the agent to stop before having found the object and restart searching on a new independent instance of the same problem. The goal is to maximize the total number of hidden objects found under a time constraint. The agent can thus skip an instance after realizing that it would spend too much time on it. Our contributions are both to the search theory and multi-armed bandits. If the distribution is known, we provide a quasi-optimal greedy strategy with the help of known computationally efficient algorithms for solving 1|prec|∑wjCj under some assumption on the DAG. If the distribution is unknown, we show how to sequentially learn it and, at the same time, act near-optimally in order to collect as many hidden objects as possible. We provide an algorithm, prove theoretical guarantees, and empirically show that it outperforms the naive baseline.</p></div>  
 <!-- <a href="serve.php?what=publications/perrault2019finding.talk.pdf">talk</a> -->
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/perrault2019finding.poster.pdf">poster</a> 
</li>

<li>Peter L. Bartlett, Victor Gabillon, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/bartlett2019simple.pdf">
<em>
A simple parameter-free and adaptive approach to optimization under a minimal local smoothness assumption</em></a>,
in  <a href="http://alt2019.algorithmiclearningtheory.org/">Algorithmic Learning Theory</a>  
 (<span class="conference-shortcut">ALT 2019</span>)
  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/bartlett2019simple.bib">bibtex</a><a onclick="wipeToggle(&#39;bartlett2019simple_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="bartlett2019simple_abstract" style="display: none"> <p><em>  Abstract:</em>We study the problem of optimizing a function under a budgeted number of evaluations. We only assume that the function is locally smooth around one of its global optima. The difficulty of optimization is measured in terms of 1) the amount of noise b of the function evaluation and 2) the local smoothness, d, of the function. A smaller d results in smaller optimization error. We come with a new, simple, and parameter-free approach. First, for all values of b and d, this approach recovers at least the state-of-the-art regret guarantees. Second, our approach additionally obtains these results while being agnostic to the values of both b and d. This leads to the first algorithm that naturally adapts to an unknown range of noise b and leads to significant improvements in a moderate and low-noise regime. Third, our approach also obtains a remarkable improvement over the state-of-the-art SOO algorithm when the noise is very low which includes the case of optimization under deterministic feedback (b=0). There, under our minimal local smoothness assumption, this improvement is of exponential magnitude and holds for a class of functions that covers the vast majority of functions that practitioners optimize (d=0). We show that our algorithmic improvement is borne out in experiments as we empirically show faster convergence on common benchmarks.</p></div>  
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/bartlett2019simple.talk.pdf">talk 1</a>
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/bartlett2019simple.talk.alt.pdf">talk 2</a>
 <!-- <a href="serve.php?what=publications/bartlett2019simple.poster.pdf">poster</a> -->
</li>


<li>Xuedong Shang, Emilie Kaufmann, <strong>Michal Valko</strong>:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/shang2019general.pdf"><em>
General parallel optimization without metric</em></a>,  
in  <a href="http://alt2019.algorithmiclearningtheory.org/">Algorithmic Learning Theory</a>  
 (<span class="conference-shortcut">ALT 2019</span>)
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/shang2019general.bib">bibtex</a><a onclick="wipeToggle(&#39;shang2019general_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="shang2019general_abstract" style="display: none"> <p><em>  Abstract:</em>Hierarchical bandits are an approach for global optimization of extremely irregular functions. This paper provides new elements regarding POO, an adaptive meta-algorithm that does not require the knowledge of local smoothness of the target function. We first highlight the fact that the subroutine algorithm used in POO should have a small regret under the assumption of local smoothness with respect to the chosen partitioning, which is unknown if it is satisfied by the standard subroutine HOO. In this work, we establish such regret guarantee for HCT, which is another hierarchical optimistic optimization algorithm that needs to know the smoothness. This confirms the validity of POO. We show that POO can be used with HCT as a subroutine with a regret upper bound that matches the one of best-known algorithms using the knowledge of smoothness up to a √ log n factor. On top of that, we propose a general wrapper, called GPO, that can cope with algorithms that only have simple regret guarantees. Finally, we complement our findings with experiments on difficult functions.</p></div> 

   <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/shang2019general.talk.pdf">talk</a>
  <!--  <a href="serve.php?what=publications/shang2019general.poster.pdf">poster</a>  --> 
	 






 </li><li>Guillaume Gautier, Rémi Bardenet, <strong>Michal Valko</strong>:
     <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/gautier2019processus.pdf"><em>
    Les processus ponctuels déterminantaux en apprentissage automatique</em></a>  
   <a href="http://researchers.lille.inria.fr/~valko/hp/publications/gautier2019processus.bib">bibtex</a><a onclick="wipeToggle(&#39;gautier2019processus_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="gautier2019processus_abstract" style="display: none"> <p><em>  Abstract:</em>For the session ``Mathematical tools in machine learning", we propose a short survey of determinantal point processes, a popular probabilistic model and tool in machine learning, which already has promising applications in signal processing.</p></div>  
     (<span class="conference-shortcut">Gretsi 2019</span>)
</li>

 
</ul>


<h2>2018</h2>
<ul class="publications-list">


<li>Jean-Bastien Grill, <strong>Michal Valko</strong>, Rémi Munos:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/grill2018optimistic.pdf"><em>Optimistic optimization of a Brownian</em></a>, 
in  <a href="http://nips.cc/Conferences/2018/">Neural Information Processing Systems</a> 
 (<span class="conference-shortcut">NeurIPS 2018</span>)    
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/grill2018optimistic.bib">bibtex</a><a onclick="wipeToggle(&#39;grill2018optimistic_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="grill2018optimistic_abstract" style="display: none"> <p><em>  Abstract:</em>We address the problem of optimizing a Brownian motion. We consider a (random) realization W of a Brownian motion with input space in [0,1]. Given W, our goal is to return an epsilon-approximation of its maximum using the smallest possible number of function evaluations, the sample complexity of the algorithm. We provide an algorithm with sample complexity of order log2(1/epsilon). This improves over previous results of Al-Mharmah and Calvin (1996) and Calvin et al. (2017) which provided only polynomial rates. Our algorithm is adaptive---each query depends on previous values---and is an instance of the optimism-in-the-face-of-uncertainty principle.</p></div> 
  <!--
   <a href="serve.php?what=publications/grill2016blazing.talk.pdf">talk</a> 
	   	 -->
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/grill2018optimistic.poster.pdf">poster</a> 
</li>


<li>Xuedong Shang, Emilie Kaufmann, <strong>Michal Valko</strong>:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/shang2018adaptive.pdf"><em>
Adaptive black-box optimization got easier: HCT needs only local smoothness</em></a>,  
in <a href="https://ewrl.wordpress.com/ewrl14-2018/">European Workshop on Reinforcement Learning</a> 
 (<span class="conference-shortcut">EWRL 2018</span>) 
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/shang2018adaptive.bib">bibtex</a><a onclick="wipeToggle(&#39;shang2018adaptive_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="shang2018adaptive_abstract" style="display: none"> <p><em>  Abstract:</em>Hierarchical bandits is an approach for global optimization of extremely irregular functions. This paper provides new elements regarding POO, an adaptive meta-algorithm that does not require the knowledge of local smoothness of the target function. We first highlight the fact that the sub-routine algorithm used in POO should have a small regret under the assumption of local smoothness with respect to the chosen partitioning, which is unknown if it is satisfied by the standard sub-routine HOO. In this work, we establish such regret guarantee for HCT which is another hierarchical optimistic optimization algorithm that needs to know the smoothness. This confirms the validity of POO. We show that POO can be used with HCT as a sub-routine with a regret upper bound that matches that of best-known algorithms using the knowledge of smoothness up to a sqrt(log(n)) factor.</p></div> 
 <!--
   <a href="serve.php?what=publications/shang2018adaptive.talk.pdf">talk</a> -->
   <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/shang2018adaptive.poster.pdf">poster</a> 
	 
</li>
	
	
<li>Edouard Oyallon, Eugene Belilovsky, Sergey Zagoruyko, <strong>Michal Valko</strong>:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/oyallon2018compressing.pdf"><em>
Compressing the input for CNNs with the first-order scattering transform</em></a>,  
in <a href="https://eccv2018.org/">European Conference on Computer Vision</a> 
 (<span class="conference-shortcut">ECCV 2018</span>) 
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/oyallon2018compressing.bib">bibtex</a><a onclick="wipeToggle(&#39;oyallon2018compressing_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="oyallon2018compressing_abstract" style="display: none"> <p><em>  Abstract:</em>We study the first-order scattering transform as a candidate for reducing the signal processed by a convolutional neural network (CNN). We show theoretical and empirical evidence that in the case of natural images and sufficiently small translation invariance, this transform preserves most of the signal information needed for classification while substantially reducing the spatial resolution and total signal size. We demonstrate that cascading a CNN with this representation performs on par with ImageNet classification models, commonly used in downstream tasks, such as the ResNet-50. We subsequently apply our trained hybrid ImageNet model as a base model on a detection system, which has typically larger image inputs. On Pascal VOC and COCO detection tasks we demonstrate improvements in the inference speed and training memory consumption compared to models trained directly on the input image.</p></div> 
 <!--
   <a href="serve.php?what=publications/oyallon2018compressing.talk.pdf">talk</a>  -->
   <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/oyallon2018compressing.poster.pdf">poster</a> 
	
</li>

<li>Daniele Calandriello, Ioannis Koutis, Alessandro Lazaric, <strong>Michal Valko</strong>:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2018improved.pdf"><em>
Improved large-scale graph learning through ridge spectral sparsification</em></a>,  
in <a href="https://icml.cc/Conferences/2018">International Conference on Machine Learning</a> 
 (<span class="conference-shortcut">ICML 2018</span>) 
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/calandriello2018improved.bib">bibtex</a><a onclick="wipeToggle(&#39;calandriello2018improved_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="calandriello2018improved_abstract" style="display: none"> <p><em>  Abstract:</em>The representation and learning benefits of methods based on graph Laplacians, such as Laplacian smoothing or harmonic function solution for semi-supervised learning (SSL), are empirically and theoretically well supported. Nonetheless, the exact versions of these methods scale poorly with the number of nodes n of the graph. In this paper, we combine a spectral sparsification routine with Laplacian learning. Given a graph G as input, our algorithm computes a sparsifier in a distributed way in O(nlog3(n)) time, O(mlog3(n)) work and O(nlog(n)) memory, using only log(n) rounds of communication. Furthermore, motivated by the regularization often employed in learning algorithms, we show that constructing sparsifiers that preserve the spectrum of the Laplacian only up to the regularization level may drastically reduce the size of the final graph. By constructing a spectrally-similar graph, we are able to bound the error induced by the sparsification for a variety of downstream tasks (e.g., SSL). We empirically validate the theoretical guarantees on Amazon co-purchase graph and compare to the state-of-the-art heuristics.</p></div> 
   <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2018improved.talk.pdf">talk</a>
   <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2018improved.poster.pdf">poster</a> 
</li>


<li>Yasin Abbasi-Yadkori, Peter L. Bartlett, Victor Gabillon, Alan Malek, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/abbasi-yadkori2018best.pdf">
<em>Best of both worlds: Stochastic &amp;
adversarial best-arm identification</em></a>, 
<a href="http://www.learningtheory.org/colt2018/"> Conference on Learning Theory</a>
 (<span class="conference-shortcut">COLT 2018</span>)
  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/abbasi-yadkori2018best.bib">bibtex</a><a onclick="wipeToggle(&#39;abbasi-yadkori2018best_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="abbasi-yadkori2018best_abstract" style="display: none"> <p><em>  Abstract:</em>We study bandit best-arm identification with arbitrary and potentially adversarial rewards. A simple random uniform learner obtains the optimal rate of error in the adversarial scenario. However, this type of strategy is suboptimal when the rewards are sampled stochastically. Therefore, we ask: Can we design a learner that performs optimally in both the stochastic and adversarial problems while not being aware of the nature of the rewards? First, we show that designing such a learner is impossible in general. In particular, to be robust to adversarial rewards, we can only guarantee optimal rates of error on a subset of the stochastic problems. We give a lower bound that characterizes the optimal rate in stochastic problems if the strategy is constrained to be robust to adversarial rewards. Finally, we design a simple parameter-free algorithm and show that its probability of error matches (up to log factors) the lower bound in stochastic problems, and it is also robust to adversarial ones.</p></div>  
    <a href="https://www.youtube.com/watch?v=oIOK4AyB05I">video</a>
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/abbasi-yadkori2018best.talk.pdf">talk</a>
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/abbasi-yadkori2018best.poster.pdf">poster</a>
</li>

</ul>

<h2>2017</h2>
<ul class="publications-list">


<li>Daniele Calandriello, Alessandro Lazaric, <strong>Michal Valko</strong>:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2017efficient.pdf"><em>
Efficient second-order online kernel learning with adaptive embedding</em></a>,  
in <a href="https://nips.cc/Conferences/2017">Neural Information Processing Systems</a> 
 (<span class="conference-shortcut">NeurIPS 2017</span>) 
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/calandriello2017efficient.bib">bibtex</a><a onclick="wipeToggle(&#39;calandriello2017efficient_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="calandriello2017efficient_abstract" style="display: none"> <p><em>  Abstract:</em>Online kernel learning (OKL) is a flexible framework to approach prediction problems, since the large approximation space provided by reproducing kernel Hilbert spaces can contain an accurate function for the problem. Nonetheless, optimizing over this space is computationally expensive. Not only first order methods accumulate O( sqrt T ) more loss than the optimal function, but the curse of kernelization results in a O(t) per step complexity. Second-order methods get closer to the optimum much faster, suffering only O( log(T)) regret, but second-order updates are even more expensive, with a O(t 2) per-step cost. Existing approximate OKL methods try to reduce this complexity either by limiting the Support Vectors (SV) introduced in the predictor, or by avoiding the kernelization process altogether using embedding. Nonetheless, as long as the size of the approximation space or the number of SV does not grow over time, an adversary can always exploit the approximation process. In this paper, we propose PROS-N-KONS, a method that combines Nystrom sketching to project the input point in a small, accurate embedded space, and performs efficient second-order updates in this space. The embedded space is continuously updated to guarantee that the embedding remains accurate, and we show that the per-step cost only grows with the effective dimension of the problem and not with T . Moreover, the second-order updated allows us to achieve the logarithmic regret. We empirically compare our algorithm on recent large-scales benchmarks and show it performs favorably.</p></div> 
   <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2017efficient.talk.pdf">talk</a>
   <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2017efficient.poster.pdf">poster</a> 
</li>

<li>Zheng Wen, Branislav Kveton , <strong>Michal Valko</strong>, Sharan Vaswani:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/wen2017online.pdf"><em>
Online influence maximization under independent cascade model with semi-bandit feedback</em></a>,  in <a href="https://nips.cc/Conferences/2017">Neural Information Processing Systems</a> 
 (<span class="conference-shortcut">NeurIPS 2017</span>) 
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/wen2017online.bib">bibtex</a><a onclick="wipeToggle(&#39;wen2017online_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="wen2017online_abstract" style="display: none"> <p><em>  Abstract:</em>We study the online influence maximization problem in social networks under the independent cascade model. Specifically, we aim to learn the set of " best influencers " in a social network online while repeatedly interacting with it. We address the challenges of (i) combinatorial action space, since the number of feasible influencer sets grows exponentially with the maximum number of influencers, and (ii) limited feedback, since only the influenced portion of the network is observed. Under a stochastic semi-bandit feedback, we propose and analyze IMLinUCB, a computationally efficient UCB-based algorithm. Our bounds on the cumulative regret are polynomial in all quantities of interest, achieve near-optimal dependence on the number of interactions and reflect the topology of the network and the activation probabilities of its edges, thereby giving insights on the problem complexity. To the best of our knowledge, these are the first such results. Our experiments show that in several representative graph topologies, the regret of IMLinUCB scales as suggested by our upper bounds. IMLinUCB permits linear generalization and thus is both statistically and computationally suitable for large-scale problems. Our experiments also show that IMLinUCB with linear generalization can lead to low regret in real-world online influence maximization.</p></div> 
<!--   <aa href="serve.php?what=publications/wen2017online.talk.pdf">talk</aa>
   <aa href="serve.php?what=publications/wen2017online.poster.pdf">poster</aa> -->
</li>


<li>Daniele Calandriello, Alessandro Lazaric, <strong>Michal Valko</strong>:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2017second.pdf"><em>
Second-order kernel online convex optimization with adaptive sketching</em>,  in </a><a href="http://icml.cc/2017/">International Conference on Machine Learning</a> 
 (<span class="conference-shortcut">ICML 2017</span>) 
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/calandriello2017second.bib">bibtex</a><a onclick="wipeToggle(&#39;calandriello2017second_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="calandriello2017second_abstract" style="display: none"> <p><em>  Abstract:</em>Kernel online convex optimization (KOCO) is a framework combining the expressiveness of non-parametric kernel models with the regret guarantees of online learning. First-order KOCO methods such as functional gradient descent require only O(t) time and space per iteration, and, when the only information on the losses is their convexity, achieve a minimax optimal O(sqrtT) regret. Nonetheless, many common losses in kernel problems, such as squared loss, logistic loss, and squared hinge loss posses stronger curvature that can be exploited. In this case, second-order KOCO methods achieve O(log(Det(K))) regret, which we show scales as O(deff log T), where deff is the effective dimension of the problem and is usually much smaller than O(sqrtT). The main drawback of second-order methods is their much higher O(t 2) space and time complexity. In this paper, we introduce kernel online Newton step (KONS), a new second-order KOCO method that also achieves O(defflog T) regret. To address the computational complexity of second-order methods, we introduce a new matrix sketching algorithm for the kernel matrix K, and show that for a chosen parameter gamma leq 1 our Sketched-KONS reduces the space and time complexity by a factor of gamma 2 to O(t 2gamma 2) space and time per iteration, while incurring only 1/gamma times more regret.</p></div> 
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2017second.talk.pdf">talk</a>
   <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2017second.poster.pdf">poster</a> 
</li>


<li>Guillaume Gautier, Rémi Bardenet, <strong>Michal Valko</strong>:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/gautier2017zonotope.pdf"><em>
Zonotope hit-and-run for efficient sampling from projection DPPs</em></a>,  in <a href="http://icml.cc/2017/">International Conference on Machine Learning</a> 
 (<span class="conference-shortcut">ICML 2017</span>) 
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/gautier2017zonotope.bib">bibtex</a><a onclick="wipeToggle(&#39;gautier2017zonotope_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="gautier2017zonotope_abstract" style="display: none"> <p><em>  Abstract:</em>Determinantal point processes (DPPs) are distributions over sets of items that model diversity using kernels. Their applications in machine learning include summary extraction and recommendation systems. Yet, the cost of sampling from a DPP is prohibitive in large-scale applications, which has triggered an effort towards efficient approximate samplers. We build a novel MCMC sampler that combines ideas from combinatorial geometry, linear programming, and Monte Carlo methods to sample from DPPs with a fixed sample cardinality, also called projection DPPs. Our sampler leverages the ability of the hit-and-run MCMC kernel to efficiently move across convex bodies. Previous theoretical results yield a fast mixing time of our chain when targeting a distribution that is close to a projection DPP, but not a DPP in general. Our empirical results demonstrate that this extends to sampling projection DPPs, i.e., our sampler is more sample-efficient than previous approaches which in turn translates to faster convergence when dealing with costly-to-evaluate functions, such as summary extraction in our experiments.</p></div> 
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/gautier2017zonotope.talk.pdf">talk</a> 
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/gautier2017zonotope.poster.pdf">poster</a>
</li>


<li>Daniele Calandriello, Alessandro Lazaric, <strong>Michal Valko</strong>:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2017distributed.pdf"><em>
Distributed adaptive sampling for kernel matrix approximation</em></a>,  in <a href="http://www.aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2017</span>) and (<span class="conference-shortcut-more">ICML 2017 - <a href="http://rlabstraction2016.wixsite.com/icml-2017"> LL</a></span>)   
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/calandriello2017distributed.bib">bibtex</a><a onclick="wipeToggle(&#39;calandriello2017distributed_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="calandriello2017distributed_abstract" style="display: none"> <p><em>  Abstract:</em>Most kernel-based methods, such as kernel regression, kernel PCA, ICA, or k-means clustering, do not scale to large datasets, because constructing and storing the kernel matrix Kn requires at least O(n2) time and space for n samples. Recent works (Alaoui 2014, Musco 2016) show that sampling points with replacement according to their ridge leverage scores (RLS) generates small dictionaries of relevant points with strong spectral approximation guarantees for Kn. The drawback of RLS-based methods is that computing exact RLS requires constructing and storing the whole kernel matrix. In this paper, we introduce SQUEAK, a new algorithm for kernel approximation based on RLS sampling that sequentially processes the dataset, storing a dictionary which creates accurate kernel matrix approximations with a number of points that only depends on the effective dimension deffgamma of the dataset. Moreover since all the RLS estimations are efficiently performed using only the small dictionary, SQUEAK never constructs the whole matrix kermatrixn, runs in linear time widetildeO(ndeffgamma3) w.r.t.n, and requires only a single pass over the dataset. We also propose a parallel and distributed version of SQUEAK achieving similar accuracy in as little as widetildeO(log(n)deffgamma3) time.</p></div> 
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2017distributed.talk.pdf">talk</a> 
     <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/squeak.py">code</a> 
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2017distributed.poster.pdf">poster</a> 
</li>


<li>Akram Erraqabi, Alessandro Lazaric, <strong>Michal Valko</strong>, Emma Brunskill, Yu-En Liu:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/erraqabi2017trading.pdf"><em>Trading off rewards and errors in multi-armed bandits</em></a>,  in <a href="http://www.aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2017</span>)    
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/erraqabi2017trading.bib">bibtex</a><a onclick="wipeToggle(&#39;erraqabi2017trading_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="erraqabi2017trading_abstract" style="display: none"> <p><em>  Abstract:</em>In multi-armed bandits, the most common objective is the maximization of the cumulative reward. Alternative settings include active exploration, where a learner tries to gain accurate estimates of the rewards of all arms. While these objectives are contrasting, in many scenarios it is desirable to trade off rewards and errors. For instance, in educational games the designer wants to gather generalizable knowledge about the behavior of the students and teaching strategies (small estimation errors) but, at the same time, the system needs to avoid giving a bad experience to the players, who may leave the system permanently (large reward). In this paper, we formalize this tradeoff and introduce the ForcingBalance algorithm whose performance is provably close to the best possible tradeoff strategy. Finally, we demonstrate on real-world educational data that ForcingBalance returns useful information about the arms without compromising the overall reward.</p></div> 
 <!-- <a href="serve.php?what=publications/erraqabi2016pliable.talk.pdf">talk</a> -->
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/erraqabi2017trading.poster.pdf">poster</a>
</li>





</ul>
<h2>2016</h2>
<ul class="publications-list">

<li><strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2016bandits.pdf"><em>Bandits on graphs and structures</em></a>, 
 habilitation thesis, <a href="http://www.ens-cachan.fr/">École normale supérieure de Cachan</a>
 (<span class="conference-shortcut">ENS Cachan 2016</span>)    
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/valko2016bandits.bib">bibtex</a><a onclick="wipeToggle(&#39;valko2016bandits_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="valko2016bandits_abstract" style="display: none"> <p><em>  Abstract:</em>We investigate the structural properties of certain sequential decision-making problems with limited feedback (bandits) in order to bring the known algorithmic solutions closer to a practical use. In the first part, we put a special emphasis on structures that can be represented as graphs on actions, in the second part we study the large action spaces that can be of exponential size in the number of base actions or even infinite. We show how to take advantage of structures over the actions and (provably) learn faster.</p></div> 
  <!-- <a href="serve.php?what=publications/grill2016blazing.poster.pdf">poster</a> -->
</li>



<li>Jean-Bastien Grill, <strong>Michal Valko</strong>, Rémi Munos:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/grill2016blazing.pdf"><em>Blazing the trails before beating the path: Sample-efficient Monte-Carlo planning</em></a>, 
in  <a href="http://nips.cc/Conferences/2016/">Neural Information Processing Systems</a> 
 (<span class="conference-shortcut">NeurIPS 2016</span>)    
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/grill2016blazing.bib">bibtex</a><a onclick="wipeToggle(&#39;grill2016blazing_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="grill2016blazing_abstract" style="display: none"> <p><em>  Abstract:</em>You are a robot and you live in a Markov decision process (MDP) with a finite or an infinite number of transitions from state-action to next states. You got brains and so you plan before you act. Luckily, your roboparents equipped you with a generative model to do some Monte-Carlo planning. The world is waiting for you and you have no time to waste. You want your planning to be efficient. Sample-efficient. Indeed, you want to exploit the possible structure of the MDP by exploring only a subset of states reachable by following near-optimal policies. You want guarantees on sample complexity that depend on a measure of the quantity of near-optimal states. You want something, that is an extension of Monte-Carlo sampling (for estimating an expectation) to problems that alternate maximization (over actions) and expectation (over next states). But you do not want to StOP with exponential running time, you want something simple to implement and computationally efficient. You want it all and you want it now. You want TrailBlazer.</p></div> 
   <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/grill2016blazing.talk.pdf">talk</a> 
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/grill2016blazing.poster.pdf">poster</a> 
  [<span style="color: #CC3333">full oral presentation</span> - 1.8% acceptance rate]  
</li>

<li>Daniele Calandriello, Alessandro Lazaric, <strong>Michal Valko</strong>:
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2016pack.pdf"><em>Pack only the essentials: Adaptive dictionary learning for kernel ridge regression</em></a>, in <a href="https://sites.google.com/site/nips2016adaptive/">Adaptive and Scalable Nonparametric Methods in Machine Learning at Neural Information Processing Systems</a> 
  (<span class="conference-shortcut">NeurIPS 2016 - ASNMML</span>)
  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/calandriello2016pack.bib">bibtex</a><a onclick="wipeToggle(&#39;calandriello2016pack_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="calandriello2016pack_abstract" style="display: none"> <p><em>  Abstract:</em>Most kernel-based methods, such as kernel regression, kernel PCA, ICA, or k-means clustering, do not scale to large datasets, because constructing and storing the kernel matrix Kn requires at least O(n2) time and space for n samples. Recent works (Alaoui 2014, Musco 2016) show that sampling points with replacement according to their ridge leverage scores (RLS) generates small dictionaries of relevant points with strong spectral approximation guarantees for Kn. The drawback of RLS-based methods is that computing exact RLS requires constructing and storing the whole kernel matrix. In this paper, we introduce SQUEAK, a new algorithm for kernel approximation based on RLS sampling that sequentially processes the dataset, storing a dictionary which creates accurate kernel matrix approximations with a number of points that only depends on the effective dimension deffgamma of the dataset. Moreover since all the RLS estimations are efficiently performed using only the small dictionary, SQUEAK never constructs the whole matrix kermatrixn, runs in linear time widetildeO(ndeffgamma3) w.r.t.n, and requires only a single pass over the dataset.</p></div> 
 <!-- <a href="serve.php?what=publications/calandriello2016analysis.talk.pdf">talk</a> -->
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2016pack.poster.pdf">poster</a> 
</li>



<li>Akram Erraqabi, Alessandro Lazaric, <strong>Michal Valko</strong>, Emma Brunskill, Yu-En L@iu:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/erraqabi2016rewards.pdf"><em>Rewards and Errors in Multi-armed Bandit for Interactive Education</em></a>, in <a href="http://ciml.chalearn.org/ciml2016">Challenges in Machine Learning: 
Learning and Education workshop at Neural Information Processing Systems</a> 
 (<span class="conference-shortcut">NeurIPS 2016 - CIML</span>)    
  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/erraqabi2016rewards.bib">bibtex</a><a onclick="wipeToggle(&#39;erraqabi2016rewards_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="erraqabi2016rewards_abstract" style="display: none"> <p><em>  Abstract:</em>In multi-armed bandits, the most common objective is the maximization of the cumulative reward. Alternative settings include active exploration, where a learner tries to gain accurate estimates of the rewards of all arms. While these objectives are contrasting, in many scenarios it is desirable to trade off rewards and errors. For instance, in educational games the designer wants to gather generalizable knowledge about the behavior of the students and teaching strategies (small estimation errors) but, at the same time, the system needs to avoid giving a bad experience to the players, who may leave the system permanently (large reward). In this paper, we formalize this tradeoff and introduce the ForcingBalance algorithm whose performance is provably close to the best possible tradeoff strategy. Finally, we demonstrate on real-world educational data that ForcingBalance returns useful information about the arms without compromising the overall reward.</p></div> 
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/erraqabi2016rewards.poster.pdf">poster</a> 

</li>


<li>Akram Erraqabi, <strong>Michal Valko</strong>, Alexandra Carpentier, Odalric-Ambrym Maillard:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/erraqabi2016pliable.pdf"><em>Pliable rejection sampling</em></a>, in <a href="http://icml.cc/2016/">International Conference on Machine Learning</a> 
 (<span class="conference-shortcut">ICML 2016</span>)    
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/erraqabi2016pliable.bib">bibtex</a><a onclick="wipeToggle(&#39;erraqabi2016pliable_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="erraqabi2016pliable_abstract" style="display: none"> <p><em>  Abstract:</em>Rejection sampling is a technique for sampling from difficult distributions. However, its use is limited due to a high rejection rate. Common adaptive rejection sampling methods either work only for very specific distributions or without performance guarantees. In this paper, we present pliable rejection sampling (PRS), a new approach to rejection sampling, where we learn the sampling proposal using a kernel estimator. Since our method builds on rejection sampling, the samples obtained are with high probability i.i.d. and distributed according to f. Moreover, PRS comes with a guarantee on the number of accepted samples.</p></div> 
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/erraqabi2016pliable.talk.pdf">talk</a>
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/erraqabi2016pliable.talk.long.pdf">long talk</a>
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/erraqabi2016pliable.poster.pdf">poster</a>
</li>


<li>Daniele Calandriello, Alessandro Lazaric, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2016analysis.pdf"><em>Analysis of Nyström method with sequential ridge leverage scores</em></a>, in <a href="http://auai.org/uai2016/">Uncertainty in Artificial Intelligence</a> 
 (<span class="conference-shortcut">UAI 2016</span>)    
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/calandriello2016analysis.bib">bibtex</a><a onclick="wipeToggle(&#39;calandriello2016analysis_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="calandriello2016analysis_abstract" style="display: none"> <p><em>  Abstract:</em>Large-scale kernel ridge regression (KRR) is limited by the need to store a large kernel matrix Kt. To avoid storing the entire matrix Kt, Nyström methods subsample a subset of columns of the kernel matrix, and efficiently find an approximate KRR solution on the reconstructed Kt . The chosen subsampling distribution in turn affects the statistical and computational tradeoffs. For KRR problems, [15, 1] show that a sampling distribution proportional to the ridge leverage scores (RLSs) provides strong reconstruction guarantees for Kt. While exact RLSs are as difficult to compute as a KRR solution, we may be able to approximate them well enough. In this paper, we study KRR problems in a sequential setting and introduce the INK-ESTIMATE algorithm, that incrementally computes the RLSs estimates. INK-ESTIMATE maintains a small sketch of Kt, that at each step is used to compute an intermediate es- timate of the RLSs. First, our sketch update does not require access to previously seen columns, and therefore a single pass over the kernel ma- trix is sufficient. Second, the algorithm requires a fixed, small space budget to run dependent only on the effective dimension of the kernel matrix. Finally, our sketch provides strong approximation guarantees on the distance ∥Kt−Kt∥2 , and on the statistical risk of the approximate KRR solution at any time, because all our guarantees hold at any intermediate step.</p></div> 
 <!-- <a href="serve.php?what=publications/calandriello2016analysis.talk.pdf">talk</a> -->
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2016analysis.poster.pdf">poster</a> 
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2016analysis.spotlight.pdf">spotlight</a> 
</li>


<li>Tomáš Kocák, Gergely Neu, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kocak2016onlinea.pdf"><em>Online learning with Erdős-Rényi side-observation graphs</em></a>, in <a href="http://auai.org/uai2016/">Uncertainty in Artificial Intelligence</a> 
 (<span class="conference-shortcut">UAI 2016</span>)    
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/kocak2016onlinea.bib">bibtex</a><a onclick="wipeToggle(&#39;kocak2016onlinea_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="kocak2016onlinea_abstract" style="display: none"> <p><em>  Abstract:</em>We consider adversarial multi-armed bandit problems where the learner is allowed to observe losses of a number of arms beside the arm that it actually chose. We study the case where all non-chosen arms reveal their loss with an unknown probability rt, independently of each other and the action of the learner. Moreover, we allow rt to change in every round t, which rules out the possibility of estimating rt by a well-concentrated sample average. We propose an algorithm which operates under the assumption that rt is large enough to warrant at least one side observation with high probability. We show that after T rounds in a bandit problem with N arms, the expected regret of our algorithm is of order O(sqrt(sum(t=1)T (1/rt) log N )), given that rt less than log T / (2N-2) for all t. All our bounds are within logarithmic factors of the best achievable performance of any algorithm that is even allowed to know exact values of rt.</p></div> 
 <!-- <a href="serve.php?what=publications/kocak2016onlinea.talk.pdf">talk</a> -->
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kocak2016onlinea.poster.pdf">poster</a>
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kocak2016onlinea.spotlight.pdf">spotlight</a>
  <!-- [<span style="color: #CC3333">full oral presentation</span> - 6% acceptance rate] -->  
</li>

<li>Mohammad Ghavamzadeh, Yaakov Engel, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/ghavamzadeh2016bayesian.pdf"><em>Bayesian policy gradient and actor-critic algorithms</em></a>, 
<a href="http://www.jmlr.org/"> Journal of Machine Learning Research</a>
 (<span class="conference-shortcut">JMLR 2016</span>)    
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/ghavamzadeh2016bayesian.bib">bibtex</a><a onclick="wipeToggle(&#39;ghavamzadeh2016bayesian_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="ghavamzadeh2016bayesian_abstract" style="display: none"> <p><em>  Abstract:</em>Policy gradient methods are reinforcement learning algorithms that adapt a parameterized policy by following a performance gradient estimate. Many conventional policy gradient methods use Monte-Carlo techniques to estimate this gradient. The policy is improved by adjusting the parameters in the direction of the gradient estimate. Since Monte-Carlo methods tend to have high variance, a large number of samples is required to attain accurate estimates, resulting in slow convergence. In this paper, we first propose a Bayesian framework for policy gradient, based on modeling the policy gradient as a Gaussian process. This reduces the number of samples needed to obtain accurate gradient estimates. Moreover, estimates of the natural gradient as well as a measure of the uncertainty in the gradient estimates, namely, the gradient covariance, are provided at little extra cost. Since the proposed Bayesian framework considers system trajectories as its basic observable unit, it does not require the dynamics within trajectories to be of any particular form, and thus, can be easily extended to partially observable problems. On the downside, it cannot take advantage of the Markov property when the system is Markovian. To address this issue, we proceed to supplement our Bayesian policy gradient framework with a new actor-critic learning model in which a Bayesian class of non- parametric critics, based on Gaussian process temporal difference learning, is used. Such critics model the action- value function as a Gaussian process, allowing Bayes' rule to be used in computing the posterior distribution over action-value functions, conditioned on the observed data. Appropriate choices of the policy parameterization and of the prior covariance (kernel) between action-values allow us to obtain closed-form expressions for the posterior distribution of the gradient of the expected return with respect to the policy parameters. We perform detailed experimental comparisons of the proposed Bayesian policy gradient and actor-critic algorithms with classic Monte-Carlo based policy gradient methods, as well as with each other, on a number of reinforcement learning problems.</p></div> 
  <a href="https://sequel.lille.inria.fr/Software/BAC">code</a>
  <!-- <a href="serve.php?what=publications/kveton2016learning.talk.pdf">talk</a> -->
  <!-- <a href="serve.php?what=publications/kveton2016learning.poster.pdf">poster</a> -->
</li>


<li>Tomáš Kocák, Gergely Neu, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kocak2016online.pdf"><em>Online learning with noisy side observations</em></a>, in <a href="http://www.aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2016</span>)    
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/kocak2016online.bib">bibtex</a><a onclick="wipeToggle(&#39;kocak2016online_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="kocak2016online_abstract" style="display: none"> <p><em>  Abstract:</em>We propose a new partial-observability model for online learning problems where the learner, besides its own loss, also observes some noisy feedback about the other actions, depending on the underlying structure of the problem. We represent this structure by a weighted directed graph, where the edge weights are related to the quality of the feedback shared by the connected nodes. Our main contribution is an efficient algorithm that guarantees a regret of O(sqrt(alpha{\^{</p></div> 
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kocak2016online.talk.pdf">talk</a> 
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kocak2016online.poster.pdf">poster</a>
 [<span style="color: #CC3333">full oral presentation</span> - 6% acceptance rate]  
</li>

<li>Alexandra Carpentier, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/carpentier2016revealing.pdf"><em>Revealing graph bandits for maximizing local influence</em></a>, in <a href="http://www.aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2016</span>)    
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/carpentier2016revealing.bib">bibtex</a><a onclick="wipeToggle(&#39;carpentier2016revealing_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="carpentier2016revealing_abstract" style="display: none"> <p><em>  Abstract:</em>We study a graph bandit setting where the objective of the learner is to detect the most influential node of a graph by requesting as little information from the graph as possible. One of the relevant applications for this setting is marketing in social networks, where the marketer aims at finding and taking advantage of the most influential customers. The existing approaches for bandit problems on graphs require either partial or complete knowledge of the graph. In this paper, we do not assume any knowledge of the graph, but we consider a setting where it can be gradually discovered in a sequential and active way. At each round, the learner chooses a node of the graph and the only information it receives is a stochastic set of the nodes that the chosen node is currently influencing. To address this setting, we propose BARE, a bandit strategy for which we prove a regret guarantee that scales with the detectable dimension, a problem dependent quantity that is often much smaller than the number of nodes.</p></div> 
  <!--  <a href="serve.php?what=publications/carpentier2016revealing.talk.pdf">talk</a>  --> 
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/carpentier2016revealing.poster.pdf">poster</a>
</li>


</ul>

<h2>2015</h2>
<ul class="publications-list">


<li>Jean-Bastien Grill, <strong>Michal Valko</strong>, Rémi Munos:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/grill2015black-box.pdf"><em>Black-box optimization of noisy functions with unknown smoothness</em></a>, 
in  <a href="http://nips.cc/Conferences/2015/">Neural Information Processing Systems</a> 
 (<span class="conference-shortcut">NeurIPS 2015</span>)    
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/grill2015black-box.bib">bibtex</a><a onclick="wipeToggle(&#39;grill2015black-box_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="grill2015black-box_abstract" style="display: none"> <p><em>  Abstract:</em>We study the problem of black-box optimization of a function f of any dimension, given function evaluations perturbed by noise. The function is assumed to be locally smooth around one of its global optima, but this smoothness is unknown. Our contribution is an adaptive optimization algorithm, POO or parallel optimistic optimization, that is able to deal with this setting. POO performs almost as well as the best known algorithms requiring the knowledge of the smoothness. Furthermore, POO works for a larger class of functions than what was previously considered, especially for functions that are difficult to optimize, in a very precise sense. We provide a finite-time analysis of POO's performance, which shows that its error after n evaluations is at most a factor of sqrt(ln n) away from the error of the best known optimization algorithms using the knowledge of the smoothness.</p></div> 
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=../projects/stosoo/poo_v1.zip">code</a>, 
  <a href="https://cran.r-project.org/web/packages/OOR/index.html">code in R</a> 
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/grill2015black-box.poster.pdf">poster</a>
</li>



<li>Alexandra Carpentier, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/carpentier2015simple.pdf"><em>Simple regret for infinitely many armed bandits</em></a>, in <a href="http://icml.cc/2015/">International Conference on Machine Learning</a> 
 (<span class="conference-shortcut">ICML 2015</span>)    
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/carpentier2015simple.bib">bibtex</a><a onclick="wipeToggle(&#39;carpentier2015simple_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="carpentier2015simple_abstract" style="display: none"> <p><em>  Abstract:</em>We consider a stochastic bandit problem with infinitely many arms. In this setting, the learner has no chance of trying all the arms even once and has to dedicate its limited number of samples only to a certain number of arms. All previous algorithms for this setting were designed for minimizing the cumulative regret of the learner. In this paper, we propose an algorithm aiming at minimizing the simple regret. As in the cumulative regret setting of infinitely many armed bandits, the rate of the simple regret will depend on a parameter \$\backslash beta\$ characterizing the distribution of the near-optimal arms. We prove that depending on \$\backslash beta\$, our algorithm is minimax optimal either up to a multiplicative constant or up to a \$\backslash log(n)\$ factor. We also provide extensions to several important cases: when \$\backslash beta\$ is unknown, in a natural setting where the near-optimal arms have a small variance, and in the case of unknown time horizon.</p></div> 
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/carpentier2015simple.talk.pdf">talk</a> 
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/carpentier2015simple.poster.pdf">poster</a> 
 <a href="http://arxiv.org/abs/1505.04627">arXiv</a>
</li>


<li>Manjesh Hanawal, Venkatesh Saligrama, <strong>Michal Valko</strong>, Rémi Munos:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/hanawal2015cheap.pdf"><em>Cheap Bandits</em></a>, in <a href="http://icml.cc/2015/">International Conference on Machine Learning</a> 
 (<span class="conference-shortcut">ICML 2015</span>)    
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/hanawal2015cheap.bib">bibtex</a><a onclick="wipeToggle(&#39;hanawal2015cheap_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="hanawal2015cheap_abstract" style="display: none"> <p><em>  Abstract:</em>We consider stochastic sequential learning problems where the learner can observe the average reward of several actions. Such a setting is interesting in many applications involving monitoring and surveillance, where the set of the actions to observe represent some (geographical) area. The importance of this setting is that in these applications, it is actually cheaper to observe average reward of a group of actions rather than the reward of a single action. We show that when the reward is smooth over a given graph representing the neighboring actions, we can maximize the cumulative reward of learning while minimizing the sensing cost. In this paper we propose CheapUCB, an algorithm that matches the regret guarantees of the known algorithms for this setting and at the same time guarantees a linear cost again over them. As a by-product of our analysis, we establish a Omega($\backslash$sqrt(dT)) lower bound on the cumulative regret of spectral bandits for a class of graphs with effective dimension d.</p></div> 
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/hanawal2015cheap.talk.pdf">talk</a> 
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/hanawal2015cheap.poster.pdf">poster</a>
</li>


<li>Daniele Calandriello, Alessandro Lazaric, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2015large-scale.pdf"><em>Large-scale semi-supervised learning with online spectral graph sparsification</em></a>, in <a href="https://sites.google.com/site/icml2015budgetedml/">Resource-Efficient Machine Learning workshop at International Conference on Machine Learning</a> 
 (<span class="conference-shortcut">ICML 2015 - REML</span>)    
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/calandriello2015large-scale.bib">bibtex</a><a onclick="wipeToggle(&#39;calandriello2015large-scale_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="calandriello2015large-scale_abstract" style="display: none"> <p><em>  Abstract:</em>We introduce Sparse-HFS, a scalable algorithm that can compute solutions to SSL problems using only O(n polylog(n)) space and O(m polylog(n)) time.</p></div> 
 <!-- <a href="serve.php?what=publications/calandriello2016analysis.talk.pdf">talk</a> -->
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/calandriello2015large-scale.poster.pdf">poster</a> 
 <!-- <a href="serve.php?what=publications/calandriello2015large-scale.spotlight.pdf">spotlight</a>  -->
</li>

<li>Julien Audiffren, <strong>Michal Valko</strong>, Alessandro Lazaric, Mohammad Ghavamzadeh:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/audiffren2015maximum.pdf">
<em> Maximum Entropy Semi-Supervised Inverse Reinforcement Learning</em></a>, 
in  <a href="http://ijcai-15.org/">International Joint Conferences on Artificial Intelligence</a> 
(<span class="conference-shortcut">IJCAI 2015</span>)  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/audiffren2015maximum.bib">bibtex</a><a onclick="wipeToggle(&#39;audiffren2015maximum_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="audiffren2015maximum_abstract" style="display: none"> <p><em>  Abstract:</em>A popular approach to apprenticeship learning (AL) is to formulate it as an inverse reinforcement learning (IRL) problem. The MaxEnt-IRL algorithm successfully integrates the maximum entropy principle into IRL and unlike its predecessors, it resolves the ambiguity arising from the fact that a possibly large number of policies could match the expert's behavior. In this paper, we study an AL setting in which in addition to the expert's trajectories, a number of unsupervised trajectories is available. We introduce MESSI, a novel algorithm that combines MaxEnt-IRL with principles coming from semi-supervised learning. In particular, MESSI integrates the unsupervised data into the MaxEnt-IRL framework using a pairwise penalty on trajectories. Empirical results in a highway driving and grid-world problems indicate that MESSI is able to take advantage of the unsupervised trajectories and improve the performance of MaxEnt-IRL.</p></div> <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/audiffren2015maximum.talk.pdf">talk</a> 
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/audiffren2015maximum.poster.pdf">poster</a> 
</li>

</ul>


<h2>2014</h2>
<ul class="publications-list">

<li>Tomáš Kocák, Gergely Neu, <strong>Michal Valko</strong>, Rémi Munos:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kocak2014efficient.pdf">
<em>Efficient Learning by Implicit Exploration in Bandit Problems with Side Observations</em></a>, 
in <a href="http://nips.cc/Conferences/2014/">Neural Information Processing Systems</a> 
(<span class="conference-shortcut">NeurIPS 2014</span>)  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/kocak2014efficient.bib">bibtex</a><a onclick="wipeToggle(&#39;kocak2014efficient_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="kocak2014efficient_abstract" style="display: none"> <p><em>  Abstract:</em>We consider online learning problems under a partial observability model capturing situations where the information conveyed to the learner is between full information and bandit feedback. In the simplest variant, we assume that in addition to its own loss, the learner also gets to observe losses of some other actions. The revealed losses depend on the learner's action and a directed observation system chosen by the environment. For this setting, we propose the first algorithm that enjoys near-optimal regret guarantees without having to know the observation system before selecting its actions. Along similar lines, we also define a new partial information setting that models online combinatorial optimization problems where the feedback received by the learner is between semi-bandit and full feedback. As the predictions of our first algorithm cannot be always computed efficiently in this setting, we propose another algorithm with similar properties and with the benefit of always being computationally efficient, at the price of a slightly more complicated tuning mechanism. Both algorithms rely on a novel exploration strategy called implicit exploration, which is shown to be more efficient both computationally and information-theoretically than previously studied exploration strategies for the problem.</p></div><a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kocak2014efficient.talk.pdf">talk</a> 
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kocak2014efficient.poster.pdf">poster</a> 
</li>


<li>Alexandra Carpentier, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/carpentier2014extreme.pdf">
<em>Extreme Bandits</em></a>, 
in <a href="http://nips.cc/Conferences/2014/">Neural Information Processing Systems</a>
(<span class="conference-shortcut">NeurIPS 2014</span>)  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/carpentier2014extreme.bib">bibtex</a><a onclick="wipeToggle(&#39;carpentier2014extreme_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="carpentier2014extreme_abstract" style="display: none"> <p><em>  Abstract:</em>In many areas of medicine, security, and life sciences, we want to allocate limited resources to different sources in order to detect extreme values. In this paper, we study an efficient way to allocate these resources sequentially under limited feedback. While sequential design of experiments is well studied in bandit theory, the most commonly optimized property is the regret with respect to the maximum mean reward. However, in other problems such as network intrusion detection, we are interested in detecting the most extreme value output by the sources. Therefore, in our work we study extreme regret which measures the efficiency of an algorithm compared to the oracle policy selecting the source with the heaviest tail. We propose the ExtremeHunter algorithm, provide its analysis, and evaluate it empirically on synthetic and real-world experiments.</p></div><a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/carpentier2014extreme.poster.pdf">poster</a> 
</li>

<li>Gergely Neu, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/neu2014online.pdf">
<em>Online Combinatorial Optimization with Stochastic Decision Sets and Adversarial Losses</em></a>, 
in <a href="http://nips.cc/Conferences/2014/">Neural Information Processing Systems</a> 
(<span class="conference-shortcut">NeurIPS 2014</span>)  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/neu2014online.bib">bibtex</a><a onclick="wipeToggle(&#39;neu2014online_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="neu2014online_abstract" style="display: none"> <p><em>  Abstract:</em>Most work on sequential learning assumes a fixed set of actions that are available all the time. However, in practice, actions can consist of picking subsets of readings from sensors that may break from time to time, road segments that can be blocked or goods that are out of stock. In this paper we study learning algorithms that are able to deal with stochastic availability of such unreliable composite actions. We propose and analyze algorithms based on the Follow-The-Perturbed-Leader prediction method for several learning settings differing in the feedback provided to the learner. Our algorithms rely on a novel loss estimation technique that we call Counting Asleep Times. We deliver regret bounds for our algorithms for the previously studied full information and (semi-)bandit settings, as well as a natural middle point between the two that we call the restricted information setting. A special consequence of our results is a significant improvement of the best known performance guarantees achieved by an efficient algorithm for the sleeping bandit problem with stochastic availability. Finally, we evaluate our algorithms empirically and show their improvement over the known approaches.</p></div><a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/neu2014online.talk.pdf">talk</a> 
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/neu2014online.poster.pdf">poster</a> 
</li>


<li><strong>Michal Valko</strong>, Rémi Munos, Branislav Kveton, Tomáš Kocák:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2014spectral.pdf">
<em>Spectral Bandits for Smooth Graph Functions</em></a>, 
in <a href="http://icml.cc/2014/">International Conference on Machine Learning</a> 
(<span class="conference-shortcut">ICML 2014</span>)  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/valko2014spectral.bib">bibtex</a><a onclick="wipeToggle(&#39;valko2014spectral_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="valko2014spectral_abstract" style="display: none"> <p><em>  Abstract:</em>Smooth functions on graphs have wide applications in manifold and semi-supervised learning. In this paper, we study a bandit problem where the payoffs of arms are smooth on a graph. This framework is suitable for solving online learning problems that involve graphs, such as content-based recommendation. In this problem, each item we can recommend is a node and its expected rating is similar to its neighbors. The goal is to recommend items that have high expected ratings. We aim for the algorithms where the cumulative regret with respect to the optimal policy would not scale poorly with the number of nodes. In particular, we introduce the notion of an effective dimension, which is small in real-world graphs, and propose two algorithms for solving our problem that scale linearly and sublinearly in this dimension. Our experiments on real-world content recommendation problem show that a good estimator of user preferences for thousands of items can be learned from just tens of nodes evaluations.</p></div><a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2014spectral.talk.pdf">slides</a>
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2014spectral.poster.pdf">poster</a> 
</li>


<li>Tomáš Kocák, <strong>Michal Valko</strong>, Rémi Munos, Shipra Agrawal:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kocak2014spectral.pdf">
<em>Spectral Thompson Sampling</em></a>, 
in <a href="http://www.aaai.org/Conferences/AAAI/aaai14.php">AAAI Conference on Artificial Intelligence</a> 
(<span class="conference-shortcut">AAAI 2014</span>)  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/kocak2014spectral.bib">bibtex</a><a onclick="wipeToggle(&#39;kocak2014spectral_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="kocak2014spectral_abstract" style="display: none"> <p><em>  Abstract:</em>Thompson Sampling (TS) has surged a lot of interest due to its good empirical performance, in particular in the computational advertising. Though successful, the tools for its performance analysis appeared only recently. In this paper, we describe and analyze SpectralTS algorithm for a bandit problem, where the payoffs of the choices are smooth given an underlying graph. In this setting, each choice is a node of a graph and the expected payoffs of the neighboring nodes are assumed to be similar. Although the setting has application both in recommender systems and advertising, the traditional algorithms would scale poorly with the number of choices. For that purpose we consider an effective dimension d, which is small in real-world graphs. We deliver the analysis showing that the regret of SpectralTS scales as d$\backslash$sqrt(T $\backslash$ln N) with high probability, where T is the time horizon and N is the number of choices. Since a d$\backslash$sqrt(T $\backslash$ln N) regret is comparable to the known results, SpectralTS offers a computationally more efficient alternative. We also show that our algorithm is competitive on both synthetic and real-world data.</p></div><a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kocak2014spectral.talk.pdf">slides</a> 
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kocak2014spectral.poster.pdf">poster</a> 
</li>

<li>Philippe Preux, Rémi Munos, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/preux2014bandits.pdf">
<em>Bandits attack function optimization</em></a>, in <a href="http://www.ieee-wcci2014.org/">IEEE Congress on Evolutionary Computation</a> 
(<span class="conference-shortcut">CEC 2014</span>)  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/preux2014bandits.bib">bibtex</a><a onclick="wipeToggle(&#39;preux2014bandits_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="preux2014bandits_abstract" style="display: none"> <p><em>  Abstract:</em>We consider function optimization as a sequential decision making problem under the budget constraint. Such constraint limits the number of objective function evaluations allowed during the optimization. We consider an algorithm inspired by a continuous version of a multi-armed bandit problem which attacks this optimization problem by solving the tradeoff between exploration (initial quasi-uniform search of the domain) and exploitation (local optimization around the potentially global maxima). We introduce the so-called Simultaneous Optimistic Optimization (SOO), a deterministic algorithm that works by domain partitioning. The benefit of such an approach are the guarantees on the returned solution and the numerical eficiency of the algorithm. We present this machine learning rooted approach to optimization, and provide the empirical assessment of SOO on the CEC’2014 competition on single objective real-parameter numerical optimization testsuite.</p></div></li>

<li>Julien Audiffren, <strong>Michal Valko</strong>, Alessandro Lazaric, Mohammad Ghavamzadeh:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/audiffren2014messi.pdf">
<em> MESSI: Maximum Entropy Semi-Supervised Inverse Reinforcement Learning</em></a>, 
in  <a href="https://tcrl14.wordpress.com/">NIPS Workshop on Novel Trends and Applications in Reinforcement Learning</a> 
(<span class="conference-shortcut">NeurIPS 2014 - TCRL</span>)  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/audiffren2014messi.bib">bibtex</a><a onclick="wipeToggle(&#39;audiffren2014messi_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="audiffren2014messi_abstract" style="display: none"> <p><em>  Abstract:</em>A popular approach to apprenticeship learning (AL) is to formulate it as an inverse reinforcement learning (IRL) problem. The MaxEnt-IRL algorithm successfully integrates the maximum entropy principle into IRL and unlike its predecessors, it resolves the ambiguity arising from the fact that a possibly large number of policies could match the expert's behavior. In this paper, we study an AL setting in which in addition to the expert's trajectories, a number of unsupervised trajectories is available. We introduce MESSI, a novel algorithm that combines MaxEnt-IRL with principles coming from semi-supervised learning. In particular, MESSI integrates the unsupervised data into the MaxEnt-IRL framework using a pairwise penalty on trajectories. Empirical results in a highway driving and grid-world problems indicate that MESSI is able to take advantage of the unsupervised trajectories and improve the performance of MaxEnt-IRL.</p></div> 
</li>

<li>Tomáš Kocák, <strong>Michal Valko</strong>, Rémi Munos, Branislav Kveton, Shipra Agrawal:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kocak2014wspectral.pdf">
<em>Spectral Bandits for Smooth Graph Functions with Applications in Recommender Systems</em></a>, 
in  <a href="http://www.aaai.org/ws14workshops/ws14workshops.php#ws14">AAAI Workshop on Sequential Decision-Making with Big Data</a> 
(<span class="conference-shortcut">AAAI 2014 - SDMBD</span>)  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/kocak2014wspectral.bib">bibtex</a><a onclick="wipeToggle(&#39;kocak2014wspectral_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="kocak2014wspectral_abstract" style="display: none"> <p><em>  Abstract:</em>Smooth functions on graphs have wide applications in manifold and semi-supervised learning. In this paper, we study a bandit problem where the payoffs of arms are smooth on a graph. This framework is suitable for solving online learning problems that involve graphs, such as content-based recommendation. In this problem, each recommended item is a node and its expected rating is similar to its neighbors. The goal is to recommend items that have high expected ratings. We aim for the algorithms where the cumulative regret would not scale poorly with the number of nodes. In particular, we introduce the notion of an effective dimension, which is small in real-world graphs, and propose two algorithms for solving our problem that scale linearly in this dimension. Our experiments on real-world content recommendation problem show that a good estimator of user preferences for thousands of items can be learned from just tens nodes evaluations.</p></div> 
</li>
</ul>
<h2>2013</h2>
<ul class="publications-list">

<li><strong>Michal Valko</strong>, Alexandra Carpentier, Rémi Munos:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2013stochastic.pdf"><em>Stochastic Simultaneous Optimistic Optimization</em></a>, in <a href="http://icml.cc/2013/">International Conference on Machine Learning</a> 
 (<span class="conference-shortcut">ICML 2013</span>)    
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/valko2013stochastic.bib">bibtex</a><a onclick="wipeToggle(&#39;valko2013stochastic_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="valko2013stochastic_abstract" style="display: none"> <p><em>  Abstract:</em>We study the problem of global maximization of a function f given a finite number of evaluations perturbed by noise. We consider a very weak assumption on the function, namely that it is locally smooth (in some precise sense) with respect to some semi-metric, around one of its global maxima. Compared to previous works on bandits in general spaces (Kleinberg et al., 2008; Bubeck et al., 2011a) our algorithm does not require the knowledge of this semi-metric. Our algorithm, StoSOO, follows an optimistic strategy to iteratively construct upper confidence bounds over the hierarchical partitions of the function domain to decide which point to sample next. A finite-time analysis of StoSOO shows that it performs almost as well as the best specifically-tuned algorithms even though the local smoothness of the function is not known.</p></div> 
 <a href="http://youtu.be/Vx1tB6ADc-M">demo</a>
 <a href="https://sequel.lille.inria.fr/Software/StoSOO">code</a>,
 <a href="https://cran.r-project.org/web/packages/OOR/index.html">code in R</a> 
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2013stochastic.talk.pdf">slides</a>
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2013stochastic.poster.pdf">poster</a> 
 <a href="http://techtalks.tv/talks/stochastic-simultaneous-optimistic-optimization/58353/">talk</a>
</li>


<li>
<strong>Michal Valko</strong>, Nathan Korda, Rémi Munos, Ilias Flaounas, Nello Cristianini:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2013finite.pdf"><em>Finite-Time Analysis of Kernelised Contextual Bandits</em></a>, 
 in <a href="http://auai.org/uai2013//">Uncertainty in Artificial Intelligence </a> 
 (<span class="conference-shortcut">UAI 2013</span>) and (<span class="conference-shortcut-more">JFPDA 2013</span>).    
  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/valko2013finite.bib">bibtex</a><a onclick="wipeToggle(&#39;valko2013finite_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="valko2013finite_abstract" style="display: none"> <p><em>  Abstract:</em>We tackle the problem of online reward maximisation over a large finite set of actions described by their contexts. We focus on the case when the number of actions is too big to sample all of them even once. However we assume that we have access to the similarities between actions' contexts and that the expected reward is an arbitrary linear function of the contexts' images in the related reproducing kernel Hilbert space (RKHS). We propose KernelUCB, a kernelised UCB algorithm, and give a cumulative regret bound through a frequentist analysis. For contextual bandits, the related algorithm GP-UCB turns out to be a special case of our algorithm, and our finite-time analysis improves the regret bound of GP-UCB for the agnostic case, both in the terms of the kernel-dependent quantity and the RKHS norm of the reward function. Moreover, for the linear kernel, our regret bound matches the lower bound for contextual linear bandits.</p></div>  
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2013finite.poster.pdf">poster</a>
  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2013finite.spotlight.pdf">spotlight</a>
  <a href="https://team.inria.fr/sequel/Software/KernelUCB/">code</a>
</li>


<li>Branislav Kveton, <strong>Michal Valko</strong>:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kveton2013learning.pdf"><em>Learning from a Single Labeled Face and a Stream of Unlabeled Data</em></a>, 
 in <a href="http://fg2013.cse.sc.edu/">IEEE International Conference on Automatic Face and Gesture Recognition</a> 
 (<span class="conference-shortcut">FG 2013</span>)   
<span style="color: #CC3333">[spotlight]</span> 
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/kveton2013learning.bib">bibtex</a><a onclick="wipeToggle(&#39;kveton2013learning_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="kveton2013learning_abstract" style="display: none"> <p><em>  Abstract:</em>Face recognition from a single image per person is a challenging problem because the training sample is extremely small. We consider a variation of this problem. In our problem, we recognize only one person, and there are no labeled data for any other person. This setting naturally arises in authentication on personal computers and mobile devices, and poses additional challenges because it lacks negative examples. We formalize our problem as one-class classification, and propose and analyze an algorithm that learns a non-parametric model of the face from a single labeled image and a stream of unlabeled data. In many domains, for instance when a person interacts with a computer with a camera, unlabeled data are abundant and easy to utilize. This is the first paper that investigates how these data can help in learning better models in the single-image-per-person setting. Our method is evaluated on a dataset of 43 people and we show that these people can be recognized 90\% of time at nearly zero false positives. This recall is 25+\% higher than the recall of our best performing baseline. Finally, we conduct a comprehensive sensitivity analysis of our algorithm and provide a guideline for setting its parameters in practice.</p></div> 
</li>


<li>Milos Hauskrecht, Iyad Batal, <strong>Michal Valko</strong>, Shyam Visweswaran, Gregory F. Cooper, Gilles Clermont:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/hauskrecht2013outlier.pdf">
<em>Outlier detection for patient monitoring and alerting</em></a>, in <a href="http://www.journals.elsevier.com/journal-of-biomedical-informatics/">Journal of Biomedical Informatics</a> (<span class="conference-shortcut">JBI 2013</span>)  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/hauskrecht2013outlier.bib">bibtex</a><a onclick="wipeToggle(&#39;hauskrecht2013outlier_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="hauskrecht2013outlier_abstract" style="display: none"> <p><em>  Abstract:</em>We develop and evaluate a data-driven approach for detecting unusual (anomalous) patient-management decisions using past patient cases stored in electronic health records (EHRs). Our hypothesis is that a patient-management decision that is unusual with respect to past patient care may be due to an error and that it is worthwhile to generate an alert if such a decision is encountered. We evaluate this hypothesis using data obtained from EHRs of 4486 post-cardiac surgical patients and a subset of 222 alerts generated from the data. We base the evaluation on the opinions of a panel of experts. The results of the study support our hypothesis that the outlier-based alerting can lead to promising true alert rates. We observed true alert rates that ranged from 25\% to 66\% for a variety of patient-management actions, with 66\% corresponding to the strongest outliers.</p></div></li>

</ul>
<h2>2012</h2>
<ul class="publications-list">

<li><strong>Michal Valko</strong>,
Mohammad Ghavamzadeh,  Alessandro Lazaric: <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2012semi-supervised.pdf">
<em>Semi-supervised apprenticeship learning</em></a>, in Journal of Machine Learning Research Workshop and Conference Proceedings:  <a href="http://ewrl.wordpress.com/ewrl10-2012/">European Workshop on Reinforcement Learning</a> (<span class="conference-shortcut">EWRL 2012</span>)  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/valko2012semi-supervised.bib">bibtex</a><a onclick="wipeToggle(&#39;valko2012semi-supervised_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="valko2012semi-supervised_abstract" style="display: none"> <p><em>  Abstract:</em>In apprenticeship learning we aim to learn a good policy by observing the behavior of an expert or a set of experts. In particular, we consider the case where the expert acts so as to maximize an unknown reward function defined as a linear combination of a set of state features. In this paper, we consider the setting where we observe many sample trajectories (i.e., sequences of states) but only one or a few of them are labeled as experts' trajectories. We investigate the conditions under which the remaining unlabeled trajectories can help in learning a policy with a good performance. In particular, we define an extension to the max-margin inverse reinforcement learning proposed by Abbeel and Ng (2004) where, at each iteration, the max-margin optimization step is replaced by a semi-supervised optimization problem which favors classifiers separating clusters of trajectories. Finally, we report empirical results on two grid-world domains showing that the semi-supervised algorithm is able to output a better policy in fewer iterations than the related algorithm that does not take the unlabeled trajectories into account.</p></div><a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2012semi-supervised.talk.pdf">talk</a>
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2012semi-supervised.poster.pdf">poster</a>
</li>




</ul>
<h2>2011</h2>
<ul class="publications-list">


<li><strong>Michal Valko</strong>,
Branislav Kveton, Hamed Valizadegan, Gregory F. Cooper, Milos Hauskrecht:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2011conditionala.pdf"><em>Conditional Anomaly Detection with Soft Harmonic Functions</em></a>, in <a href="http://webdocs.cs.ualberta.ca/~icdm2011/">International Conference on Data Mining</a> (<span class="conference-shortcut">ICDM 2011</span>)   <a href="http://researchers.lille.inria.fr/~valko/hp/publications/valko2011conditionala.bib">bibtex</a><a onclick="wipeToggle(&#39;valko2011conditionala_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="valko2011conditionala_abstract" style="display: none"> <p><em>  Abstract:</em>In this paper, we consider the problem of conditional anomaly detection
	that aims to identify data instances with an unusual response or
	a class label.  We develop a new non-parametric approach for conditional
	anomaly detection based on the soft harmonic solution, with which
	we estimate the confidence of the label to detect anomalous mislabeling.
	We further regularize the solution to avoid the detection of  isolated
	examples and  examples on the boundary of the distribution support.
	We demonstrate the efficacy of the proposed method on several synthetic
	and UCI ML datasets in detecting unusual labels when compared to
	several baseline approaches. We also evaluate the performance of
	our method on a real-world electronic health record dataset where
	we seek to identify unusual patient-management decisions.</p></div> 
</li>

<li> Thomas C. Hart, Patricia M. Corby, Milos Hauskrecht, Ok Hee Ryu, Richard Pelikan, <strong>Michal Valko</strong>, Maria B. Oliveira, Gerald T. Hoehn, and Walter A. Bretz:
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/hart2011indentification.pdf"><em>
Identification of Microbial and Proteomic Biomedicalkers in
Early Childhood Caries</em></a> in <a href="http://www.hindawi.com/journals/ijd/">International Journal of Dentistry</a> (<span class="conference-shortcut">IJD 2011</span>)   <a href="http://researchers.lille.inria.fr/~valko/hp/publications/hart2011indentification.bib">bibtex</a><a onclick="wipeToggle(&#39;hart2011indentification_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="hart2011indentification_abstract" style="display: none"> <p><em>  Abstract:</em>The purpose of this study was to provide a univariate and multivariate
	analysis of genomic microbial data and salivary mass-spectrometry
	proteomic profiles for dental caries outcomes. In order to determine
	potential useful biomarkers for dental caries, a multivariate classification
	analysis was employed to build predictive models capable of classifying
	microbial and salivary sample profiles with generalization performance.
	We used high-throughput methodologies including multiplexed microbial
	arrays and SELDI-TOF-MS profiling to characterize the oral flora
	and salivary proteome in 204 children aged 1-8 years (n = 118 caries-free,
	n = 86 caries-active). The population received little dental care
	and was deemed at high risk for childhood caries. Findings of the
	study indicate that models incorporating both microbial and proteomic
	data are superior to models of only microbial or salivary data alone.
	Comparison of results for the combined and independent data suggests
	that the combination of proteomic and microbial sources is beneficial
	for the classification accuracy and that combined data lead to improved
	predictive models for caries-active and caries-free patients. The
	best predictive model had a 6\% test error, &gt;92\% sensitivity, and
	&gt;95\% specificity. These findings suggest that further characterization
	of the oral microflora and the salivary proteome associated with
	health and caries may provide clinically useful biomarkers to better
	predict future caries experience.</p></div> 
<!-- <span class="citation-count">[0+1 citations]</span>  -->
</li>

<li>
<strong>Michal Valko</strong>: 
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2011adaptive.pdf"><em>Adaptive Graph-Based Algorithms for Conditional Anomaly Detection and Semi-Supervised Learning</em></a>, PhD thesis, <a href="http://www.cs.pitt.edu/">University of Pittsburgh</a>
(<span class="conference-shortcut">PITT 2011</span>)   <a href="http://researchers.lille.inria.fr/~valko/hp/publications/valko2011adaptive.bib">bibtex</a><a onclick="wipeToggle(&#39;valko2011adaptive_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="valko2011adaptive_abstract" style="display: none"> <p><em>  Abstract:</em>We develop graph-based methods for semi-supervised learning based
	on label propagation on a data similarity graph. When data is abundant
	or arrive in a stream, the problems of computation and data storage
	arise for any graph-based method. We propose a fast approximate online
	algorithm that solves for the harmonic solution on an approximate
	graph. We show, both empirically and theoretically, that good behavior
	can be achieved by collapsing nearby points into a set of local representative
	points that minimize distortion. Moreover, we regularize the harmonic
	solution to achieve better stability properties.   
	
	We also present graph-based methods for detecting conditional anomalies
	and apply them to the identification of unusual clinical actions
	in hospitals.  Our hypothesis is that patient-management actions
	that are unusual with respect to the past patients may be due to
	errors and that it is worthwhile to raise an alert if such a condition
	is encountered. Conditional anomaly detection extends standard unconditional
	anomaly framework but also faces new problems known as fringe and
	isolated points. We devise novel nonparametric graph-based methods
	to tackle these problems. Our methods rely on graph connectivity
	analysis and soft harmonic solution. Finally, we conduct an extensive
	human evaluation study of our conditional anomaly methods by 15 experts
	in critical care.</p></div> 
<!-- <span class="citation-count">[1+2 citations]</span>  -->
</li>


<li><strong>Michal Valko</strong>,
Hamed Valizadegan, Branislav Kveton, Gregory F. Cooper, Milos Hauskrecht:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2011conditional.pdf"><em>Conditional Anomaly Detection Using Soft Harmonic Functions: An Application to Clinical Alerting</em></a>, Workshop on Machine Learning for Global Challenges in <a href="http://www.icml-2011.org/">International Conference on Machine Learning</a> (<span class="conference-shortcut">ICML 2011 - Global</span>)   <a href="http://researchers.lille.inria.fr/~valko/hp/publications/valko2011conditional.bib">bibtex</a><a onclick="wipeToggle(&#39;valko2011conditional_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="valko2011conditional_abstract" style="display: none"> <p><em>  Abstract:</em>Timely detection of concerning events is an important problem in clinical
	practice. In this paper, we consider the problem of conditional anomaly
	detection that aims to identify data instances with an unusual response,
	 such as the omission of an important lab test. We develop a new
	non-parametric approach for conditional anomaly detection based on
	the soft harmonic solution, with which we estimate the confidence
	of the label to detect anomalous mislabeling. We further regularize
	the solution to avoid the detection of isolated examples and examples
	on the boundary of the distribution support. We demonstrate the efficacy
	of the proposed method in detecting unusual labels on a real-world
	electronic health record dataset and compare it to several baseline
	approaches.</p></div> 
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2011conditional.poster.pdf">poster</a> 
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2011conditional.spotlight.pdf">spotlight</a> 
<!-- <span class="citation-count">[0+1 citations]</span>  -->
</li>

</ul>
<h2>2010</h2>
<ul class="publications-list">

<li>
<strong>Michal Valko</strong>, Branislav Kveton, Ling Huang, Daniel Ting: 
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2010online.pdf"><em>Online Semi-Supervised Learning on Quantized Graphs</em></a> in 
<a href="http://event.cwi.nl/uai2010/">Uncertainty in Artificial Intelligence</a>
(<span class="conference-shortcut">UAI 2010</span>)   <a href="http://researchers.lille.inria.fr/~valko/hp/publications/valko2010online.bib">bibtex</a><a onclick="wipeToggle(&#39;valko2010online_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="valko2010online_abstract" style="display: none"> <p><em>  Abstract:</em>In this paper, we tackle the problem of online semi-supervised learning
	(SSL). When data arrive in a stream, the dual problems of computation
	and data storage arise for any SSL method. We propose a fast approximate
	online SSL algorithm that solves for the harmonic solution on an
	approximate graph. We show, both empirically and theoretically, that
	good behavior can be achieved by collapsing nearby points into a
	set of local "representative points" that minimize distortion. Moreover,
	we regularize the harmonic solution to achieve better stability properties.
	We apply our algorithm to face recognition and optical character
	recognition applications to show that we can take advantage of the
	manifold structure to outperform the previous methods. Unlike previous
	heuristic approaches, we show that our method yields provable performance
	bounds.</p></div> 
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kveton2009nipsdemo.adaptation.mov">Video: Adaptation</a>, 
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kveton2009nipsdemo.officespace.mov">Video: OfficeSpace</a>,
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2010online.spotlight.pdf">spotlight</a>
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2010online.poster.pdf">poster</a>
<!-- <span class="citation-count">[3+2 citations]</span>  -->
</li>

<li>Branislav Kveton, <strong>Michal Valko</strong>, Ali Rahimi, Ling Huang:
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kveton2010semi-supervised.pdf"><em>Semi-Supervised Learning with Max-Margin Graph Cuts</em></a> in 
<a href="http://www.aistats.org/">International Conference on Artificial Intelligence and Statistics</a>
(<span class="conference-shortcut">AISTATS 2010</span>)   <a href="http://researchers.lille.inria.fr/~valko/hp/publications/kveton2010semi-supervised.bib">bibtex</a><a onclick="wipeToggle(&#39;kveton2010semi-supervised_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="kveton2010semi-supervised_abstract" style="display: none"> <p><em>  Abstract:</em>This paper proposes a novel algorithm for semisupervised learning.
	This algorithm learns graph cuts that maximize the margin with respect
	to the labels induced by the harmonic function solution. We motivate
	the approach, compare it to existing work, and prove a bound on its
	generalization error. The quality of our solutions is evaluated on
	a synthetic problem and three UCI ML repository datasets. In most
	cases, we outperform manifold regularization of support vector machines,
	which is a state-of-the-art approach to semi-supervised max-margin
	learning.</p></div> 
<!-- <span class="citation-count">[3+3 citations]</span> -->
</li>


<li> Milos Hauskrecht, <strong>Michal Valko</strong>, Shyam Visweswaram, Iyad Batal, Gilles Clermont, Gregory Cooper: 
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/hauskrecht2010conditional.pdf"><em>Conditional Outlier Detection for Clinical Alerting</em></a> in Annual American Medical Informatics Association  conference 
(<span class="conference-shortcut">AMIA 2010</span>)  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/hauskrecht2010conditional.bib">bibtex</a><a onclick="wipeToggle(&#39;hauskrecht2010conditional_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="hauskrecht2010conditional_abstract" style="display: none"> <p><em>  Abstract:</em>We develop and evaluate a data-driven approach for detecting unusual (anomalous) patient-management actions using past patient cases stored in an electronic health record (EHR) system. Our hypothesis is that patient-management actions that are unusual with respect to past patients may be due to a potential error and that it is worthwhile to raise an alert if such a condition is encountered. We evaluate this hypothesis using data obtained from the electronic health records of 4,486 post-cardiac surgical patients. We base the evaluation on the opinions of a panel of experts. The results support that anomaly-based alerting can have reasonably low false alert rates and that stronger anomalies are correlated with higher alert rates.</p></div> 
<span style="color: #CC3333">[Homer Warner Best Paper <a href="http://en.wikipedia.org/wiki/Homer_R._Warner#Homer_R._Warner_award">Award</a>]</span>
<!-- <span class="citation-count">[3+2 citations]</span>  -->
</li>


<li>Branislav Kveton, <strong>Michal Valko</strong>, Matthai Phillipose, Ling Huang:
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kveton2010online.pdf"><em>Online Semi-Supervised Perception: Real-Time Learning without Explicit Feedback</em></a> in 
<a href="http://www.porikli.com/OLCV2010/olcv2010.html">IEEE Online Learning for Computer Vision Workshop in The
	IEEE Conference on Computer Vision and Pattern Recognition</a>
(<span class="conference-shortcut">CVPR 2010 - OLCV</span>) 
<span style="color: #CC3333">[best paper Google  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=../projects/phd_awards/award_2010_olcv.jpg">Award</a>]</span>
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/kveton2010online.bib">bibtex</a><a onclick="wipeToggle(&#39;kveton2010online_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="kveton2010online_abstract" style="display: none"> <p><em>  Abstract:</em>This paper proposes an algorithm for real-time learning without explicit
	feedback. The algorithm combines the ideas of semi-supervised learning
	on graphs and online learning. In particular, it iteratively builds
	a graphical representation of its world and updates it with observed
	examples. Labeled examples constitute the initial bias of the algorithm
	and are provided offline, and a stream of unlabeled examples is collected
	online to update this bias. We motivate the algorithm, discuss how
	to implement it efficiently, prove a regret bound on the quality
	of its solutions, and apply it to the problem of real-time face recognition.
	Our recognizer runs in real time, and achieves superior precision
	and recall on 3 challenging video datasets.</p></div> 
<!-- <span class="citation-count">[3 + 2 citations]</span> -->
</li>


<li><strong>Michal Valko</strong>, Milos Hauskrecht:
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2010feature.pdf"><em>Feature importance analysis for patient management decisions</em></a> in
<a href="http://www.imia-medinfo.org/medinfo2010/">International Congress on Medical Informatics</a>
(<span class="conference-shortcut">MEDINFO 2010</span>)   <a href="http://researchers.lille.inria.fr/~valko/hp/publications/valko2010feature.bib">bibtex</a><a onclick="wipeToggle(&#39;valko2010feature_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="valko2010feature_abstract" style="display: none"> <p><em>  Abstract:</em>The objective of this paper is to understand what characteris-tics
	and features of clinical data influence physician.s deci-sion about
	ordering laboratory tests or prescribing medica-tions the most. We
	conduct our analysis on data and decisions extracted from electronic
	health records of 4486 post-surgical cardiac patients. The summary
	statistics for 335 different lab order decisions and 407 medication
	decisions are reported. We show that in many cases, physician.s lab-order
	and medication decisions are predicted well by simple patterns such
	as last value of a single test result, time since a certain lab test
	was ordered or time since certain procedure was executed.</p></div> 
<!-- <span class="citation-count">[3 + 1 citations]</span>  -->
</li>

</ul>
<h2>2008</h2>
<ul class="publications-list">


<li><strong>Michal Valko</strong>,
  Gregory Cooper, Amy Seybert, 
  Shyam Visweswaran, Melissa Saul, Milos Hauskrecht:
 <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2008conditional.pdf"><em>Conditional anomaly detection methods for patient-management alert systems</em></a>, Workshop on Machine Learning in Health Care Applications in <a href="http://icml2008.cs.helsinki.fi/">International Conference on Machine Learning</a> (<span class="conference-shortcut">ICML-2008 - MLHealth</span>)   <a href="http://researchers.lille.inria.fr/~valko/hp/publications/valko2008conditional.bib">bibtex</a><a onclick="wipeToggle(&#39;valko2008conditional_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="valko2008conditional_abstract" style="display: none"> <p><em>  Abstract:</em>Anomaly detection methods can be very useful in identifying unusual or interesting patterns in data. A recently proposed conditional anomaly detection framework extends anomaly detection to the problem of identifying anomalous patterns on a subset of attributes in the data. The anomaly always depends (is conditioned) on the value of remaining attributes. The work presented in this paper focuses on instance-based methods for detecting conditional anomalies. The methods rely on the distance metric to identify examples in the dataset that are most critical for detecting the anomaly. We investigate various metrics and metric learning methods to optimize the performance of the instance-based anomaly detection methods. We show the benefits of the instance-based methods on two real-world detection problems: detection of unusual admission decisions for patients with the community-acquired pneumonia and detection of unusual orders of an HPF4 test that is used to confirm Heparin induced thrombocytopenia - a life-threatening condition caused by the Heparin therapy.</p></div> 
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2008conditional.talk.pdf">talk</a>
<!-- <span class="citation-count">[2+3 citations]</span>  -->
</li>
  
 
<li><strong>Michal Valko</strong>, Milos Hauskrecht: <a href="http://researchers.lille.inria.fr/~valko/hp/publications/valko2008distance.pdf"><em>Distance metric learning for conditional anomaly detection</em></a>, <a href="http://www.cs.miami.edu/home/geoff/Conferences/FLAIRS-21/">International Florida AI Research Society Conference</a> (<span class="conference-shortcut">FLAIRS 2008</span>) 
    <a href="http://researchers.lille.inria.fr/~valko/hp/publications/valko2008distance.bib">bibtex</a><a onclick="wipeToggle(&#39;valko2008distance_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="valko2008distance_abstract" style="display: none"> <p><em>  Abstract:</em>Anomaly detection methods can be very useful in identifying unusual or interesting patterns in data. A recently proposed conditional anomaly detection framework extends anomaly detection to the problem of identifying anomalous patterns on a subset of attributes in the data. The anomaly always depends (is conditioned) on the value of remaining attributes. The work presented in this paper focuses on instance-based methods for detecting conditional anomalies. The methods depend heavily on the distance metric that lets us identify examples in the dataset that are most critical for detecting the anomaly. To optimize the performance of the anomaly detection methods we explore and study metric learning methods.  We evaluate the quality of our methods on the Pneumonia PORT dataset by detecting unusual admission decisions for patients with the community-acquired pneumonia. The results of our metric learning methods show an improved detection performance over standard distance metrics, which is very promising for building automated anomaly detection systems for variety of intelligent monitoring applications.</p></div><!--	<span class="citation-count">[0 + 3 citations]</span>  -->
</li>




<li><strong>Michal Valko</strong>, Richard Pelikan, Milos Hauskrecht: <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2008learning.pdf"><em>Learning predictive models for combinations of heterogeneous
proteomic data sources</em></a>, AMIA
  Summit on Translational Bioinformatics (<span class="conference-shortcut">STB  2008</span>)  <span style="color: #CC3333">[outstanding paper <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=../projects/phd_awards/amiaSTB2008award.jpg">award</a>]</span>   <a href="http://researchers.lille.inria.fr/~valko/hp/publications/valko2008learning.bib">bibtex</a><a onclick="wipeToggle(&#39;valko2008learning_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="valko2008learning_abstract" style="display: none"> <p><em>  Abstract:</em>Multiple technologies that measure expression levels of protein mixtures
	in the human body offer a potential for detection and understanding
	the disease. The recent increase of these technologies prompts researchers
	to evaluate the individual and combined utility of data generated
	by the technologies. In this work, we study two data sources to measure
	the expression of protein mixtures in the human body: whole-sample
	MS profiling and multiplexed protein arrays.  We investigate the
	individual and combined utility of these technologies by learning
	and testing a variety of classification models on the data from a
	pancreatic cancer study. We show that for the combination of these
	two (heterogeneous) datasets, classification models that work well
	on one of them individually fail on the combination of the two datasets.
	 We study and propose a class of model fusion methods that acknowledge
	the differences and try to reap most of the benefits from their combination.</p></div><a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2008learning.talk.pdf">talk</a>
</li>

</ul>
<h2>2007</h2>
<ul class="publications-list">

<li> Milos Hauskrecht, <strong>Michal Valko</strong>, Branislav Kveton, Shyam Visweswaram, Gregory Cooper: <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/hauskrecht2007evidence-based.pdf"><em>Evidence-based Anomaly Detection in Clinical Domains</em></a> in Annual American Medical Informatics Association  conference (<span class="conference-shortcut">AMIA 2007</span>).
  <span style="color: #CC3333">[nominated for the best paper award]  </span>  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/hauskrecht2007evidence-based.bib">bibtex</a><a onclick="wipeToggle(&#39;hauskrecht2007evidence-based_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="hauskrecht2007evidence-based_abstract" style="display: none"> <p><em>  Abstract:</em>Anomaly detection methods can be very useful in identifying interesting or concerning events. In this work, we develop and examine new probabilistic anomaly detection methods that let us evaluate management decisions for a specific patient and identify those decisions that are highly unusual with respect to patients with the same or similar condition. The statistics used in this detection are derived from probabilistic models such as Bayesian networks that are learned from a database of past patient cases. We evaluate our methods on the problem of detection of unusual hospitalization patterns for patients with community acquired pneumonia. The results show very encouraging detection performance with 0.5 precision at 0.53 recall and give us hope that these techniques may provide the basis of intelligent monitoring systems that alert clinicians to the occurrence of unusual events or decisions.</p></div> 
<!-- <span class="citation-count">[3+6 citations]</span>        -->
</li>


</ul>
<h2>2006</h2>
<ul class="publications-list">


<li> Wendy W. Chapman, John N. Dowling, Gregory F. Cooper, Milos Hauskrecht and <strong>Michal Valko</strong>: <em><a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/chapman2006comparison.pdf">A Comparison of Chief Complaints and Emergency Department Reports for Identifying Patients with Acute Lower Respiratory Syndrome</a></em> in 
  

   Proceedings of the National Syndromic Surveillance Conference
  (<span class="conference-shortcut">ISDS 2006</span>) 
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/chapman2006comparison.bib">bibtex</a><a onclick="wipeToggle(&#39;chapman2006comparison_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="chapman2006comparison_abstract" style="display: none"> <p><em>  Abstract:</em>Automated syndromic surveillance systems often classify patients into
	syndromic categories based on free-text chief complaints. Chief complaints
	(CC) demonstrate low to moderate sensitivity in identify-ing syndromic
	cases. Emergency Department (ED) reports promise more detailed clinical
	information that may increase sensitivity of detection.</p></div>  </li>
 

<li>  Miloš Hauskrecht, Richard Pelikan, <strong>Michal Valko</strong>, James Lyons-Weiler: <em><a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/hauskrecht2006fundamentals.pdf">Feature Selection and Dimensionality Reduction in Genomics and Proteomics</a></em>.  <a href="http://www.springer.com/west/home/life+sci/bioinformatics?SGWID=4-10031-22-173695541-0">Fundamentals of Data Mining in Genomics and Proteomics</a>, eds. Berrar, Dubitzky, Granzow. Springer (<span class="conference-shortcut">2006</span>) 
 <a href="http://researchers.lille.inria.fr/~valko/hp/publications/hauskrecht2006fundamentals.bib">bibtex</a><a onclick="wipeToggle(&#39;hauskrecht2006fundamentals_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="hauskrecht2006fundamentals_abstract" style="display: none"> <p><em>  Abstract:</em>Finding reliable, meaningful patterns in data with high numbers of attributes can be extremely difficult. Feature selection helps us to decide what attributes or combination of attributes are most important for finding these patterns. In this chapter, we study feature selection methods for building classification models from high-throughput genomic (microarray) and proteomic (mass spectrometry) data sets. Thousands of feature candidates must be analyzed, compared and combined in such data sets. We describe the basics of four different approaches used for feature selection and illustrate their effects on an MS cancer proteomic data set. The closing discussion provides assistance in performing an analysis in high-dimensional genomic and proteomic data.</p></div> 
<!-- <span class="citation-count">[5 + 1 citations]</span>       -->
</li> 

</ul>
<h2>2005</h2>
<ul class="publications-list">


  <li>
    <strong>Michal Valko</strong>, Nuno C. Marques, Marco Castelani:      <em>Evolutionary Feature Selection for Spiking Neural Network Pattern Classifiers</em>  
      in Proceedings of  Portuguese Conference on Artificial Intelligence (<a href="http://www.springer.com/us/book/9783540307372" class="conference-shortcut">EPIA 2005</a>), 
      eds. Bento et al.,  IEEE, pages 24-32.	  <a href="http://researchers.lille.inria.fr/~valko/hp/publications/valko2005evolutionary.bib">bibtex</a><a onclick="wipeToggle(&#39;valko2005evolutionary_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="valko2005evolutionary_abstract" style="display: none"> <p><em>  Abstract:</em>This paper presents an application of the biologically realistic JASTAP
	neural network model to classification tasks. The JASTAP neural network
	model is presented as an alternative to the basic multi-layer perceptron
	model. An evolutionary procedure previously applied to the simultaneous
	solution of feature selection and neural network training on standard
	multi-layer perceptrons is extended with JASTAP model. Preliminary
	results on IRIS standard data set give evidence that this extension
	allows the use of smaller neural networks that can handle noisier
	data without any degradation in classification accuracy.</p></div> 
<!--	<span class="citation-count">[5 + 0 citations]</span>  -->
 </li>

  <li>  
    <strong>Michal Valko</strong> <em><a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=../projects/thesis/nesdt.pdf">Evolving Neural Networks for Statistical Decision Theory</a></em>, 
	Comenius University, Bratislava, 2005
    (master thesis) (<span class="conference-shortcut">2005</span>) Advisor: Radoslav Harman 
	<a href="http://diplomovka.sme.sk/en/diploma/2455/evolving-neural-networks-for-statistical-decision-theory.php">thesis@sk</a> 
	<a href="http://researchers.lille.inria.fr/~valko/hp/publications/valko2005evolving.bib">bibtex</a><a onclick="wipeToggle(&#39;valko2005evolving_abstract&#39;)"> abstract <img src="./Michal Valko - Research_files/text.gif" alt="abstract"></a><div id="valko2005evolving_abstract" style="display: none"> <p><em>  Abstract:</em>Real biological networks are able to make decisions. We will show
	that this behavior can be observed even in some simple architectures
	of biologically plausible neural models. The great interest of this
	thesis is also to contribute to methods of statistical decision theory
	by giving a lead how to evolve the neural networks to solve miscellaneous
	decision tasks.</p></div> 
    <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=../projects/thesis/defense-nesdt.pdf">talk</a> 
<!--    <span class="citation-count">[3 citations]</span>  -->
</li>
</ul>&lt;





<h2>Presentations</h2>
<ul id="presentations-list">

<li><strong>Michal Valko:</strong> <em>Graph-Based Anomaly Detection with Soft Harmonic Functions</em>: Presented at 
CS Department Research Competition  (<span class="conference-shortcut">Research 2011</span>) <span style="color: #CC3333">[<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=../projects/phd_awards/award_2011_research.jpg">#1st place</a>]  </span>
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2011csresearch.talk.pdf">talk</a>
also at  (<span class="conference-shortcut">Grad Expo 2011</span>) and  (<span class="conference-shortcut">CS DAY 2011</span>)
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2011csday.poster.pdf">poster</a>
</li>

<li>
Branislav Kveton, <strong>Michal Valko</strong>, Matthai Philiposse: <em>Real-Time Adaptive Face Recognition</em>, Presented at 
23rd Neural Information Processing Systems conference   <a href="https://nips.cc/Conferences/2009/Schedule">(<span class="conference-shortcut">NeurIPS 2009</span>)</a>, 
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kveton2009nipsdemo.adaptation.mov">Video: Adaptation</a>, 
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kveton2009nipsdemo.officespace.mov">Video: OfficeSpace</a>,
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/kveton2009nipsdemo.poster.pdf">poster #1</a>,
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2009nipsdemo.poster.pdf">poster #2</a>
</li>

<li><strong>Michal Valko:</strong>, Branislav Kveton, Matthai Philiposse:  <em>Robust Face Recognition Using Online Learning</em>, Presented at 
9th University of Pittsburgh Science conference  <a href="http://www.science2009.pitt.edu/">(<span class="conference-shortcut">SCIENCE 2009</span>)</a>
Live Demonstration
(<span class="conference-shortcut">Grad Expo 2010</span>) 
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2010robust.talk.pdf">talk</a>
and  (<span class="conference-shortcut">CS Day 2010</span>)  <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2010robust.poster.pdf">poster</a>
</li>


<li><strong>Michal Valko:</strong> <em> Conditional anomaly detection with adaptive similarity metric</em>: Presented at 
CS Department Research Competition  (<span class="conference-shortcut">Research 2008</span>) <span style="color: #CC3333">[<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=../projects/phd_awards/award_2008_research.jpg">#1st place</a>]  </span>
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2008csresearch.talk.pdf">talk</a>
</li>

<li>
<strong>Michal Valko</strong>, Milos Hauskrecht, G. Cooper, S. Visweswaran, M. Saul, A. Seybert,  J. Harrison, A. Post:
<em>Conditional Anomaly Detection</em>, Presented at (<span class="conference-shortcut">CS Day 2008</span>)
 <span style="color: #CC3333">[<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=../projects/phd_awards/award_2008_cs_day_poster_winner.jpg">#1st by people</a>, <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=../projects/phd_awards/award_2008_cs_day_poster_runner_up.jpg">#2nd by faculty</a>] </span> also at University of Pittsburgh, Arts &amp; Sciences (<span class="conference-shortcut">Grad Expo 2008</span>)
<a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/valko2008csday.poster.pdf">poster</a>
</li>
</ul>

<!-- </ul> -->

<h2>References</h2><ul> <li> <a href="http://researchers.lille.inria.fr/~valko/hp/serve.php?what=publications/library.bib">bibtex file</a> with references I often use </li> </ul>

			<div id="modified">23-Jan-2021</div>
	  </div>
	</div></div>
	<div id="downlt"><div id="downrt"><div id="down"></div></div></div>

	</body></html>