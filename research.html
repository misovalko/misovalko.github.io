<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd" >
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" >
	<head>
		<meta name="author" content="valko" />
		<meta name="keywords" content="Michal, Valko, Michal Valko, CS, Pitt, homepage, fmph, fmfi, uk, alejova, oktava " />
		<meta name="description" content="Michal Valko's homepage." />
		<meta http-equiv="Content-Type" content="application/xhtml+xml; charset=utf-8" />
		<title>Michal Valko  - Research</title>
 		<link rel="shortcut icon" href="images/micon6.jpg" /> 	
		<link rel="stylesheet" href="luky.css" title="base" type="text/css" />
		<link href='http://fonts.googleapis.com/css?family=Galdeano' rel='stylesheet' type='text/css'>
		<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-306495-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
	</head>
	<body>
	<div id="supertoplt"><div id="supertoprt"><div id="supertop"></div></div></div>
	<div id="lt"><div id="rt">
	<div id="top"><span class="nadpis">Michal Valko : Research</span></div>
	  <div id="menu">
	    <div class="menulink">
				    <a href="index.html">Intro</a>
				    <a href="research.html">Publications</a>
<!--			    <a href="project.php">Projects</a> -->	
					<a href="press.html">Press</a>
					<a href="talks.html">Talks</a> 	
				    <a href="service.html">Service</a>
				    <a href="experience.html">Experience</a>
<!--			    <a href="mva-ml-graphs.php">Teaching (MVA)</a>	-->			    					
			  	    </div> 
			<br />
			<span class="male">michal.valko#inria.fr</span>
		<div id="menuicons">
	    </div>
		<div class="centered">
		<a href="images/gr20.jpg"><img src="images/mvgr20.jpg" alt="mv" /></a>
		<br /><br />
		<a href="https://deepmind.com/"><img src="images/DM_RGB_Lockup_Blue.png" alt="DeepMind" height="35" /></a><br /><br />	
		<a href="https://team.inria.fr/sequel/team-members/"><img src="images/sequel.jpg" alt="SequeL" height="25" /></a><br /><br />
		<a href="http://www.inria.fr/centre/lille"><img src="images/INRIA-CORPO-CMJN.jpg" alt="inria" height="40"/></a><br /><br /><br />
		<a href="https://team.inria.fr/sequel/team-members/"><img src="images/vstudents.jpeg" width="65" alt="students"/></a>
		</div>
	  </div> 
	  <div id="content"> 



<!-- 
http://haltools.inria.fr/Public/afficheRequetePubli.php?auteur_exp=Michal,%20Valko&CB_auteur=oui&CB_titre=oui&CB_article=oui&langue=Anglais&tri_exp=annee_publi&tri_exp2=typdoc&tri_exp3=date_publi&ordre_aff=TA&Fen=Aff&css=../css/styles_publicationsHAL.css
-->


<!--<h2>Selected Publications</h2> -->
<!-- <ul id="starred-publications-list">
<? //require("selected_publications.php") ?>
</ul> -->
<!--<h2>Other Publications</h2> -->
<!-- <ul id="publications-list"> -->
My 
<a href="http://scholar.google.com/citations?user=jrazNCQAAAAJ&sortby=pubdate">Google Scholar profile</a>,
<a href="https://www.deepmind.com/research?*=Michal+Valko">DeepMind profile</a>,
<a href="https://arxiv.org/search/?query=Valko%2C+Michal&searchtype=author&abstracts=show&order=-announced_date_first&size=100">ArXiv profile</a>,
and 
<a href="https://hal.inria.fr/search/index/?qa[auth_t][]=Michal+Valko&sort=producedDateY_i+desc">HAL profile</a>.


<h2>preprints</h2>
<ul class="publications-list">
	
		<li>Denis Belomestny, Pierre Ménard, Alexey Naumov, Daniil Tiapkin, <strong>Michal Valko</strong>:
		  <aa href="publications/azabou2021mine.pdf"><em>
	Sharp deviations bounds for Dirichlet weighted sums with application to analysis of Bayesian algorithms</em></aa>,
		  <a href="https://arxiv.org/abs/2304.03056">arXiv preprint</a>
		</li>
	
	
		<li>Alaa Saade, Steven Kapturowski, Daniele Calandriello, Charles Blundell, Pablo Sprechmann, Leopoldo Sarra, Oliver Groth, <strong>Michal Valko</strong>, Bilal Piot:
		  <aa href="publications/azabou2021mine.pdf"><em>
	Unlocking the power of representations in long-term novelty-based exploration</em></aa>,
		  <a href="https://arxiv.org/abs/2305.01521">arXiv preprint</a>
		</li>
	

	<li>Tadashi Kozuno, Wenhao Yang, Nino Vieillard, Toshinori Kitamura, Yunhao Tang, Jincheng Mei, Pierre Ménard, Mohammad Gheshlaghi Azar, <strong>Michal Valko</strong>, Rémi Munos, Olivier Pietquin, Matthieu Geist, Csaba Szepesvári:
	  <aa href="publications/azabou2021mine.pdf"><em>
KL-entropy-regularized RL with a generative model is minimax optimal</em></aa>,
	  <a href="https://arxiv.org/abs/2205.14211">arXiv preprint</a>
	</li>	
 	
	</ul>

	<h2>2023</h2>
	<ul class="publications-list">

		<li>Daniel Jarrett, Corentin Tallec, Florent Altché, Thomas Mesnard, Rémi Munos, <strong>Michal Valko</strong>:
		  <a href="publications/jarrett2022curiosity.pdf"><em>Curiosity in hindsight: Intrinsic exploration in stochastic environments</em></a>, 
	      in <a href="https://icml.cc/Conferences/2023">International Conference on Machine Learning</a> 
	       (<span class="conference-shortcut">ICML 2023</span>)
		   (<span class="conference-shortcut-more">NeurIPS 2022 - DeepRL</span>),
		      <a href="https://arxiv.org/abs/2211.10515">arXiv preprint</a>
		</li>		
	
	<li>Yunhao Tang, Rémi Munos, Mark Rowland, <strong>Michal Valko</strong>:
	  <aa href="publications/tang2022marginalized.pdf"><em>VA-learning as a more efficient alternative to Q-learning</em></aa>,
    in <a href="https://icml.cc/Conferences/2023">International Conference on Machine Learning</a> 
     (<span class="conference-shortcut">ICML 2023</span>) 
	</li>
	
		<li>Daniil Tiapkin, Denis Belomestny, Daniele Calandriello, Éric Moulines, Rémi Munos, Alexey Naumov, Pierre Perrault, Yunhao Tang, <strong>Michal Valko</strong>, Pierre Ménard:
		  <aa href="publications/tiapkin2022optimistic.pdf"><em>
	Fast rates for maximum entropy exploration</em></aa>,
    in <a href="https://icml.cc/Conferences/2023">International Conference on Machine Learning</a> 
     (<span class="conference-shortcut">ICML 2023</span>) 
		   <a href="https://arxiv.org/abs/2303.08059">arXiv preprint</a>
		</li>

	<li>Côme Fiegel, Pierre Ménard, Tadashi Kozuno, Rémi Munos, Vianney Perchet, <strong>Michal Valko</strong>:
	  <aa href="publications/fiegel2022adapting.pdf"><em>
Adapting to game trees in zero-sum imperfect information games</em></aa>,
    in <a href="https://icml.cc/Conferences/2023">International Conference on Machine Learning</a> 
     (<span class="conference-shortcut">ICML 2023</span>) [<span style="color: #CC3333">oral - x% acceptance rate</span>]
	  <a href="https://arxiv.org/abs/2212.12567">arXiv preprint</a>
	</li>	


	<li>Yunhao Tang, Zhaohan Daniel Guo, Pierre Harvey Richemond, Bernardo Ávila Pires, Yash Chandak, Rémi Munos, Mark Rowland, Mohammad Gheshlaghi Azar, Charline Le Lan, Clare Lyle, András György, Shantanu Thakoor, Will Dabney, Bilal Piot, Daniele Calandriello, <strong>Michal Valko</strong>:
	  <aa href="publications/tang2022understanding.pdf"><em>
Understanding self-predictive learning for reinforcement learning</em></aa>,
    in <a href="https://icml.cc/Conferences/2023">International Conference on Machine Learning</a> 
     (<span class="conference-shortcut">ICML 2023</span>)
	  <a href="https://arxiv.org/abs/2212.03319">arXiv preprint</a>
	</li>	

	<li>Yunhao Tang, Tadashi Kozuno, Mark Rowland, Anna Harutyunyan, Rémi Munos, Bernardo Ávila Pires, <strong>Michal Valko</strong>:
	  <aa href="publications/tang2022marginalized.pdf"><em>DoMo-AC: Doubly multi-step off-policy actor-critic algorithm</em></aa>,
    in <a href="https://icml.cc/Conferences/2023">International Conference on Machine Learning</a> 
     (<span class="conference-shortcut">ICML 2023</span>) 
	</li>
	
	
	<li>
		Toshinori Kitamura, Tadashi Kozuno, Yunhao Tang, Nino Vieillard, Michal Valko, Wenhao Yang, Jincheng Mei, Pierre Ménard, Mohammad Gheshlaghi Azar, Rémi Munos, Olivier Pietquin, Matthieu Geist, Csaba Szepesvári, Wataru Kumagai:
	  <aa href="publications/azabou2021mine.pdf"><em>
Regularization and variance-weighted regression achieves minimax optimality in linear MDPs: Theory and practice</em></aa>,
    in <a href="https://icml.cc/Conferences/2023">International Conference on Machine Learning</a> 
     (<span class="conference-shortcut">ICML 2023</span>)
	</li>	
 

		


	<li>Thomas Mesnard, Wenqi Chen, Alaa Saade, Yunhao Tang, Mark Rowland, Theophane Weber, Clare Lyle, Audrunas Gruslys, <strong>Michal Valko</strong>, Will Dabney, Georg Ostrovski, Éric Moulines, Rémi Munos:
	  <aa href="publications/azabou2021mine.pdf"><em>Quantile credit assignment</em></aa>,
    in <a href="https://icml.cc/Conferences/2023">International Conference on Machine Learning</a> 
     (<span class="conference-shortcut">ICML 2023</span>) [<span style="color: #CC3333">oral - x% acceptance rate</span>]
	</li>	
 
	<li>Mehdi Azabou, Venkataramana Ganesh, Shantanu Thakoor, Chi-Heng Lin, Lakshmi Sathidevi, Ran Liu, <strong>Michal Valko</strong>, Petar Veličković, Eva L Dyer:
	  <aa href="publications/azabou2021mine.pdf"><em>Half-Hop: A graph upsampling approach for slowing down message passing</em></aa>,
    in <a href="https://icml.cc/Conferences/2023">International Conference on Machine Learning</a> 
     (<span class="conference-shortcut">ICML 2023</span>)
	</li>	


</ul>

<h2>2022</h2>,
<ul class="publications-list">
	

	
	
		<li>Zhaohan Daniel Guo, Shantanu Thakoor, Miruna Pîslar, Bernardo Ávila Pires, Florent Altché, Corentin Tallec, Alaa Saade, Daniele Calandriello, Jean-Bastien Grill, Yunhao Tang, <strong>Michal Valko</strong>, Rémi Munos, Mohammad Gheshlaghi Azar, Bilal Piot:
		  <a href="publications/guo2022byol.pdf"><em>
	BYOL-Explore: Exploration by bootstrapped prediction</em></a>, in <a href="https://neurips.cc/Conferences/2022/">Neural Information Processing Systems</a> 
		   (<span class="conference-shortcut">NeurIPS 2022</span>)
		  <a href="https://arxiv.org/abs/2206.08332">arXiv preprint</a>
		   <a href="publications/guo2022byol.poster.pdf">poster</a>
			     <a href="publications/guo2022byol.talk.pdf">talk</a>    
		</li>

		<li>Daniil Tiapkin, Denis Belomestny, Daniele Calandriello, Éric Moulines, Rémi Munos, Alexey Naumov, Mark Rowland, <strong>Michal Valko</strong>, Pierre Ménard:
		  <a href="publications/tiapkin2022optimistic.pdf"><em>
	Optimistic posterior sampling for reinforcement learning with few samples and tight guarantees</em></a>, in <a href="https://neurips.cc/Conferences/2022/">Neural Information Processing Systems</a> 
		   (<span class="conference-shortcut">NeurIPS 2022</span>),
		   <a href="https://arxiv.org/abs/2209.14414">arXiv preprint</a>
		   	   <a href="publications/tiapkin2022optimistic.poster.pdf">poster</a>
  	     <a href="publications/tiapkin2022optimistic.talk.pdf">talk</a> </li>
		   
		</li>
		


	   	 <li>Daniil Tiapkin, Denis Belomestny, Éric Moulines, Alexey Naumov, Sergey Samsonov, Yunhao Tang,
	 <strong>Michal Valko</strong>, Pierre Ménard:   
	    <a href="publications/tiapkin2022dirichlet.pdf"><em>
	   	From Dirichlet to Rubin: Optimistic exploration in RL without bonuses</em></a>,
	     in <a href="https://icml.cc/Conferences/2022">International Conference on Machine Learning</a> 
	      (<span class="conference-shortcut">ICML 2022</span>)
	     [<span style="color: #CC3333">long talk - 2% acceptance rate</span>]
	  <a href="https://arxiv.org/abs/2205.07704">arXiv preprint</a>,
	     <a href="publications/tiapkin2022dirichlet.talk.pdf">talk</a> 
		    	   <a href="publications/tiapkin2022dirichlet.poster.pdf">poster</a>
	 </li>

	   	 <li>Anirudh Goyal, Abram L Friesen, Theophane Weber, Andrea Banino, Nan Rosemary Ke, Adria Puigdomenech Badia, Ksenia Konyushkova, <strong>Michal Valko</strong>, Simon Osindero, Timothy P Lillicrap, Nicolas Heess, Charles Blundell:
	   	  <a href="publications/goyal2022retrieval.pdf"><em>
	   	Retrieval-augmented reinforcement learning</em></a>, 
	     in <a href="https://icml.cc/Conferences/2022">International Conference on Machine Learning</a> 
	      (<span class="conference-shortcut">ICML 2022</span>)
	     <a href="https://arxiv.org/abs/2202.08417">arXiv preprint</a></li>
	
	

	 	 <li>Daniele Calandriello, Luigi Carratino, Alessandro Lazaric, <strong>Michal Valko</strong>, Lorenzo Rosasco:
	 	  <a href="publications/calandriello2022scaling.pdf"><em>
	 	Scaling Gaussian process optimization by evaluating a few unique
	 	 candidates multiple times</em></a>, 
	      in <a href="https://icml.cc/Conferences/2022">International Conference on Machine Learning</a> 
	       (<span class="conference-shortcut">ICML 2022</span>)
	   <a href="http://arxiv.org/abs/2201.12909">arXiv preprint</a>,
	   <a href="publications/calandriello2022scaling.talk.pdf">talk</a> 
     <a href="publications/calandriello2022scaling.poster.pdf">poster</a>
   </li>


<li>Shantanu Thakoor, Corentin Tallec, Mohammad Gheshlaghi Azar, Mehdi Azabou, Eva L. Dyer,  Rémi Munos, Petar Veličković, <strong>Michal Valko</strong>:
  <a href="publications/thakoor2022bootstrapped.pdf"><em>
Large-scale representation learning on graphs via bootstrapping</em></a>,
	in <a href="https://aistats.org/">International Conference on Learning Representations</a> 
   (<span class="conference-shortcut">ICLR 2022</span>)
   (<span class="conference-shortcut-more">ICLR 2021 - GTRL</span>) 
     <a href="https://arxiv.org/abs/2102.06514">arXiv preprint</a>
	   <a href="publications/thakoor2022bootstrapped.poster.pdf ">poster</a>
</li>	



<li>Jean Tarbouriech, Omar Darwiche Domingues, Pierre Ménard, Matteo Pirotta, <strong>Michal Valko</strong>, Alessandro Lazaric:
  <a href="publications/tarbouriech2022adaptive.pdf"><em>
Adaptive multi-goal exploration</em></a>, 
	 (<span class="conference-shortcut">AISTATS 2022</span>)
 <a href="https://arxiv.org/abs/2111.12045">arXiv preprint</a>
</li>

<li>Yunhao Tang, Mark Rowland, Rémi Munos, <strong>Michal Valko</strong>:
  <a href="publications/tang2022marginalized.pdf"><em>Marginalized operators for off-policy reinforcement learning</em></a>,
in <a href="https://aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2022</span>)
and (<span class="conference-shortcut-more">ICML 2021 - RL Theory</span>)
 <a href="https://arxiv.org/abs/2203.16177">arXiv preprint</a>
</li>	

</ul>



<h2>2021</h2>
<ul class="publications-list">

<li>Ran Liu, Mehdi Azabou, Max Dabagia, Chi-Heng Lin, Mohammad Gheshlaghi Azar, Keith B. Hengen, <strong>Michal Valko</strong>, Eva L. Dyer:
  <a href="publications/liu2021drop.pdf"><em>
Drop, Swap, and Generate: A self-supervised approach for generating neural activity</em></a>,
		in <a href="https://neurips.cc/Conferences/2021/">Neural Information Processing Systems</a> 
		   (<span class="conference-shortcut">NeurIPS 2021</span>)  [<span style="color: #CC3333">oral - 1% acceptance rate</span>]
	 <a href="https://arxiv.org/pdf/2111.02338">arXiv preprint</a>	   
	</li>
		  
	
	
<li>Jean Tarbouriech, Runlong Zhou, Simon S. Du, Matteo Pirotta, <strong>Michal Valko</strong>, Alessandro Lazaric:
  <a href="publications/tarbouriech2021stochastic.pdf"><em>
Stochastic shortest path: minimax, parameter-free and towards horizon-free regret</em></a>,
		in <a href="https://neurips.cc/Conferences/2021/">Neural Information Processing Systems</a> 
		   (<span class="conference-shortcut">NeurIPS 2021</span>)  <span style="color: #CC3333">spotlight - 3% acceptance rate</span>]
and (<span class="conference-shortcut-more">ICML 2021 - RL Theory</span>),
 <a href="https://arxiv.org/pdf/2104.11186">arXiv preprint</a>,
<a href="publications/tarbouriech2021stochastic.talk.pdf">talk</a> 
<a href="https://youtu.be/6mo4uT_Iavc">video</a>
</li>

<li>Jean Tarbouriech, Matteo Pirotta, <strong>Michal Valko</strong>, Alessandro Lazaric:
  <a href="publications/tarbouriech2021provably.pdf"><em>
A provably efficient sample collection strategy for reinforcement learning</em></a>,
		in <a href="https://neurips.cc/Conferences/2021/">Neural Information Processing Systems</a> 
		   (<span class="conference-shortcut">NeurIPS 2021</span>)  <span style="color: #CC3333">spotlight - 3% acceptance rate</span>] 
  <a href="https://arxiv.org/abs/2007.06437">arXiv preprint,</a>
<a href="publications/tarbouriech2021provably.bib">bibtex</a></li>

	
<li>Tadashi Kozuno*, Pierre Ménard*, Rémi Munos, <strong>Michal Valko</strong>:
  <a href="publications/kozuno2021model-free.pdf"><em>
Model-free learning for two-player zero-sum partially observable Markov games with perfect recall</em></a>,
		in <a href="https://neurips.cc/Conferences/2021/">Neural Information Processing Systems</a> 
		   (<span class="conference-shortcut">NeurIPS 2021</span>) 
  <a href="https://arxiv.org/abs/2106.06279">arXiv preprint</a>,
       <a href="publications/kozuno2021model-free.talk.pdf">talk</a> 
	     <a href="publications/kozuno2021model-free.poster.pdf ">poster</a>
</li>	
	
<li>Yunhao Tang*, Tadashi Kozuno*,  Mark Rowland, Rémi Munos, <strong>Michal Valko</strong>:
  <a href="publications/tang2021unifying.pdf"><em>
Unifying gradient estimators for meta-reinforcement learning via off-policy evaluation</em></a>,
		in <a href="https://neurips.cc/Conferences/2021/">Neural Information Processing Systems</a> 
		   (<span class="conference-shortcut">NeurIPS 2021</span>) 
  <a href="https://arxiv.org/abs/2106.13125">arXiv preprint</a>
</li>

		
		
		
	
	
<li>Adrià Recasens, Pauline Luc, Jean-Baptiste Alayrac, Luyu Wang, Florian Strub, Corentin Tallec, Mateusz Malinowski, Viorica Patraucean, Florent Altché, <strong>Michal Valko</strong>, Jean-Bastien Grill, Aäron van den Oord, Andrew Zisserman:
  <a href="publications/recasens2021broaden.pdf"><em>
Broaden your views for self-supervised video learning</em></a>, in 
 <a href="http://iccv2021.thecvf.com/home"> International Conference on Computer Vision</a> 
   (<span class="conference-shortcut">ICCV 2021</span>)
  <a href="https://arxiv.org/abs/2103.16559">arXiv preprint</a>
  	     <a href="publications/recasens2021broaden.poster.pdf ">poster</a>
</li>	
	

<li>Pierre Ménard, Omar Darwiche Domingues, Xuedong Shang, <strong>Michal Valko</strong>:
  <a href="publications/menard2021ucb.pdf"><em>
UCB Momentum Q-learning: Correcting the bias without forgetting</em></a>,
  in <a href="https://icml.cc/Conferences/2021">International Conference on Machine Learning</a> 
   (<span class="conference-shortcut">ICML 2021</span>)
  [<span style="color: #CC3333">long talk - 3% acceptance rate</span>] 
  <a href="https://arxiv.org/abs/2103.01312">arXiv preprint</a>
      <a href="publications/menard2021ucb.poster.pdf">poster</a>
     <a href="publications/menard2021ucb.talk.pdf">talk</a> 
</li>	


<li>Pierre Ménard, Omar Darwiche Domingues, Emilie Kaufmann, Anders Jonsson, Edouard Leurent, <strong>Michal Valko</strong>:
  <a href="publications/menard2021fast.pdf"><em>
Fast active learning for pure exploration in reinforcement learning</em></a>,
  in <a href="https://icml.cc/Conferences/2021">International Conference on Machine Learning</a> 
   (<span class="conference-shortcut">ICML 2021</span>)
  <a href="https://arxiv.org/abs/2007.13442">arXiv preprint,</a>
<a href="publications/menard2021fast.bib">bibtex</a></li>	


<li>Tadashi Kozuno, Yunhao Tang, Mark Rowland, Rémi Munos, Steven Kapturowski, Will Dabney, <strong>Michal Valko</strong>, David Abel:
  <a href="publications/kozuno2021revisiting.pdf"><em>
Revisiting Peng's Q(λ) for for modern reinforcement learning</em></a>,
  in <a href="https://icml.cc/Conferences/2021">International Conference on Machine Learning</a> 
   (<span class="conference-shortcut">ICML 2021</span>)
  <a href="https://arxiv.org/abs/2103.00107">arXiv preprint</a>
<a href="publications/kozuno2021revisiting.bib">bibtex</a></li>	




<li>Yunhao Tang, Mark Rowland, Rémi Munos, <strong>Michal Valko</strong>:
  <a href="publications/tang2021taylor.pdf"><em>
Taylor expansion of discount factors</em></a>,
  in <a href="https://icml.cc/Conferences/2021">International Conference on Machine Learning</a> 
   (<span class="conference-shortcut">ICML 2021</span>)
     <a href="https://arxiv.org/abs/2106.06170">arXiv preprint</a>



<li>Xavier Fontaine, Pierre Perrault, <strong>Michal Valko</strong>, Vianney Perchet:
  <a href="publications/fontaine2021online.pdf"><em>
Online A-optimal design and active linear regression</em></a>,
  in <a href="https://icml.cc/Conferences/2021">International Conference on Machine Learning</a> 
   (<span class="conference-shortcut">ICML 2021</span>) 
 <a href="https://arxiv.org/abs/1906.08509">arXiv preprint</a>
  <a href="publications/fontaine2021online.poster.png">poster</a>

</li>

 <li>Omar Darwiche Domingues, Pierre Ménard, Matteo Pirotta,  Emilie Kaufmann, <strong>Michal Valko</strong>:
   <a href="publications/domingues2021kernel-based.pdf"><em>
 Kernel-based reinforcement Learning: A finite-time analysis</em></a>,  
 in <a href="https://icml.cc/Conferences/2021">International Conference on Machine Learning</a> 
  (<span class="conference-shortcut">ICML 2021</span>)
  <a href="https://arxiv.org/abs/2004.05599">arXiv preprint</a>
 <a href="publications/domingues2021kernel-based.bib">bibtex</a> </li>


	
	<li>Karl Tuyls, Shayegan Omidshafiei, Paul Muller, Zhe Wang, Jerome Connor, Daniel Hennes, Ian Graham, William Spearman, Tim Waskett, Dafydd Steele, Pauline Luc, Adria Recasens, Alexandre Galashov, Gregory Thornton, Romuald Elie, Pablo Sprechmann, Pol Moreno, Kris Cao, Marta Garnelo, Praneet Dutta, <strong>Michal Valko</strong>, Nicolas Heess, Alex Bridgland, Julien Perolat, Bart De Vylder, Ali Eslami, Mark Rowland, Andrew Jaegle, Remi Munos, Trevor Back, Razia Ahamed, Simon Bouton, Nathalie Beauguerlange, Jackson Broshear, Thore Graepel, Demis Hassabis:
	  <a href="publications/tuyls2021game.pdf"><em>
	Game plan: What AI can do for football, and what football can do for AI,</em></a>
		in <a href="https://www.jair.org/">Journal of Artificial Intelligence Research</a>
			  (<span class="conference-shortcut">JAIR 2021</span>)  
	  <a href="https://arxiv.org/abs/2011.09192">arXiv preprint</a>
		</li>	
	
	
	
	<li>Omar Darwiche Domingues, Pierre Ménard, Matteo Pirotta,  Emilie Kaufmann, <strong>Michal Valko</strong>:
	  <a href="publications/domingues2021kernel-based-non-stationary.pdf"><em>
	A kernel-based approach to non-stationary reinforcement learning in metric spaces</em></a>, in 
	in <a href="https://aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
	 (<span class="conference-shortcut">AISTATS 2021</span>) and
	 (<span class="conference-shortcut-more">ICML 2020 - RL Theory</span>) 	 [<span style="color: #CC3333">oral - 6% acceptance rate</span>]
	 <a href="https://arxiv.org/abs/2007.05078">arXiv preprint</a>  
	 <a href="https://youtu.be/jJBpyPbyjQA">video</a> 
	 	
	
	<li>Omar Darwiche Domingues, Pierre Ménard,  Emilie Kaufmann, <strong>Michal Valko</strong>:
	  <a href="publications/domingues2021episodic.pdf"><em>
	Episodic reinforcement learning in finite MDPs: Minimax lower bounds revisited</em></a>,
	 in  <a href="http://algorithmiclearningtheory.org/alt2021/">Algorithmic Learning Theory</a> 
	(<span class="conference-shortcut">ALT 2021</span>)
	  <a href="https://arxiv.org/abs/2010.03531">arXiv preprint</a>
	  <a href="https://youtu.be/WBGcrIW1ip8">video</a> 
	<a href="publications/domingues2021episodic.bib">bibtex</a>	</li>
	
	
	<li>Jean Tarbouriech, Matteo Pirotta, <strong>Michal Valko</strong>, Alessandro Lazaric:
	  <a href="publications/tarbouriech2021sample.pdf"><em>
	Sample complexity bounds for stochastic shortest path with a generative model</em></a>,
	 in  <a href="http://algorithmiclearningtheory.org/alt2021/">Algorithmic Learning Theory</a> 
	(<span class="conference-shortcut">ALT 2021</span>)
	 <a href="https://youtu.be/QICsAlS1BU8">video</a>    
	<? //php read_bib("tarbouriech2021sample");?>
	</li>
	
    <li>Emilie Kaufmann, Pierre Ménard, Omar Darwiche Domingues, Anders Jonsson, Edouard Leurent, <strong>Michal Valko</strong>:
      <a href="publications/kaufmann2021adaptive.pdf"><em>
    Adaptive reward-free exploration</em></a>, in 
      <a href="https://arxiv.org/abs/2006.06294">arXiv preprint</a>,
	   <a href="https://youtu.be/NDSsXQefvIA">video 1</a> 
      <a href="https://youtu.be/BeuLl5_cTu0">video 2</a> 	  
	  in  <a href="http://algorithmiclearningtheory.org/alt2021/">Algorithmic Learning Theory</a>  
	   (<span class="conference-shortcut">ALT 2021</span>) and    (<span class="conference-shortcut">ICML 2020 - RL Theory</span>) 
	  
    <a href="publications/kaufmann2020adaptive.bib">bibtex</a>    </li>	
	

    <li>Guillaume Gautier, Rémi Bardenet, <strong>Michal Valko</strong>:
      <aa href="https://rdcu.be/cdtIo.pdf"><em>
    Fast sampling from β-ensembles</em></aa>,
	 <a href="https://www.springer.com/journal/11222">Statistics and Computing</a>  
	 (<span class="conference-shortcut">Statistics and Computing 2021</span>) 
   <a href="https://arxiv.org/abs/2003.02344">arXiv preprint</a>,
   <a href="publications/gautier2021fast.bib">bibtex</a> </li>

<li>Mehdi Azabou, Mohammad Gheshlaghi Azar, Ran Liu, Chi-Heng Lin, Erik C. Johnson, Kiran Bhaskaran-Nair, Max Dabagia, Bernardo Ávila Pires, Lindsey Kitchell, Keith B. Hengen, William Gray-Roncal, <strong>Michal Valko</strong>, Eva L. Dyer:
  <aa href="publications/azabou2021mine.pdf"><em>
Mine Your Own vieW: Self-supervised learning through across-sample prediction,</em></aa>
in <a href="https://sslneurips21.github.io/">NeurIPS 2021 Workshop: Self-Supervised Learning - Theory and Practice</a>,
  <a href="https://arxiv.org/abs/2102.10106">arXiv preprint</a>
</li>	



   <li>Omar Darwiche Domingues, Corentin Tallec, Rémi Munos, <strong>Michal Valko</strong>:
     <a href="publications/domingues2021density-based.pdf"><em>Density-based bonuses on learned representations for reward-free exploration in deep reinforcement learning</em></a>,
   in <a href="https://urlworkshop.github.io/">ICML 2021 Workshop: Unsupervised Reinforcement Learning</a>,
     <a href="https://openreview.net/pdf?id=vRSY3L4Rlhp">openreview</a>

</li>	
	


</ul>
<h2>2020</h2>
<ul class="publications-list">

<!-- <h2>preprints</h2>
<ul class="publications-list"> -->


<li>Jean-Bastien Grill, Florian Strub, Florent Altché, Corentin Tallec, Pierre H. Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Ávila Pires, Zhaohan Daniel Guo, Mohammad Gheshlaghi Azar, Bilal Piot, Koray Kavukcuoglu, Rémi Munos, <strong>Michal Valko</strong>:
  <a href="publications/grill2020bootstrap.pdf"><em>
Bootstrap Your Own Latent: A new approach to self-supervised learning</em></a>,
in <a href="https://neurips.cc/Conferences/2020/">Neural Information Processing Systems</a> 
   (<span class="conference-shortcut">NeurIPS 2020</span>)  [<span style="color: #CC3333">oral - 1% acceptance rate</span>]
   
<ul>	   
<li> <a href="https://arxiv.org/abs/2006.07733">arXiv preprint</a> 
   <a href="publications/grill2020bootstrap.bib">bibtex</a> </li>
<li><a href="https://twitter.com/DeepMind/status/1272810643222126594">our twitter announcement</a>
and <a href="https://github.com/deepmind/deepmind-research/tree/master/byol">our code</a> </li>
<li> <a href="https://youtu.be/YPfUiOMYOEE">youtube video by Yannic</a>, <a href="https://medium.com/the-dl/easy-self-supervised-learning-with-byol-53b8ad8185d">unoffical blog 1</a> and <a href="https://medium.com/swlh/neural-networks-intuitions-10-byol-paper-explanation-f8b1d6e83b1c">unoffical blog 2</a> 

</li> 
</ul>

<li>Pierre H. Richemond, Jean-Bastien Grill, Florent Altché, Corentin Tallec, Florian Strub, Andrew Brock, Samuel Smith, Soham De, Razvan Pascanu, Bilal Piot, <strong>Michal Valko</strong>:
  <a href="publications/richemond2020byol.pdf"><em>
BYOL works even without batch statistics</em></a>,
in <a href="https://sslneuips20.github.io/">NeurIPS 2020 Workshop: Self-Supervised Learning - Theory and Practice</a> 
  <a href="https://arxiv.org/abs/2010.10241">arXiv preprint</a> 
  <a href="publications/richemond2020byol.bib">bibtex</a></li>	


<li>Jean Tarbouriech, Matteo Pirotta, <strong>Michal Valko</strong>, Alessandro Lazaric:
  <a href="publications/tarbouriech2020improved.pdf"><em>
Improved sample complexity for incremental autonomous exploration in MDPs</em></a>, 
in <a href="https://neurips.cc/Conferences/2020/">Neural Information Processing Systems</a> 
   (<span class="conference-shortcut">NeurIPS 2020</span>)   [<span style="color: #CC3333">oral - 1% acceptance rate</span>]
     <a href="https://arxiv.org/abs/2012.14755">arXiv preprint</a> 
	  <a href="publications/tarbouriech2020improved.poster.pdf">poster</a>
<a href="publications/tarbouriech2020improved.bib">bibtex</a></li>

<li>Daniele Calandriello*, Michał Dereziński*, <strong>Michal Valko</strong>:
  <a href="publications/calandriello2020sampling.pdf"><em>
Sampling from a k-DPP without looking at all items</em></a>,
in <a href="https://neurips.cc/Conferences/2020/">Neural Information Processing Systems</a>  
   (<span class="conference-shortcut">NeurIPS 2020</span>)  <span style="color: #CC3333">spotlight - 3% acceptance rate</span>] 
    <a href="https://arxiv.org/abs/2006.16947">arXiv preprint</a>
 <!--   <a href="publications/calandriello2020sampling.talk.pdf">talk</a> -->
 <!-- <a href="publications/derezinski2019exact.poster.pdf">poster</a> -->
     <a href="publications/calandriello2020sampling.bib">bibtex</a> 
</li>

<li>Pierre Perrault, Etienne Boursier, Vianney Perchet, <strong>Michal Valko</strong>:
  <a href="publications/perrault2020statistical.pdf"><em>
Statistical efficiency of Thompson sampling for combinatorial semi-bandits</em></a>, 
in <a href="https://neurips.cc/Conferences/2020/">Neural Information Processing Systems</a>  
   (<span class="conference-shortcut">NeurIPS 2020</span>)  
 <a href="https://arxiv.org/abs/2006.06613">arXiv preprint</a>
<a href="publications/perrault2020statistical.bib">bibtex</a></li>	



	
<li>Anders Jonsson, Emilie Kaufmann, Pierre Ménard, Omar Darwiche Domingues, Edouard Leurent, <strong>Michal Valko</strong>:
  <a href="publications/jonsson2020planning.pdf"><em>
Planning in Markov decision processes with gap-dependent sample complexity</em></a>,  
in <a href="https://neurips.cc/Conferences/2020/">Neural Information Processing Systems</a>  
   (<span class="conference-shortcut">NeurIPS 2020</span>) 
 <a href="https://arxiv.org/abs/2006.05879">arXiv preprint</a>
  <a href="publications/jonsson2020planning.poster.pdf">poster</a>
<a href="publications/jonsson2020planning.bib">bibtex</a></li>	
	


<li>
Jean-Bastien Grill, Florent Altché, Yunhao Tang, Thomas Hubert, <strong>Michal Valko</strong>, Ioannis Antonoglou, Rémi Munos:
  <a href="publications/grill2020monte-carlo.pdf"><em>
Monte-Carlo tree search as regularized policy optimization</em></a>,  
  in <a href="https://icml.cc/Conferences/2020">International Conference on Machine Learning</a> (<span class="conference-shortcut">ICML 2020</span>)
     <a href="publications/grill2020monte-carlo.talk.pdf">talk</a>
	 <a href="https://arxiv.org/abs/2007.12509">arXiv preprint</a> 
	  <a href="https://icml.cc/virtual/2020/poster/6380">video</a> 
	   <a href="publications/grill2020monte-carlo.bib">bibtex</a></li>

<li>Yunhao Tang, <strong>Michal Valko</strong>, Rémi Munos:
  <a href="publications/tang2020taylor.pdf"><em>
Taylor expansion policy optimization</em></a>,  
  in <a href="https://icml.cc/Conferences/2020">International Conference on Machine Learning</a> (<span class="conference-shortcut">ICML 2020</span>)
  and (<span class="conference-shortcut-more">MS RL Day 2021</span>)
  <a href="https://arxiv.org/abs/2003.06259">arXiv preprint</a>
      <a href="publications/tang2020taylor.talk.pdf">talk</a> 
	    <a href="publications/tang2020taylor.bib">bibtex</a></li>


<li>Rémy Degenne, Pierre Ménard, Xuedong Shang, <strong>Michal Valko</strong>:
  <a href="publications/degenne2020gamification.pdf"><em>
Gamification of pure exploration for linear bandits</em></a>,  
  in <a href="https://icml.cc/Conferences/2020">International Conference on Machine Learning</a> (<span class="conference-shortcut">ICML 2020</span>)
    <a href="https://arxiv.org/abs/2007.00953">arXiv preprint</a>
       <a href="publications/degenne2020gamification.talk.pdf">talk</a> 
	     <a href="publications/degenne2020gamification.bib">bibtex</a> 
</li>
 

<li>Pierre Perrault, Zheng Wen, Jennifer Healey, <strong>Michal Valko</strong>:
  <a href="publications/perrault2020budgeted.pdf"><em>
Budgeted online influence maximization</em></a>,  
  in <a href="https://icml.cc/Conferences/2020">International Conference on Machine Learning</a> (<span class="conference-shortcut">ICML 2020</span>)
    <a href="https://icml.cc/virtual/2020/poster/6378">video</a> 
  <a href="publications/perrault2020budgeted.bib">bibtex</a></li>

<li>Jean Tarbouriech, Evrard Garcelon, <strong>Michal Valko</strong>, Matteo Pirotta, Alessandro Lazaric:
  <a href="publications/tarbouriech2020no-regret.pdf"><em>
No-regret exploration in goal-oriented reinforcement learning</em></a>, 
  in <a href="https://icml.cc/Conferences/2020">International Conference on Machine Learning</a> (<span class="conference-shortcut">ICML 2020</span>) 
  <a href="https://arxiv.org/abs/1912.03517">arXiv preprint</a>
    <a href="publications/tarbouriech2020no-regret.talk.pdf">talk</a> 
  <a href="publications/tarbouriech2020no-regret.bib">bibtex</a></li>

   <li>Aadirupa Saha, Pierre Gaillard, <strong>Michal Valko</strong>:
     <a href="publications/saha2020improved.pdf"><em>
   Improved sleeping bandits with stochastic action sets and adversarial rewards</em></a>,
     in <a href="https://icml.cc/Conferences/2020">International Conference on Machine Learning</a> (<span class="conference-shortcut">ICML 2020</span>)
  <a href="https://arxiv.org/abs/2004.06248">arXiv preprint</a>
      <a href="publications/saha2020improved.talk.pdf">talk</a> 
  <a href="publications/saha2020improved.bib">bibtex</a></li>


<li>Anne Manegueu, Claire Vernade, Alexandra Carpentier, <strong>Michal Valko</strong>:
  <a href="publications/manegueu2020stochastic.pdf"><em>
Stochastic bandits with arm-dependent delays</em></a>,  
  in <a href="https://icml.cc/Conferences/2020">International Conference on Machine Learning</a> (<span class="conference-shortcut">ICML 2020</span>) and
  (<span class="conference-shortcut-more">GPSD 2020</span>) and 
   (<span class="conference-shortcut-more">WiML 2019</span>)
     <a href="https://arxiv.org/abs/2006.10459">arXiv preprint</a>
  	<a href="https://icml.cc/virtual/2020/poster/6140">video</a>	 	 
   <a href="publications/manegueu2020stochastic.bib">bibtex</a>

 <li>Daniele Calandriello, Luigi Carratino, Alessandro Lazaric, <strong>Michal Valko</strong>, Lorenzo Rosasco:
  <a href="publications/calandriello2020near-linear.pdf"><em>
Near-linear time Gaussian process optimization with adaptive batching and resparsification</em></a>, 
   in <a href="https://icml.cc/Conferences/2020">International Conference on Machine Learning</a> (<span class="conference-shortcut">ICML 2020</span>) and
   (<span class="conference-shortcut-more">OPT 2019</span>)
    <a href="https://arxiv.org/abs/2002.09954">arXiv preprint</a>
  <a href="publications/calandriello2020near-linear.talk.pdf">talk</a>
 <!--  <a href="publications/calandriello2020near-linear.poster.pdf">poster</a> -->
    <a href="publications/calandriello2020near-linear.bib">bibtex</a></li>



<li>Pierre Perrault, Vianney Perchet, <strong>Michal Valko</strong>:
 <a href="publications/perrault2020covariance-adapting.pdf">
<em>
Covariance-adapting algorithm for semi-bandits with application to sparse rewards</em></a>,
  in <a href="http://www.learningtheory.org/colt2020/"> Conference on Learning Theory</a>
   (<span class="conference-shortcut">COLT 2020</span>),
   	<a href="https://www.colt2020.org/virtual/papers/paper_251.html">video</a>
<!--
  <a href="publications/perrault2020covariance-adapting.talk.pdf">talk</a>
	
  <a href="publications/perrault2020covariance-adapting.poster.pdf">poster</a>
 -->
	 <a href="publications/perrault2020covariance-adapting.bib">bibtex</a></li>






<li>Xuedong Shang, Rianne de Heide,  Emilie Kaufmann, Pierre Ménard, <strong>Michal Valko</strong>:
  <a href="publications/shang2020fixed-confidence.pdf"><em>
Fixed-confidence guarantees for Bayesian best-arm identification</em></a>,  
in <a href="https://aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2020</span>)
  <a href="publications/shang2020fixed-confidence.talk.pdf">talk</a>

 <a href="publications/shang2020fixed-confidence.bib">bibtex</a> 
 <!--
   <a href="publications/shang2019simple.talk.pdf">talk</a> 
   <a href="publications/shang2020fixed-confidence.poster.pdf">poster</a>  
     <a href="publications/shang2020fixed-confidence.code.zip">code</a>
   --> 
   <a href="https://arxiv.org/abs/1910.10945">arXiv preprint</a>
</li>

<li>Côme Fiegel, Victor Gabillon, <strong>Michal Valko</strong>:
 <a href="publications/fiegel2020adaptive.pdf">
<em>
Adaptive multi-fidelity optimization with fast learning rates</em></a>
in <a href="https://aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2020</span>)
     <a href="publications/fiegel2020adaptive.bib">bibtex</a>     <!--
 <a href="https://slideslive.com/38917632/online-learning-2">video</a>
  <a href="publications/bartlett2019scale-free.talk.pdf">talk</a>
  <a href="publications/bartlett2019scale-free.poster.pdf">poster</a> 
</li>
 --> 

 <li>Victor Gabillon, Rasul Tutunov, <strong>Michal Valko</strong>, Haitham Bou Ammar:
 <a href="publications/gabillon2020derivative-free.pdf">
<em>
Derivative-free & order-robust optimisation</em></a>
in <a href="https://aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2020</span>)
     <a href="publications/gabillon2020derivative-free.bib">bibtex</a>     <!--
 <a href="https://slideslive.com/38917632/online-learning-2">video</a>  --> 
 <a href="publications/gabillon2020derivative-free.talk.pdf">talk</a> 
    <!-- <a href="publications/gabillon2020derivative-free".poster.pdf">poster</a> 
</li>
 --> 

<li> Julien Seznec, Pierre Ménard, Alessandro Lazaric, <strong>Michal Valko</strong>:
 <a href="publications/seznec2020single.pdf"><em>A single algorithm for both restless and rested rotting bandits</em></a>, 
 in <a href="https://aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2020</span>)
  <a href="publications/seznec2020single.bib">bibtex</a>  
  <a href="publications/seznec2020single.talk.pdf">talk</a> 
   <!--   <a href="publications/seznec2020single.poster.pdf">poster</a>
   [<span style="color: #CC3333">full oral presentation</span> - 2.5% acceptance rate]
 -->
</li>


<li>Jean Tarbouriech, Matteo Pirotta, <strong>Michal Valko</strong>, Alessandro Lazaric:
  <a href="publications/tarbouriech2020reward-free.pdf"><em>
Reward-free exploration beyond finite-horizon</em></a>, in 
<a href="https://wensun.github.io/rl_theory_workshop_2020_ICML.github.io/">Theoretical Foundations of RL Workshop @ ICML 2020</a>
 (<span class="conference-shortcut">ICML 2020 - RL Theory</span>)  
 	<a href="https://youtu.be/rDLaWSNAnqs">video</a> 
</li>



<li>Tomáš Kocák, Rémi Munos, Branislav Kveton, Shipra Agrawal, <strong>Michal Valko</strong>:
 <a href="publications/kocak2020spectral.pdf">
<em>Spectral Bandits</em></a>, 
<a href="http://www.jmlr.org/"> Journal of Machine Learning Research</a>
 (<span class="conference-shortcut">JMLR 2020</span>) 
  <a href="publications/kocak2020spectral.bib">bibtex</a> 
</li>

</ul>

<h2>2019</h2>
<ul class="publications-list">

 

<li>Jean-Bastien Grill*, Omar Darwiche Domingues*, Pierre Ménard,  Rémi Munos, <strong>Michal Valko</strong>:
 <a href="publications/grill2019planning.pdf"><em>Planning in entropy-regularized Markov decision processes and games</em></a>, 
in <a href="https://neurips.cc/Conferences/2019/">Neural Information Processing Systems</a> 
   (<span class="conference-shortcut">NeurIPS 2019</span>)
 <a href="publications/grill2019planning.bib">bibtex</a> 
  <!--
   <a href="publications/grill2016blazing.talk.pdf">talk</a> -->
       
  <a href="publications/grill2019planning.poster.pdf">poster</a> 
</li>

<li>Mark Rowland, Shayegan Omidshafiei, Karl Tuyls, Julien Pérolat,  <strong>Michal Valko</strong>, Georgios Piliouras, Rémi Munos:
 <aa href="publications/grill2019planning.pdf"><em>Multiagent evaluation under incomplete information</em></a>, 
in <a href="https://neurips.cc/Conferences/2019/">Neural Information Processing Systems</a> 
   (<span class="conference-shortcut">NeurIPS 2019</span>)
 <a href="publications/rowland2019multiagent.bib">bibtex</a> 
  <!--
   <a href="publications/grill2016blazing.talk.pdf">talk</a> 
       
  <a href="publications/grill2018optimistic.poster.pdf">poster</a> -->
</li>



<li>Michał Dereziński*, Daniele Calandriello*, <strong>Michal Valko</strong>:
  <a href="publications/derezinski2019exact.pdf"><em>
Exact sampling of determinantal point processes with sublinear time preprocessing</em></a>,
     in <a href="https://neurips.cc/Conferences/2019/">Neural Information Processing Systems</a> 
   (<span class="conference-shortcut">NeurIPS 2019</span>)   and
   (<span class="conference-shortcut-more">ICML 2019 - NEGDEP</span>)
   <a href="publications/derezinski2019exact.bib">bibtex</a> 
 <!-- <a href="publications/derezinski2019exact.talk.pdf">talk</a> -->
 <!-- <a href="publications/derezinski2019exact.poster.pdf">poster</a> -->
<a href="https://slideslive.com/38917381/exact-sampling-of-determinantal-point-processes-with-sublinear-time-preprocessing">video</a>
</li>

   <li>Guillaume Gautier, Rémi Bardenet, <strong>Michal Valko</strong>:
     <aa href="publications/gautier2019two.pdf"><em>
   On two ways to use determinantal point processes for Monte Carlo integration</em></aa>,
   in <a href="https://neurips.cc/Conferences/2019/">Neural Information Processing Systems</a> 
   (<span class="conference-shortcut">NeurIPS 2019</span>)   and
   (<span class="conference-shortcut-more">ICML 2019 - NEGDEP</span>)  
    <a href="publications/gautier2019two.bib">bibtex</a>  
 <a href="https://slideslive.com/38917386/on-two-ways-to-use-determinantal-point-processes-for-monte-carlo-integration">video</a>
</li>






<li>Daniele Calandriello, Luigi Carratino, Alessandro Lazaric, <strong>Michal Valko</strong>, Lorenzo Rosasco:
  <a href="publications/calandriello2019gaussian.pdf"><em>
Gaussian process optimization with adaptive sketching: Scalable and no regret</em></a>, in
  <a href="http://www.learningtheory.org/colt2019/"> Conference on Learning Theory</a>
   (<span class="conference-shortcut">COLT 2019</span>) and (<span class="conference-shortcut-more">ICML 2019 - NEGDEP</span>)
   and (<span class="conference-shortcut-more">SWSL 2019</span>)
   <a href="publications/calandriello2019gaussian.bib">bibtex</a> <a href="https://slideslive.com/38917391/gaussian-process-optimization-with-adaptive-sketching-scalable-and-no-regret">video</a>
  <a href="publications/calandriello2019gaussian.talk.pdf">talk</a>
  <a href="publications/calandriello2019gaussian.poster.pdf">poster</a> 
</li>



<li>Peter Bartlett, Victor Gabillon, Jennifer Healey, <strong>Michal Valko</strong>:
 <a href="publications/bartlett2019scale-free.pdf">
<em>
Scale-free adaptive planning for deterministic dynamics & discounted rewards</em></a>
  in <a href="https://icml.cc/Conferences/2019">International Conference on Machine Learning</a> 
   (<span class="conference-shortcut">ICML 2019</span>)
     <a href="publications/bartlett2019scale-free.bib">bibtex</a> <a href="https://slideslive.com/38917632/online-learning-2">video</a>
  <a href="publications/bartlett2019scale-free.talk.pdf">talk</a>
  <a href="publications/bartlett2019scale-free.poster.pdf">poster</a> 
</li>

<li>Pierre Perrault, Vianney Perchet, <strong>Michal Valko</strong>:
 <a href="publications/perrault2019exploiting.pdf">
<em>
Exploiting structure of uncertainty for efficient matroid semi-bandits</em></a>,
  in <a href="https://icml.cc/Conferences/2019">International Conference on Machine Learning</a> 
   (<span class="conference-shortcut">ICML 2019</span>)
    <a href="publications/perrault2019exploiting.bib">bibtex</a> <a href="https://www.facebook.com/icml.imls/videos/444326646299556/">video</a>
  <a href="publications/perrault2019exploiting.talk.pdf">talk</a>
  <a href="publications/perrault2019exploiting.poster.pdf">poster</a>
 
</li>



<li>Xuedong Shang, Emilie Kaufmann, <strong>Michal Valko</strong>:
  <a href="publications/shang2019simple.pdf"><em>
A simple dynamic bandit-based algorithm for hyper-parameter tuning</em></a>,  
in  <a href="https://sites.google.com/corp/view/automl2019icml/">  shop on Automated Machine Learning at International Conference on Machine Learning</a>  
 (<span class="conference-shortcut">ICML 2019 - AutoML</span>)

 <a href="publications/shang2019simple.bib">bibtex</a> 
 <!--
   <a href="publications/shang2019simple.talk.pdf">talk</a> --> 
   <a href="publications/shang2019simple.poster.pdf">poster</a>  
	   <a href="publications/shang2019simple.code.zip">code</a>
	 
</li>

  <li>Guillaume Gautier, Rémi Bardenet, <strong>Michal Valko</strong>:
     <a href="publications/gautier2019dppy.pdf"><em>
   DPPy: Sampling determinantal point processes with Python</em></a>,
   <a href="http://www.jmlr.org/">Journal of Machine Learning Research</a>
 (<span class="conference-shortcut">JMLR 2019</span>)      
    <a href="https://arxiv.org/abs/1809.07258">arXiv preprint</a>
	   <a href="publications/gautier2019dppy.bib">bibtex</a> 
   </li>
</li>


<li> Julien Seznec, Andrea Locatelli, Alexandra Carpentier, Alessandro Lazaric, <strong>Michal Valko</strong>:
 <a href="publications/seznec2019rotting.pdf"><em>Rotting bandits are not harder than stochastic ones</em></a>, 
 in <a href="https://aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2019</span>)
  <a href="publications/seznec2019rotting.bib">bibtex</a> 
  <a href="publications/seznec2019rotting.talk.pdf">talk</a> 
   <a href="publications/seznec2019rotting.poster.pdf">poster</a>
   [<span style="color: #CC3333">full oral presentation</span> - 2.5% acceptance rate]
</li>



<li>Andrea Locatelli, Alexandra Carpentier, <strong>Michal Valko</strong>:
 <aa href="publications/locatelli2019active.pdf"><em>Active multiple matrix completion with adaptive confidence sets</em></aa>, 
 in <a href="https://aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
  (<span class="conference-shortcut">AISTATS 2019</span>)
  <a href="publications/locatelli2019active.bib">bibtex</a> 
 <a href="publications/locatelli2018active.talk.pdf">talk</a> 
 <a href="publications/locatelli2019active.poster.pdf">poster</a>
</li>

<li>Pierre Perrault, Vianney Perchet, <strong>Michal Valko</strong>:
 <a href="publications/perrault2019finding.pdf">
<em>
Finding the bandit in a graph: Sequential search-and-stop</em></a>, 
in <a href="https://aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2019</span>)
  <a href="publications/perrault2019finding.bib">bibtex</a>  
 <!-- <a href="publications/perrault2019finding.talk.pdf">talk</a> -->
  <a href="publications/perrault2019finding.poster.pdf">poster</a> 
</li>

<li>Peter L. Bartlett, Victor Gabillon, <strong>Michal Valko</strong>:
 <a href="publications/bartlett2019simple.pdf">
<em>
A simple parameter-free and adaptive approach to optimization under a minimal local smoothness assumption</em></a>,
in  <a href="http://alt2019.algorithmiclearningtheory.org">Algorithmic Learning Theory</a>  
 (<span class="conference-shortcut">ALT 2019</span>)
  <a href="publications/bartlett2019simple.bib">bibtex</a>  
  <a href="publications/bartlett2019simple.talk.pdf">talk 1</a>
  <a href="publications/bartlett2019simple.talk.alt.pdf">talk 2</a>
 <!-- <a href="publications/bartlett2019simple.poster.pdf">poster</a> -->
</li>


<li>Xuedong Shang, Emilie Kaufmann, <strong>Michal Valko</strong>:
  <a href="publications/shang2019general.pdf"><em>
General parallel optimization without metric</em></a>,  
in  <a href="http://alt2019.algorithmiclearningtheory.org">Algorithmic Learning Theory</a>  
 (<span class="conference-shortcut">ALT 2019</span>)
 <a href="publications/shang2019general.bib">bibtex</a> 

   <a href="publications/shang2019general.talk.pdf">talk</a>
  <!--  <a href="publications/shang2019general.poster.pdf">poster</a>  --> 
	 






 <li>Guillaume Gautier, Rémi Bardenet, <strong>Michal Valko</strong>:
     <a href="publications/gautier2019processus.pdf"><em>
    Les processus ponctuels déterminantaux en apprentissage automatique</em></a>  
   <a href="publications/gautier2019processus.bib">bibtex</a>  
     (<span class="conference-shortcut">Gretsi 2019</span>)
</li>

 
</ul>


<h2>2018</h2>
<ul class="publications-list">


<li>Jean-Bastien Grill, <strong>Michal Valko</strong>, Rémi Munos:
 <a href="publications/grill2018optimistic.pdf"><em>Optimistic optimization of a Brownian</em></a>, 
in  <a href="https://neurips.cc/Conferences/2018/">Neural Information Processing Systems</a> 
 (<span class="conference-shortcut">NeurIPS 2018</span>)    
 <a href="publications/grill2018optimistic.bib">bibtex</a> 
  <!--
   <a href="publications/grill2016blazing.talk.pdf">talk</a> 
	   	 -->
  <a href="publications/grill2018optimistic.poster.pdf">poster</a> 
</li>


<li>Xuedong Shang, Emilie Kaufmann, <strong>Michal Valko</strong>:
  <a href="publications/shang2018adaptive.pdf"><em>
Adaptive black-box optimization got easier: HCT needs only local smoothness</em></a>,  
in <a href="https://ewrl.wordpress.com/ewrl14-2018/">European Workshop on Reinforcement Learning</a> 
 (<span class="conference-shortcut">EWRL 2018</span>) 
 <a href="publications/shang2018adaptive.bib">bibtex</a> 
 <!--
   <a href="publications/shang2018adaptive.talk.pdf">talk</a> -->
   <a href="publications/shang2018adaptive.poster.pdf">poster</a> 
	 
</li>
	
	
<li>Edouard Oyallon, Eugene Belilovsky, Sergey Zagoruyko, <strong>Michal Valko</strong>:
  <a href="publications/oyallon2018compressing.pdf"><em>
Compressing the input for CNNs with the first-order scattering transform</em></a>,  
in <a href="https://eccv2018.org/">European Conference on Computer Vision</a> 
 (<span class="conference-shortcut">ECCV 2018</span>) 
 <a href="publications/oyallon2018compressing.bib">bibtex</a> 
 <!--
   <a href="publications/oyallon2018compressing.talk.pdf">talk</a>  -->
   <a href="publications/oyallon2018compressing.poster.pdf">poster</a> 
	
</li>

<li>Daniele Calandriello, Ioannis Koutis, Alessandro Lazaric, <strong>Michal Valko</strong>:
  <a href="publications/calandriello2018improved.pdf"><em>
Improved large-scale graph learning through ridge spectral sparsification</em></a>,  
in <a href="https://icml.cc/Conferences/2018">International Conference on Machine Learning</a> 
 (<span class="conference-shortcut">ICML 2018</span>) 
 <a href="publications/calandriello2018improved.bib">bibtex</a> 
   <a href="publications/calandriello2018improved.talk.pdf">talk</a>
   <a href="publications/calandriello2018improved.poster.pdf">poster</a> 
</li>


<li>Yasin Abbasi-Yadkori, Peter L. Bartlett, Victor Gabillon, Alan Malek, <strong>Michal Valko</strong>:
 <a href="publications/abbasi-yadkori2018best.pdf">
<em>Best of both worlds: Stochastic &
adversarial best-arm identification</em></a>, 
<a href="http://www.learningtheory.org/colt2018/"> Conference on Learning Theory</a>
 (<span class="conference-shortcut">COLT 2018</span>)
  <a href="publications/abbasi-yadkori2018best.bib">bibtex</a>  
    <a href="https://www.youtube.com/watch?v=oIOK4AyB05I">video</a>
  <a href="publications/abbasi-yadkori2018best.talk.pdf">talk</a>
  <a href="publications/abbasi-yadkori2018best.poster.pdf">poster</a>
</li>

</ul>

<h2>2017</h2>
<ul class="publications-list">


<li>Daniele Calandriello, Alessandro Lazaric, <strong>Michal Valko</strong>:
  <a href="publications/calandriello2017efficient.pdf"><em>
Efficient second-order online kernel learning with adaptive embedding</em></a>,  
in <a href="https://nips.cc/Conferences/2017">Neural Information Processing Systems</a> 
 (<span class="conference-shortcut">NeurIPS 2017</span>) 
 <a href="publications/calandriello2017efficient.bib">bibtex</a> 
   <a href="publications/calandriello2017efficient.talk.pdf">talk</a>
   <a href="publications/calandriello2017efficient.poster.pdf">poster</a> 
</li>

<li>Zheng Wen, Branislav Kveton , <strong>Michal Valko</strong>, Sharan Vaswani:
  <a href="publications/wen2017online.pdf"><em>
Online influence maximization under independent cascade model with semi-bandit feedback</em></a>,  in <a href="https://nips.cc/Conferences/2017">Neural Information Processing Systems</a> 
 (<span class="conference-shortcut">NeurIPS 2017</span>) 
 <a href="publications/wen2017online.bib">bibtex</a> 
<!--   <aa href="publications/wen2017online.talk.pdf">talk</aa>
   <aa href="publications/wen2017online.poster.pdf">poster</aa> -->
</li>


<li>Daniele Calandriello, Alessandro Lazaric, <strong>Michal Valko</strong>:
  <a href="publications/calandriello2017second.pdf"><em>
Second-order kernel online convex optimization with adaptive sketching</em></aa>,  in <a href="http://icml.cc/2017/">International Conference on Machine Learning</a> 
 (<span class="conference-shortcut">ICML 2017</span>) 
 <a href="publications/calandriello2017second.bib">bibtex</a> 
  <a href="publications/calandriello2017second.talk.pdf">talk</a>
   <a href="publications/calandriello2017second.poster.pdf">poster</a> 
</li>


<li>Guillaume Gautier, Rémi Bardenet, <strong>Michal Valko</strong>:
  <a href="publications/gautier2017zonotope.pdf"><em>
Zonotope hit-and-run for efficient sampling from projection DPPs</em></a>,  in <a href="http://icml.cc/2017/">International Conference on Machine Learning</a> 
 (<span class="conference-shortcut">ICML 2017</span>) 
 <a href="publications/gautier2017zonotope.bib">bibtex</a> 
 <a href="publications/gautier2017zonotope.talk.pdf">talk</a> 
 <a href="publications/gautier2017zonotope.poster.pdf">poster</a>
</li>


<li>Daniele Calandriello, Alessandro Lazaric, <strong>Michal Valko</strong>:
  <a href="publications/calandriello2017distributed.pdf"><em>
Distributed adaptive sampling for kernel matrix approximation</em></a>,  in <a href="https://aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2017</span>) and (<span class="conference-shortcut-more">ICML 2017 - <a href="http://rlabstraction2016.wixsite.com/icml-2017"> LL</a></span>)   
 <a href="publications/calandriello2017distributed.bib">bibtex</a> 
  <a href="publications/calandriello2017distributed.talk.pdf">talk</a> 
     <a href="publications/squeak.py">code</a> 
  <a href="publications/calandriello2017distributed.poster.pdf">poster</a> 
</li>


<li>Akram Erraqabi, Alessandro Lazaric, <strong>Michal Valko</strong>, Emma Brunskill, Yu-En Liu:
 <a href="publications/erraqabi2017trading.pdf"><em>Trading off rewards and errors in multi-armed bandits</em></a>,  in <a href="https://aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2017</span>)    
 <a href="publications/erraqabi2017trading.bib">bibtex</a> 
 <!-- <a href="publications/erraqabi2016pliable.talk.pdf">talk</a> -->
  <a href="publications/erraqabi2017trading.poster.pdf">poster</a>
</li>





</ul>
<h2>2016</h2>
<ul class="publications-list">

<li><strong>Michal Valko</strong>:
 <a href="publications/valko2016bandits.pdf"><em>Bandits on graphs and structures</em></a>, 
 habilitation thesis, École normale supérieure de Cachan
 (<span class="conference-shortcut">ENS Cachan 2016</span>)    
 <a href="publications/valko2016bandits.bib">bibtex</a> 
  <!-- <a href="publications/grill2016blazing.poster.pdf">poster</a> -->
</li>



<li>Jean-Bastien Grill, <strong>Michal Valko</strong>, Rémi Munos:
 <a href="publications/grill2016blazing.pdf"><em>Blazing the trails before beating the path: Sample-efficient Monte-Carlo planning</em></a>, 
in  <a href="https://neurips.cc/Conferences/2016/">Neural Information Processing Systems</a> 
 (<span class="conference-shortcut">NeurIPS 2016</span>)    
 <a href="publications/grill2016blazing.bib">bibtex</a> 
   <a href="publications/grill2016blazing.talk.pdf">talk</a> 
  <a href="publications/grill2016blazing.poster.pdf">poster</a> 
  [<span style="color: #CC3333">full oral presentation</span> - 1.8% acceptance rate]  
</li>

<li>Daniele Calandriello, Alessandro Lazaric, <strong>Michal Valko</strong>:
  <a href="publications/calandriello2016pack.pdf"><em>Pack only the essentials: Adaptive dictionary learning for kernel ridge regression</em></a>, in <a href="https://sites.google.com/site/nips2016adaptive/">Adaptive and Scalable Nonparametric Methods in Machine Learning at Neural Information Processing Systems</a> 
  (<span class="conference-shortcut">NeurIPS 2016 - ASNMML</span>)
  <a href="publications/calandriello2016pack.bib">bibtex</a> 
 <!-- <a href="publications/calandriello2016analysis.talk.pdf">talk</a> -->
  <a href="publications/calandriello2016pack.poster.pdf">poster</a> 
</li>



<li>Akram Erraqabi, Alessandro Lazaric, <strong>Michal Valko</strong>, Emma Brunskill, Yu-En L@iu:
 <a href="publications/erraqabi2016rewards.pdf"><em>Rewards and Errors in Multi-armed Bandit for Interactive Education</em></a>, in <a href="http://ciml.chalearn.org/ciml2016">Challenges in Machine Learning: 
Learning and Education workshop at Neural Information Processing Systems</a> 
 (<span class="conference-shortcut">NeurIPS 2016 - CIML</span>)    
  <a href="publications/erraqabi2016rewards.bib">bibtex</a> 
 <a href="publications/erraqabi2016rewards.poster.pdf">poster</a> 

</li>


<li>Akram Erraqabi, <strong>Michal Valko</strong>, Alexandra Carpentier, Odalric-Ambrym Maillard:
 <a href="publications/erraqabi2016pliable.pdf"><em>Pliable rejection sampling</em></a>, in <a href="http://icml.cc/2016/">International Conference on Machine Learning</a> 
 (<span class="conference-shortcut">ICML 2016</span>)    
 <a href="publications/erraqabi2016pliable.bib">bibtex</a> 
 <a href="publications/erraqabi2016pliable.talk.pdf">talk</a>
  <a href="publications/erraqabi2016pliable.talk.long.pdf">long talk</a>
  <a href="publications/erraqabi2016pliable.poster.pdf">poster</a>
</li>


<li>Daniele Calandriello, Alessandro Lazaric, <strong>Michal Valko</strong>:
 <a href="publications/calandriello2016analysis.pdf"><em>Analysis of Nyström method with sequential ridge leverage scores</em></a>, in <a href="http://auai.org/uai2016/">Uncertainty in Artificial Intelligence</a> 
 (<span class="conference-shortcut">UAI 2016</span>)    
 <a href="publications/calandriello2016analysis.bib">bibtex</a> 
 <!-- <a href="publications/calandriello2016analysis.talk.pdf">talk</a> -->
  <a href="publications/calandriello2016analysis.poster.pdf">poster</a> 
  <a href="publications/calandriello2016analysis.spotlight.pdf">spotlight</a> 
</li>


<li>Tomáš Kocák, Gergely Neu, <strong>Michal Valko</strong>:
 <a href="publications/kocak2016onlinea.pdf"><em>Online learning with Erdős-Rényi side-observation graphs</em></a>, in <a href="http://auai.org/uai2016/">Uncertainty in Artificial Intelligence</a> 
 (<span class="conference-shortcut">UAI 2016</span>)    
 <a href="publications/kocak2016onlinea.bib">bibtex</a> 
 <!-- <a href="publications/kocak2016onlinea.talk.pdf">talk</a> -->
 <a href="publications/kocak2016onlinea.poster.pdf">poster</a>
  <a href="publications/kocak2016onlinea.spotlight.pdf">spotlight</a>
  <!-- [<span style="color: #CC3333">full oral presentation</span> - 6% acceptance rate] -->  
</li>

<li>Mohammad Ghavamzadeh, Yaakov Engel, <strong>Michal Valko</strong>:
 <a href="publications/ghavamzadeh2016bayesian.pdf"><em>Bayesian policy gradient and actor-critic algorithms</em></a>, 
<a href="http://www.jmlr.org/"> Journal of Machine Learning Research</a>
 (<span class="conference-shortcut">JMLR 2016</span>)    
 <a href="publications/ghavamzadeh2016bayesian.bib">bibtex</a> 
  <a href="https://fr.mathworks.com/matlabcentral/fileexchange/60839-bayesian-policy-gradient-and-actor-critic-algorithms">code</a>
  <!-- <a href="publications/kveton2016learning.talk.pdf">talk</a> -->
  <!-- <a href="publications/kveton2016learning.poster.pdf">poster</a> -->
</li>


<li>Tomáš Kocák, Gergely Neu, <strong>Michal Valko</strong>:
 <a href="publications/kocak2016online.pdf"><em>Online learning with noisy side observations</em></a>, in <a href="https://aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2016</span>)    
 <a href="publications/kocak2016online.bib">bibtex</a> 
 <a href="publications/kocak2016online.talk.pdf">talk</a> 
 <a href="publications/kocak2016online.poster.pdf">poster</a>
 [<span style="color: #CC3333">full oral presentation</span> - 6% acceptance rate]  
</li>

<li>Alexandra Carpentier, <strong>Michal Valko</strong>:
 <a href="publications/carpentier2016revealing.pdf"><em>Revealing graph bandits for maximizing local influence</em></a>, in <a href="https://aistats.org/">International Conference on Artificial Intelligence and Statistics</a> 
 (<span class="conference-shortcut">AISTATS 2016</span>)    
 <a href="publications/carpentier2016revealing.bib">bibtex</a> 
  <!--  <a href="publications/carpentier2016revealing.talk.pdf">talk</a>  --> 
 <a href="publications/carpentier2016revealing.poster.pdf">poster</a>
</li>


</ul>

<h2>2015</h2>
<ul class="publications-list">


<li>Jean-Bastien Grill, <strong>Michal Valko</strong>, Rémi Munos:
 <a href="publications/grill2015black-box.pdf"><em>Black-box optimization of noisy functions with unknown smoothness</em></a>, 
in  <a href="https://neurips.cc/Conferences/2015/">Neural Information Processing Systems</a> 
 (<span class="conference-shortcut">NeurIPS 2015</span>)    
 <a href="publications/grill2015black-box.bib">bibtex</a> 
  <a href="projects/stosoo/poo_v1.zip">code</a>, 
  <a href="https://cran.r-project.org/web/packages/OOR/index.html">code in R</a> 
  <a href="publications/grill2015black-box.poster.pdf">poster</a>
</li>



<li>Alexandra Carpentier, <strong>Michal Valko</strong>:
 <a href="publications/carpentier2015simple.pdf"><em>Simple regret for infinitely many armed bandits</em></a>, in <a href="http://icml.cc/2015/">International Conference on Machine Learning</a> 
 (<span class="conference-shortcut">ICML 2015</span>)    
 <a href="publications/carpentier2015simple.bib">bibtex</a> 
  <a href="publications/carpentier2015simple.talk.pdf">talk</a> 
 <a href="publications/carpentier2015simple.poster.pdf">poster</a> 
 <a href="https://arxiv.org/abs/1505.04627">arXiv</a>
</li>


<li>Manjesh Hanawal, Venkatesh Saligrama, <strong>Michal Valko</strong>, Rémi Munos:
 <a href="publications/hanawal2015cheap.pdf"><em>Cheap Bandits</em></a>, in <a href="http://icml.cc/2015/">International Conference on Machine Learning</a> 
 (<span class="conference-shortcut">ICML 2015</span>)    
 <a href="publications/hanawal2015cheap.bib">bibtex</a> 
  <a href="publications/hanawal2015cheap.talk.pdf">talk</a> 
 <a href="publications/hanawal2015cheap.poster.pdf">poster</a>
</li>


<li>Daniele Calandriello, Alessandro Lazaric, <strong>Michal Valko</strong>:
 <a href="publications/calandriello2015large-scale.pdf"><em>Large-scale semi-supervised learning with online spectral graph sparsification</em></a>, in <a href="https://sites.google.com/site/icml2015budgetedml/">Resource-Efficient Machine Learning workshop at International Conference on Machine Learning</a> 
 (<span class="conference-shortcut">ICML 2015 - REML</span>)    
 <a href="publications/calandriello2015large-scale.bib">bibtex</a> 
 <!-- <a href="publications/calandriello2016analysis.talk.pdf">talk</a> -->
  <a href="publications/calandriello2015large-scale.poster.pdf">poster</a> 
 <!-- <a href="publications/calandriello2015large-scale.spotlight.pdf">spotlight</a>  -->
</li>

<li>Julien Audiffren, <strong>Michal Valko</strong>, Alessandro Lazaric, Mohammad Ghavamzadeh:
 <a href="publications/audiffren2015maximum.pdf">
<em> Maximum Entropy Semi-Supervised Inverse Reinforcement Learning</em></a>, 
in  <a href="http://ijcai-15.org/">International Joint Conferences on Artificial Intelligence</a> 
(<span class="conference-shortcut">IJCAI 2015</span>)  <a href="publications/audiffren2015maximum.bib">bibtex</a> <a href="publications/audiffren2015maximum.talk.pdf">talk</a> 
 <a href="publications/audiffren2015maximum.poster.pdf">poster</a> 
</li>

</ul>


<h2>2014</h2>
<ul class="publications-list">

<li>Tomáš Kocák, Gergely Neu, <strong>Michal Valko</strong>, Rémi Munos:
 <a href="publications/kocak2014efficient.pdf">
<em>Efficient Learning by Implicit Exploration in Bandit Problems with Side Observations</em></a>, 
in <a href="https://neurips.cc/Conferences/2014/">Neural Information Processing Systems</a> 
(<span class="conference-shortcut">NeurIPS 2014</span>)  <a href="publications/kocak2014efficient.bib">bibtex</a><a href="publications/kocak2014efficient.talk.pdf">talk</a> 
<a href="publications/kocak2014efficient.poster.pdf">poster</a> 
</li>


<li>Alexandra Carpentier, <strong>Michal Valko</strong>:
 <a href="publications/carpentier2014extreme.pdf">
<em>Extreme Bandits</em></a>, 
in <a href="https://neurips.cc/Conferences/2014/">Neural Information Processing Systems</a>
(<span class="conference-shortcut">NeurIPS 2014</span>)  <a href="publications/carpentier2014extreme.bib">bibtex</a><a href="publications/carpentier2014extreme.poster.pdf">poster</a> 
</li>

<li>Gergely Neu, <strong>Michal Valko</strong>:
 <a href="publications/neu2014online.pdf">
<em>Online Combinatorial Optimization with Stochastic Decision Sets and Adversarial Losses</em></a>, 
in <a href="https://neurips.cc/Conferences/2014/">Neural Information Processing Systems</a> 
(<span class="conference-shortcut">NeurIPS 2014</span>)  <a href="publications/neu2014online.bib">bibtex</a><a href="publications/neu2014online.talk.pdf">talk</a> 
<a href="publications/neu2014online.poster.pdf">poster</a> 
</li>


<li><strong>Michal Valko</strong>, Rémi Munos, Branislav Kveton, Tomáš Kocák:
 <a href="publications/valko2014spectral.pdf">
<em>Spectral Bandits for Smooth Graph Functions</em></a>, 
in <a href="http://icml.cc/2014/">International Conference on Machine Learning</a> 
(<span class="conference-shortcut">ICML 2014</span>)  <a href="publications/valko2014spectral.bib">bibtex</a><a href="publications/valko2014spectral.talk.pdf">slides</a>
 <a href="publications/valko2014spectral.poster.pdf">poster</a> 
</li>


<li>Tomáš Kocák, <strong>Michal Valko</strong>, Rémi Munos, Shipra Agrawal:
 <a href="publications/kocak2014spectral.pdf">
<em>Spectral Thompson Sampling</em></a>, 
in <a href="http://www.aaai.org/Conferences/AAAI/aaai14.php">AAAI Conference on Artificial Intelligence</a> 
(<span class="conference-shortcut">AAAI 2014</span>)  <a href="publications/kocak2014spectral.bib">bibtex</a><a href="publications/kocak2014spectral.talk.pdf">slides</a> 
<a href="publications/kocak2014spectral.poster.pdf">poster</a> 
</li>

<li>Philippe Preux, Rémi Munos, <strong>Michal Valko</strong>:
 <a href="publications/preux2014bandits.pdf">
<em>Bandits attack function optimization</em></a>, in <a href="http://www.ieee-wcci2014.org/">IEEE Congress on Evolutionary Computation</a> 
(<span class="conference-shortcut">CEC 2014</span>)  <a href="publications/preux2014bandits.bib">bibtex</a></li>

<li>Julien Audiffren, <strong>Michal Valko</strong>, Alessandro Lazaric, Mohammad Ghavamzadeh:
 <a href="publications/audiffren2014messi.pdf">
<em> MESSI: Maximum Entropy Semi-Supervised Inverse Reinforcement Learning</em></a>, 
in  <a href="https://tcrl14.wordpress.com/">NIPS Workshop on Novel Trends and Applications in Reinforcement Learning</a> 
(<span class="conference-shortcut">NeurIPS 2014 - TCRL</span>)  <a href="publications/audiffren2014messi.bib">bibtex</a> 
</li>

<li>Tomáš Kocák, <strong>Michal Valko</strong>, Rémi Munos, Branislav Kveton, Shipra Agrawal:
 <a href="publications/kocak2014wspectral.pdf">
<em>Spectral Bandits for Smooth Graph Functions with Applications in Recommender Systems</em></a>, 
in  <a href="http://www.aaai.org/ws14workshops/ws14workshops.php#ws14">AAAI Workshop on Sequential Decision-Making with Big Data</a> 
(<span class="conference-shortcut">AAAI 2014 - SDMBD</span>)  <a href="publications/kocak2014wspectral.bib">bibtex</a> 
</li>
</ul>
<h2>2013</h2>
<ul class="publications-list">

<li><strong>Michal Valko</strong>, Alexandra Carpentier, Rémi Munos:
 <a href="publications/valko2013stochastic.pdf"><em>Stochastic Simultaneous Optimistic Optimization</em></a>, in <a href="http://icml.cc/2013/">International Conference on Machine Learning</a> 
 (<span class="conference-shortcut">ICML 2013</span>)    
 <a href="publications/valko2013stochastic.bib">bibtex</a> 
 <a href="http://youtu.be/Vx1tB6ADc-M">demo</a>
 <a href="https://fr.mathworks.com/matlabcentral/fileexchange/42343-stochastic-simultaneous-optimistic-optimization">code</a>,
 <a href="https://cran.r-project.org/web/packages/OOR/index.html">code in R</a> 
 <a href="publications/valko2013stochastic.talk.pdf">slides</a>
 <a href="publications/valko2013stochastic.poster.pdf">poster</a> 
 <a href="http://techtalks.tv/talks/stochastic-simultaneous-optimistic-optimization/58353/">talk</a>
</li>


<li>
<strong>Michal Valko</strong>, Nathan Korda, Rémi Munos, Ilias Flaounas, Nello Cristianini:
 <a href="publications/valko2013finite.pdf"><em>Finite-Time Analysis of Kernelised Contextual Bandits</em></a>, 
 in <a href="http://auai.org/uai2013//">Uncertainty in Artificial Intelligence </a> 
 (<span class="conference-shortcut">UAI 2013</span>) and (<span class="conference-shortcut-more">JFPDA 2013</span>).    
  <a href="publications/valko2013finite.bib">bibtex</a>  
  <a href="publications/valko2013finite.poster.pdf">poster</a>
  <a href="publications/valko2013finite.spotlight.pdf">spotlight</a>
  <a href="https://team.inria.fr/sequel/Software/KernelUCB/">code</a>
</li>


<li>Branislav Kveton, <strong>Michal Valko</strong>:
 <a href="publications/kveton2013learning.pdf"><em>Learning from a Single Labeled Face and a Stream of Unlabeled Data</em></a>, 
 in <a href="http://fg2013.cse.sc.edu/">IEEE International Conference on Automatic Face and Gesture Recognition</a> 
 (<span class="conference-shortcut">FG 2013</span>)   
<span style="color: #CC3333">[spotlight]</span> 
 <a href="publications/kveton2013learning.bib">bibtex</a> 
</li>


<li>Milos Hauskrecht, Iyad Batal, <strong>Michal Valko</strong>, Shyam Visweswaran, Gregory F. Cooper, Gilles Clermont:
 <a href="publications/hauskrecht2013outlier.pdf">
<em>Outlier detection for patient monitoring and alerting</em></a>, in <a href="http://www.journals.elsevier.com/journal-of-biomedical-informatics/">Journal of Biomedical Informatics</a> (<span class="conference-shortcut">JBI 2013</span>)  <a href="publications/hauskrecht2013outlier.bib">bibtex</a></li>

</ul>
<h2>2012</h2>
<ul class="publications-list">

<li><strong>Michal Valko</strong>,
Mohammad Ghavamzadeh,  Alessandro Lazaric: <a href="publications/valko2012semi-supervised.pdf">
<em>Semi-supervised apprenticeship learning</em></a>, in Journal of Machine Learning Research Workshop and Conference Proceedings:  <a href="http://ewrl.wordpress.com/ewrl10-2012/">European Workshop on Reinforcement Learning</a> (<span class="conference-shortcut">EWRL 2012</span>)  <a href="publications/valko2012semi-supervised.bib">bibtex</a><a href="publications/valko2012semi-supervised.talk.pdf">talk</a>
<a href="publications/valko2012semi-supervised.poster.pdf">poster</a>
</li>




</ul>
<h2>2011</h2>
<ul class="publications-list">


<li><strong>Michal Valko</strong>,
Branislav Kveton, Hamed Valizadegan, Gregory F. Cooper, Milos Hauskrecht:
 <a href="publications/valko2011conditionala.pdf"><em>Conditional Anomaly Detection with Soft Harmonic Functions</em></a>, in <a href="http://webdocs.cs.ualberta.ca/~icdm2011/">International Conference on Data Mining</a> (<span class="conference-shortcut">ICDM 2011</span>)   <a href="publications/valko2011conditionala.bib">bibtex</a> 
</li>

<li> Thomas C. Hart, Patricia M. Corby, Milos Hauskrecht, Ok Hee Ryu, Richard Pelikan, <strong>Michal Valko</strong>, Maria B. Oliveira, Gerald T. Hoehn, and Walter A. Bretz:
<a href="publications/hart2011indentification.pdf"><em>
Identification of Microbial and Proteomic Biomedicalkers in
Early Childhood Caries</em></a> in <a href="http://www.hindawi.com/journals/ijd/">International Journal of Dentistry</a> (<span class="conference-shortcut">IJD 2011</span>)   <a href="publications/hart2011indentification.bib">bibtex</a> 
<!-- <span class="citation-count">[0+1 citations]</span>  -->
</li>

<li>
<strong>Michal Valko</strong>: 
<a href="publications/valko2011adaptive.pdf"><em>Adaptive Graph-Based Algorithms for Conditional Anomaly Detection and Semi-Supervised Learning</em></a>, PhD thesis, <a href="http://www.cs.pitt.edu/">University of Pittsburgh</a>
(<span class="conference-shortcut">PITT 2011</span>)   <a href="publications/valko2011adaptive.bib">bibtex</a> 
<!-- <span class="citation-count">[1+2 citations]</span>  -->
</li>


<li><strong>Michal Valko</strong>,
Hamed Valizadegan, Branislav Kveton, Gregory F. Cooper, Milos Hauskrecht:
 <a href="publications/valko2011conditional.pdf"><em>Conditional Anomaly Detection Using Soft Harmonic Functions: An Application to Clinical Alerting</em></a>, Workshop on Machine Learning for Global Challenges in <a href="http://www.icml-2011.org/">International Conference on Machine Learning</a> (<span class="conference-shortcut">ICML 2011 - Global</span>)   <a href="publications/valko2011conditional.bib">bibtex</a> 
<a href="publications/valko2011conditional.poster.pdf">poster</a> 
<a href="publications/valko2011conditional.spotlight.pdf">spotlight</a> 
<!-- <span class="citation-count">[0+1 citations]</span>  -->
</li>

</ul>
<h2>2010</h2>
<ul class="publications-list">

<li>
<strong>Michal Valko</strong>, Branislav Kveton, Ling Huang, Daniel Ting: 
<a href="publications/valko2010online.pdf"><em>Online Semi-Supervised Learning on Quantized Graphs</em></a> in 
<a href="http://event.cwi.nl/uai2010/">Uncertainty in Artificial Intelligence</a>
(<span class="conference-shortcut">UAI 2010</span>)   <a href="publications/valko2010online.bib">bibtex</a> 
<a href="publications/kveton2009nipsdemo.adaptation.mov">Video: Adaptation</a>, 
<a href="publications/kveton2009nipsdemo.officespace.mov">Video: OfficeSpace</a>,
<a href="publications/valko2010online.spotlight.pdf">spotlight</a>
<a href="publications/valko2010online.poster.pdf">poster</a>
<!-- <span class="citation-count">[3+2 citations]</span>  -->
</li>

<li>Branislav Kveton, <strong>Michal Valko</strong>, Ali Rahimi, Ling Huang:
<a href="publications/kveton2010semi-supervised.pdf"><em>Semi-Supervised Learning with Max-Margin Graph Cuts</em></a> in 
<a href="https://aistats.org/">International Conference on Artificial Intelligence and Statistics</a>
(<span class="conference-shortcut">AISTATS 2010</span>)   <a href="publications/kveton2010semi-supervised.bib">bibtex</a> 
<!-- <span class="citation-count">[3+3 citations]</span> -->
</li>


<li> Milos Hauskrecht, <strong>Michal Valko</strong>, Shyam Visweswaram, Iyad Batal, Gilles Clermont, Gregory Cooper: 
<a href="publications/hauskrecht2010conditional.pdf"><em>Conditional Outlier Detection for Clinical Alerting</em></a> in Annual American Medical Informatics Association  conference 
(<span class="conference-shortcut">AMIA 2010</span>)  <a href="publications/hauskrecht2010conditional.bib">bibtex</a> 
<span style="color: #CC3333">[Homer Warner Best Paper <a href="http://en.wikipedia.org/wiki/Homer_R._Warner#Homer_R._Warner_award">Award</a>]</span>
<!-- <span class="citation-count">[3+2 citations]</span>  -->
</li>


<li>Branislav Kveton, <strong>Michal Valko</strong>, Matthai Phillipose, Ling Huang:
<a href="publications/kveton2010online.pdf"><em>Online Semi-Supervised Perception: Real-Time Learning without Explicit Feedback</em></a> in 
<a href="http://www.porikli.com/OLCV2010/olcv2010.html">IEEE Online Learning for Computer Vision Workshop in The
	IEEE Conference on Computer Vision and Pattern Recognition</a>
(<span class="conference-shortcut">CVPR 2010 - OLCV</span>) 
<span style="color: #CC3333">[best paper Google  <a href="projects/phd_awards/award_2010_olcv.jpg">Award</a>]</span>
 <a href="publications/kveton2010online.bib">bibtex</a> 
<!-- <span class="citation-count">[3 + 2 citations]</span> -->
</li>


<li><strong>Michal Valko</strong>, Milos Hauskrecht:
<a href="publications/valko2010feature.pdf"><em>Feature importance analysis for patient management decisions</em></a> in
<a href="http://www.imia-medinfo.org/medinfo2010/">International Congress on Medical Informatics</a>
(<span class="conference-shortcut">MEDINFO 2010</span>)   <a href="publications/valko2010feature.bib">bibtex</a> 
<!-- <span class="citation-count">[3 + 1 citations]</span>  -->
</li>

</ul>
<h2>2008</h2>
<ul class="publications-list">


<li><strong>Michal Valko</strong>,
  Gregory Cooper, Amy Seybert, 
  Shyam Visweswaran, Melissa Saul, Milos Hauskrecht:
 <a href="publications/valko2008conditional.pdf"><em>Conditional anomaly detection methods for patient-management alert systems</em></a>, Workshop on Machine Learning in Health Care Applications in <a href="http://icml2008.cs.helsinki.fi/">International Conference on Machine Learning</a> (<span class="conference-shortcut">ICML-2008 - MLHealth</span>)   <a href="publications/valko2008conditional.bib">bibtex</a> 
<a href="publications/valko2008conditional.talk.pdf">talk</a>
<!-- <span class="citation-count">[2+3 citations]</span>  -->
</li>
  
 
<li><strong>Michal Valko</strong>, Milos Hauskrecht: <a href="publications/valko2008distance.pdf"><em>Distance metric learning for conditional anomaly detection</em></a>, <a href="http://www.cs.miami.edu/home/geoff/Conferences/FLAIRS-21/">International Florida AI Research Society Conference</a> (<span class="conference-shortcut">FLAIRS 2008</span>) 
    <a href="publications/valko2008distance.bib">bibtex</a><!--	<span class="citation-count">[0 + 3 citations]</span>  -->
</li>




<li><strong>Michal Valko</strong>, Richard Pelikan, Milos Hauskrecht: <a href="publications/valko2008learning.pdf"><em>Learning predictive models for combinations of heterogeneous
proteomic data sources</em></a>, AMIA
  Summit on Translational Bioinformatics (<span class="conference-shortcut">STB  2008</span>)  <span style="color: #CC3333">[outstanding paper <a href="projects/phd_awards/amiaSTB2008award.jpg">award</a>]</span>   <a href="publications/valko2008learning.bib">bibtex</a><a href="publications/valko2008learning.talk.pdf">talk</a>
</li>

</ul>
<h2>2007</h2>
<ul class="publications-list">

<li> Milos Hauskrecht, <strong>Michal Valko</strong>, Branislav Kveton, Shyam Visweswaram, Gregory Cooper: <a href="publications/hauskrecht2007evidence-based.pdf"><em>Evidence-based Anomaly Detection in Clinical Domains</em></a> in Annual American Medical Informatics Association  conference (<span class="conference-shortcut">AMIA 2007</span>).
  <span style="color: #CC3333">[nominated for the best paper award]  </span>  <a href="publications/hauskrecht2007evidence-based.bib">bibtex</a> 
<!-- <span class="citation-count">[3+6 citations]</span>        -->
</li>


</ul>
<h2>2006</h2>
<ul class="publications-list">


<li> Wendy W. Chapman, John N. Dowling, Gregory F. Cooper, Milos Hauskrecht and <strong>Michal Valko</strong>: <em><a href="publications/chapman2006comparison.pdf">A Comparison of Chief Complaints and Emergency Department Reports for Identifying Patients with Acute Lower Respiratory Syndrome</a></em> in 
  

   Proceedings of the National Syndromic Surveillance Conference
  (<span class="conference-shortcut">ISDS 2006</span>) 
 <a href="publications/chapman2006comparison.bib">bibtex</a>  </li>
 

<li>  Miloš Hauskrecht, Richard Pelikan, <strong>Michal Valko</strong>, James Lyons-Weiler: <em><a href="publications/hauskrecht2006fundamentals.pdf">Feature Selection and Dimensionality Reduction in Genomics and Proteomics</a></em>.  <a href="http://www.springer.com/west/home/life+sci/bioinformatics?SGWID=4-10031-22-173695541-0">Fundamentals of Data Mining in Genomics and Proteomics</a>, eds. Berrar, Dubitzky, Granzow. Springer (<span class="conference-shortcut">2006</span>) 
 <a href="publications/hauskrecht2006fundamentals.bib">bibtex</a> 
<!-- <span class="citation-count">[5 + 1 citations]</span>       -->
</li> 

</ul>
<h2>2005</h2>
<ul class="publications-list">


  <li>
    <strong>Michal Valko</strong>, Nuno C. Marques, Marco Castelani:      <em>Evolutionary Feature Selection for Spiking Neural Network Pattern Classifiers</em>  
      in Proceedings of  Portuguese Conference on Artificial Intelligence (<a href="http://www.springer.com/us/book/9783540307372" class="conference-shortcut">EPIA 2005</a>), 
      eds. Bento et al.,  IEEE, pages 24-32.	  <a href="publications/valko2005evolutionary.bib">bibtex</a> 
<!--	<span class="citation-count">[5 + 0 citations]</span>  -->
 </li>

  <li>  
    <strong>Michal Valko</strong> <em><a href="projects/thesis/nesdt.pdf">Evolving Neural Networks for Statistical Decision Theory</a></em>, 
	Comenius University, Bratislava, 2005
    (master thesis) (<span class="conference-shortcut">2005</span>) Advisor: Radoslav Harman 
<!--   	<a href="http://diplomovka.sme.sk/en/diploma/2455/evolving-neural-networks-for-statistical-decision-theory.php">thesis@sk</a> -->
	<a href="publications/valko2005evolving.bib">bibtex</a> 
    <a   href="projects/thesis/defense-nesdt.pdf">talk</a> 
<!--    <span class="citation-count">[3 citations]</span>  -->
</li>
</ul>

<h2>older preprints</h2>
<ul class="publications-list">
	
<li>Zhaohan Daniel Guo, Mohammad Gheshlaghi Azar, Alaa Saade, Shantanu Thakoor, Bilal Piot, Bernardo Ávila Pires, <strong>Michal Valko</strong>, Thomas Mesnard, Tor Lattimore, Rémi Munos:
  <aa href="publications/guo2021geometric.pdf"><em>
Geometric entropic exploration,</em></aa>
  <a href="https://arxiv.org/abs/2101.02055">arXiv preprint</a>
</li>

<li>Pierre Perrault, Jennifer Healey, Zheng Wen, Michal Valko <strong>Michal Valko</strong>:
  <aa href="publications/perrault2021on.pdf"><em>
On the approximation relationship between optimizing ratio of submodular (RS) and difference of submodular (DS) functions,</em></aa>
  <a href="https://arxiv.org/abs/2101.01631">arXiv preprint</a>
</li>	


<li>Branislav Kveton, Zheng Wen, Azin Ashkan, <strong>Michal Valko</strong>:
 <aa href="publications/kveton2016learning.pdf"><em>Learning to Act Greedily: Polymatroid Semi-Bandits</em></aa>, 
accepted for publication to <a href="http://www.jmlr.org/">Journal of Machine Learning Research</a>
 (<span class="conference-shortcut">JMLR</span>)    
 <a href="publications/kveton2016learning.bib">bibtex</a> 
 <a href="https://arxiv.org/abs/1405.7752">arXiv preprint</a>
  <!-- <a href="publications/kveton2016learning.talk.pdf">talk</a> -->
  <!-- <a href="publications/kveton2016learning.poster.pdf">poster</a> -->
</li>

 
 


</ul>



<h2>Presentations</h2>
<ul id="presentations-list">

<li><strong>Michal Valko:</strong> <em>Graph-Based Anomaly Detection with Soft Harmonic Functions</em>: Presented at 
CS Department Research Competition  (<span class="conference-shortcut">Research 2011</span>) <span style="color: #CC3333">[<a href="
projects/phd_awards/award_2011_research.jpg">#1st place</a>]  </span>
<a href="publications/valko2011csresearch.talk.pdf">talk</a>
also at  (<span class="conference-shortcut">Grad Expo 2011</span>) and  (<span class="conference-shortcut">CS DAY 2011</span>)
<a href="publications/valko2011csday.poster.pdf">poster</a>
</li>

<li>
Branislav Kveton, <strong>Michal Valko</strong>, Matthai Philiposse: <em>Real-Time Adaptive Face Recognition</em>, Presented at 
23rd Neural Information Processing Systems conference   <a href="https://nips.cc/Conferences/2009/Schedule">(<span class="conference-shortcut">NeurIPS 2009</span>)</a>, 
<a href="publications/kveton2009nipsdemo.adaptation.mov">Video: Adaptation</a>, 
<a href="publications/kveton2009nipsdemo.officespace.mov">Video: OfficeSpace</a>,
<a href="publications/kveton2009nipsdemo.poster.pdf">poster #1</a>,
<a href="publications/valko2009nipsdemo.poster.pdf">poster #2</a>
</li>

<li><strong>Michal Valko:</strong>, Branislav Kveton, Matthai Philiposse:  <em>Robust Face Recognition Using Online Learning</em>, Presented at 
9th University of Pittsburgh Science conference  (<span class="conference-shortcut">SCIENCE 2009</span>)</
Live Demonstration
(<span class="conference-shortcut">Grad Expo 2010</span>) 
<a href="publications/valko2010robust.talk.pdf">talk</a>
and  (<span class="conference-shortcut">CS Day 2010</span>)  <a href="publications/valko2010robust.poster.pdf">poster</a>
</li>


<li><strong>Michal Valko:</strong> <em> Conditional anomaly detection with adaptive similarity metric</em>: Presented at 
CS Department Research Competition  (<span class="conference-shortcut">Research 2008</span>) <span style="color: #CC3333">[<a href="
projects/phd_awards/award_2008_research.jpg">#1st place</a>]  </span>
<a href="publications/valko2008csresearch.talk.pdf">talk</a>
</li>

<li>
<strong>Michal Valko</strong>, Milos Hauskrecht, G. Cooper, S. Visweswaran, M. Saul, A. Seybert,  J. Harrison, A. Post:
<em>Conditional Anomaly Detection</em>, Presented at (<span class="conference-shortcut">CS Day 2008</span>)
 <span style="color: #CC3333">[<a href="projects/phd_awards/award_2008_cs_day_poster_winner.jpg">#1st by people</a>, <a href="projects/phd_awards/award_2008_cs_day_poster_runner_up.jpg">#2nd by faculty</a>] </span> also at University of Pittsburgh, Arts &amp; Sciences (<span class="conference-shortcut">Grad Expo 2008</span>)
<a href="publications/valko2008csday.poster.pdf">poster</a>
</li>
</ul>

<h2>References</h2><ul> <li> <a href="publications/library.bib">bibtex file</a> with references I often use </li> </ul>
<!-- </ul> -->


			<div id="modified">mv </div>
	  </div>
	</div></div>
	<div id="downlt"><div id="downrt"><div id="down"></div></div></div>

	</body>
</html>
