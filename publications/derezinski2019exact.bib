@inproceedings{derezinski2019exact,
abstract = {We study the complexity of sampling from a distribution over all index subsets of the set (1,...,n) with the probability of a subset S proportional to the determinant of the submatrix LS of some n x n p.s.d. matrix L, where LS corresponds to the entries of L indexed by S. Known as a determinantal point process, this distribution is used in machine learning to induce diversity in subset selection. In practice, we often wish to sample multiple subsets S with small expected size k = E[card(S)] that is much smaller then n from a very large matrix L, so it is important to minimize the preprocessing cost of the procedure (performed once) as well as the sampling cost (performed repeatedly). For this purpose, we propose a new algorithm which, given access to L, samples exactly from a determinantal point process while satisfying the following two properties: (1) its preprocessing cost is n x poly(k) (sublinear in the size of L) and (2) its sampling cost is poly(k) (independent of the size of L). Prior to our results, state-of-the-art exact samplers required O(n3) preprocessing time and sampling time linear in n or dependent on the spectral properties of L. We also give a reduction which allows using our algorithm for sampling from cardinality constrained determinantal point processes with n x poly(k) time preprocessing.},
author = {Derezi{\'{n}}ski, Micha{\l} and Calandriello, Daniele and Valko, Michal},
booktitle = {Neural Information Processing Systems},
title = {{Exact sampling of determinantal point processes with sublinear time preprocessing}},
year = {2019}
}
