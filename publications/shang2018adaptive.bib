@inproceedings{shang2018adaptive,
abstract = {Hierarchical bandits is an approach for global optimization of extremely irregular functions. This paper provides new elements regarding POO, an adaptive meta-algorithm that does not require the knowledge of local smoothness of the target function. We first highlight the fact that the sub-routine algorithm used in POO should have a small regret under the assumption of local smoothness with respect to the chosen partitioning, which is unknown if it is satisfied by the standard sub-routine HOO. In this work, we establish such regret guarantee for HCT which is another hierarchical optimistic optimization algorithm that needs to know the smoothness. This confirms the validity of POO. We show that POO can be used with HCT as a sub-routine with a regret upper bound that matches that of best-known algorithms using the knowledge of smoothness up to a sqrt(log(n)) factor.},
author = {Shang, Xuedong and Kaufmann, Emilie and Valko, Michal},
booktitle = {European Workshop on Reinforcement Learning},
title = {{Adaptive black-box optimization got easier: HCT needs only local smoothness}},
year = {2018}
}
